{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/img/grafana/1.png","path":"img/grafana/1.png","modified":1,"renderable":0},{"_id":"source/img/grafana/5.png","path":"img/grafana/5.png","modified":1,"renderable":0},{"_id":"source/img/grafana/4.png","path":"img/grafana/4.png","modified":1,"renderable":0},{"_id":"source/img/grafana-alerting/3.png","path":"img/grafana-alerting/3.png","modified":1,"renderable":0},{"_id":"source/img/grafana-alerting/2.png","path":"img/grafana-alerting/2.png","modified":1,"renderable":0},{"_id":"source/img/grafana-alerting/5.png","path":"img/grafana-alerting/5.png","modified":1,"renderable":0},{"_id":"source/img/grafana-alerting/6.png","path":"img/grafana-alerting/6.png","modified":1,"renderable":0},{"_id":"source/img/grafana-alerting/7.png","path":"img/grafana-alerting/7.png","modified":1,"renderable":0},{"_id":"source/img/grafana-alerting/4.png","path":"img/grafana-alerting/4.png","modified":1,"renderable":0},{"_id":"source/img/k8s/4.png","path":"img/k8s/4.png","modified":1,"renderable":0},{"_id":"source/img/k8s/3.jpg","path":"img/k8s/3.jpg","modified":1,"renderable":0},{"_id":"source/img/loki/3.png","path":"img/loki/3.png","modified":1,"renderable":0},{"_id":"source/img/loki/logo.png","path":"img/loki/logo.png","modified":1,"renderable":0},{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"source/img/grafana/3.png","path":"img/grafana/3.png","modified":1,"renderable":0},{"_id":"source/img/grafana/2.png","path":"img/grafana/2.png","modified":1,"renderable":0},{"_id":"source/img/k8s/1.png","path":"img/k8s/1.png","modified":1,"renderable":0},{"_id":"source/img/grafana-alerting/8.png","path":"img/grafana-alerting/8.png","modified":1,"renderable":0},{"_id":"source/img/k8s/2.png","path":"img/k8s/2.png","modified":1,"renderable":0},{"_id":"source/img/k8s/6.png","path":"img/k8s/6.png","modified":1,"renderable":0},{"_id":"source/img/loki/2.png","path":"img/loki/2.png","modified":1,"renderable":0},{"_id":"source/img/k8s/5.svg","path":"img/k8s/5.svg","modified":1,"renderable":0},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"source/img/grafana/2.bak.png","path":"img/grafana/2.bak.png","modified":1,"renderable":0},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":1,"renderable":1},{"_id":"source/img/loki/1.png","path":"img/loki/1.png","modified":1,"renderable":0},{"_id":"themes/landscape/source/css/images/banner_org.jpg","path":"css/images/banner_org.jpg","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"source/img/hexo/1.png","path":"img/hexo/1.png","modified":1,"renderable":0}],"Cache":[{"_id":"themes/landscape/.npmignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1573235632520},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1573235632520},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1573235632520},{"_id":"themes/landscape/README.md","hash":"c7e83cfe8f2c724fc9cac32bd71bb5faf9ceeddb","modified":1573235632520},{"_id":"themes/landscape/_config.yml","hash":"fb8c98a0f6ff9f962637f329c22699721854cd73","modified":1573235632520},{"_id":"themes/landscape/package.json","hash":"85358dc34311c6662e841584e206a4679183943f","modified":1573235632524},{"_id":"source/_posts/gitrunner-helm-install.md","hash":"76e9725956c556ce048ce4cf21a9eedf78beff85","modified":1573235632508},{"_id":"source/_posts/btree.md","hash":"20163b97ecca7688995fff29fa8b8c1a57b322ae","modified":1573235632508},{"_id":"source/_posts/core-dns.md","hash":"496f6e44284a39dea988a0d5a8e909b07ffb9cb3","modified":1573235632508},{"_id":"source/_posts/grafana-alerting.md","hash":"3c690636e27a61c586fd41c65c537266fb64dfea","modified":1573235632508},{"_id":"source/_posts/grafana-variables.md","hash":"8f3bb478f395d2e325348ae5c4ccb9a7cfb4cad9","modified":1573235632508},{"_id":"source/_posts/helm.md","hash":"81b70934e1cd8998e90f51d573b1eebfe10bbcb4","modified":1573235632508},{"_id":"source/_posts/hexo.md","hash":"51bfd19df7b64d842e4e62d8f49e5b496248ad15","modified":1573237476088},{"_id":"source/_posts/jenkins-introduction.md","hash":"464df297713d0f726a33d7e2a1529e7553c73abf","modified":1573235632508},{"_id":"source/_posts/k8s-introduction.md","hash":"78f3103afc1f202d94cf82c86c456b18fed6f546","modified":1573235632512},{"_id":"source/_posts/k8s-migration-1.md","hash":"47a225e9fcd48de61710a92b0ee58e48fdeb7a05","modified":1573236908701},{"_id":"source/_posts/k8s-notes.md","hash":"c50a1c60212a3c2a88e8e9baeba7abdd6523bacb","modified":1573235632512},{"_id":"source/_posts/loki.md","hash":"928c15f569a9364e8893cbb348868e72f909eedf","modified":1573235632512},{"_id":"source/_posts/laravel.md","hash":"39b4a3e8ea28d7d04dd14f3e72f88c0f8f93594c","modified":1573235632512},{"_id":"source/_posts/nginx.md","hash":"a5d5f40a5a02298032125aa8f32f7e84cd5da6d4","modified":1573235632512},{"_id":"source/_posts/prometheus.md","hash":"dc7425ce51e502d574d2280602d3c3c6326e91f9","modified":1573235632512},{"_id":"source/_posts/tcp.md","hash":"d1cb619b737c280749db9be87ff3d9e65f9f8350","modified":1573235632512},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1573235632520},{"_id":"themes/landscape/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1573235632520},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1573235632520},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1573235632520},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1573235632520},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1573235632520},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1573235632520},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1573235632520},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1573235632520},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1573235632524},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1573235632524},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1573235632524},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1573235632524},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1573235632524},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1573235632524},{"_id":"source/img/grafana/1.png","hash":"6688d162f54a6b31d8a3f58da4a747e2a90b7e0f","modified":1573235632512},{"_id":"source/img/grafana/5.png","hash":"8eafae501beb11d44f1c1cba33ab5d7be7fb436b","modified":1573235632516},{"_id":"source/img/grafana/4.png","hash":"c5767d6d65f0dfa19776c01bf698aa0a7a21144c","modified":1573235632516},{"_id":"source/img/grafana-alerting/3.png","hash":"7445b32c9bc421331dde0efa8eedf8928e5a24b6","modified":1573235632512},{"_id":"source/img/grafana-alerting/2.png","hash":"40bf8a0133c93d206d3f3d3615d9fce997f0ed3f","modified":1573235632512},{"_id":"source/img/grafana-alerting/5.png","hash":"f3e7ace9feb0d40d49022dd26de062de5f240ffd","modified":1573235632512},{"_id":"source/img/grafana-alerting/6.png","hash":"27515ce8d5f065a40d1139d270941477d5c43045","modified":1573235632512},{"_id":"source/img/grafana-alerting/7.png","hash":"875de873a9eb3b938eaf719dbf96fabcf32fb9a1","modified":1573235632512},{"_id":"source/img/grafana-alerting/4.png","hash":"8e7beab20bf3c2df3e52e45a63e10b4fbac8d750","modified":1573235632512},{"_id":"source/img/k8s/4.png","hash":"a8ac198596f6cbc2b176f60a3af8ef770ba74986","modified":1573235632520},{"_id":"source/img/k8s/3.jpg","hash":"04222abe2ac1cb68bd21655780e275b94d4b7bb9","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"82a30f81c0e8ba4a8af17acd6cc99e93834e4d5e","modified":1573235632520},{"_id":"source/img/loki/3.png","hash":"a853262492ce9cf76df0e0fcad9212c07f712430","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1573235632520},{"_id":"source/img/loki/logo.png","hash":"d3a1ff513556c5bb1c144b9e7caa96d71acb594b","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"931aaaffa0910a48199388ede576184ff15793ee","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"4fe8853e864d192701c03e5cd3a5390287b90612","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"c21ca56f419d01a9f49c27b6be9f4a98402b2aa3","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1573235632520},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1573235632520},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1573235632520},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1573235632520},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1573235632520},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1573235632520},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1573235632524},{"_id":"themes/landscape/source/css/_variables.styl","hash":"5e37a6571caf87149af83ac1cc0cdef99f117350","modified":1573235632524},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1573235632528},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1573235632528},{"_id":"source/img/grafana/3.png","hash":"5226ddfc672c157931a1a64d014978105f3e23a1","modified":1573235632516},{"_id":"source/img/grafana/2.png","hash":"ffb7d6e0ca4bdbf08813b7fdccd7d90089528aee","modified":1573235632516},{"_id":"source/img/k8s/1.png","hash":"aaef20704f36c5cd855b30ffdb370925642b4404","modified":1573235632516},{"_id":"source/img/grafana-alerting/8.png","hash":"d5b36c2709a622f0b7e3be5be8aa06dfe2b1fb93","modified":1573235632512},{"_id":"source/img/k8s/2.png","hash":"a0cc8e0bc5608f991b98602237ed12b4757e56f2","modified":1573235632516},{"_id":"source/img/k8s/6.png","hash":"88cc3026320b900ac1280757e90b8ac9d08504b4","modified":1573236501930},{"_id":"source/img/loki/2.png","hash":"4f40694f5dc0eaf9f4e8df1d2f9b6e2a6fd041b9","modified":1573235632520},{"_id":"source/img/k8s/5.svg","hash":"d1411cded83856552f37911eb4522d9887ca4e83","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1573235632520},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1573235632520},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1573235632524},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1573235632524},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1573235632524},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1573235632524},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1573235632524},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1573235632524},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1573235632528},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1573235632528},{"_id":"source/img/grafana/2.bak.png","hash":"5dded09e9b81014954c28c39cd6bfe326e730fce","modified":1573235632512},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1573235632524},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"e86656f9a24e0d0849aff08aa6490a717e6e1f8d","modified":1573235632524},{"_id":"source/img/loki/1.png","hash":"1698dc20dd0e4e7fccb7ef63b83209a66d784797","modified":1573235632520},{"_id":"themes/landscape/source/css/images/banner_org.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1573235632528},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1573235632524},{"_id":"source/img/hexo/1.png","hash":"63f36a8ef225402464c3551ab53f1906cc92cf62","modified":1573235632516},{"_id":"public/2019/10/grafana-variables/index.html","hash":"9d9f0d4a35cc98c55842a426127a6557077292ff","modified":1573237486799},{"_id":"public/2019/10/grafana-alerting/index.html","hash":"d253372ab2329c9014328c7a17203ef71e120a88","modified":1573237486799},{"_id":"public/2019/02/btree/index.html","hash":"660231f21698c5cff7c34360c104cd246ebb4051","modified":1573237486800},{"_id":"public/2019/02/nginx/index.html","hash":"00ddc560ed336ac75cadbbce3a2fd22c03b4f13f","modified":1573237486800},{"_id":"public/archives/index.html","hash":"d7ccf7665aa7db1b78dd5bd2bc6084cca0739673","modified":1573237486800},{"_id":"public/archives/page/2/index.html","hash":"ec076bdee523d00fcb41c9b94cd0455d64c9a63c","modified":1573237486800},{"_id":"public/archives/2019/index.html","hash":"edb46fc2cb9d24a70a3d197d0b81afd79e8635f8","modified":1573237486800},{"_id":"public/archives/2019/page/2/index.html","hash":"d6aa99cd98f437cda29f97277cb58eaf4b787dd0","modified":1573237486800},{"_id":"public/archives/2019/01/index.html","hash":"f9e2a5219816dfd7757fd9fce718eee783a77eff","modified":1573237486800},{"_id":"public/archives/2019/02/index.html","hash":"e5b3bc73a6f509e5ca94fea73246d6f579d57eb3","modified":1573237486800},{"_id":"public/archives/2019/10/index.html","hash":"15149243c340a97c12e2948585f460ca3f1621c5","modified":1573237486800},{"_id":"public/archives/2019/11/index.html","hash":"f7eb077ad29c18c8e8d51fda5d2d60ad2d8026a0","modified":1573237486801},{"_id":"public/tags/gitrunner/index.html","hash":"19f122ee3c2cca9d5cd2bd4cb921a83a6bcdb652","modified":1573237486801},{"_id":"public/tags/helm/index.html","hash":"5b47442f9d7bd57cf74b7d5c9cf14ac6aa61f915","modified":1573237486801},{"_id":"public/tags/b树/index.html","hash":"00a3b5e7b4504b214c924c7b187efd09fadb62a3","modified":1573237486801},{"_id":"public/tags/数据结构/index.html","hash":"ffc1d8d04b85ce47cd254c5be78a38c54fe381d8","modified":1573237486801},{"_id":"public/tags/coredns/index.html","hash":"d08666591f2bd19d594672d793e58a906ecc9a5a","modified":1573237486801},{"_id":"public/tags/etcd/index.html","hash":"4843937aac1682062a5fa3d205554d64d4af28c6","modified":1573237486801},{"_id":"public/tags/loki/index.html","hash":"ae37490e206383c1436a719c179bc28776b5abfe","modified":1573237486801},{"_id":"public/tags/promtal/index.html","hash":"8a0525ca5ee00d0c922296fb607c0aa62fd05702","modified":1573237486801},{"_id":"public/tags/grafana/index.html","hash":"2542578dc17ac55779cc0d4744cc43aae6ddda8f","modified":1573237486801},{"_id":"public/tags/k8s/index.html","hash":"d043a228e49ed62b8503447768ff5116a7d1cfb5","modified":1573237486801},{"_id":"public/tags/charts/index.html","hash":"af84bf3ef8b99d862c6c798c27233fc67e58a56f","modified":1573237486801},{"_id":"public/tags/prometheus/index.html","hash":"b69a2f4fb44d57a886c0e996981d651c26346dfc","modified":1573237486801},{"_id":"public/tags/报警/index.html","hash":"183f0d40fe6a44e487f857f270bbaf0efad57d3e","modified":1573237486801},{"_id":"public/tags/hexo/index.html","hash":"974416bc7a0f858eae572b3c0d6b51b0a3539ef6","modified":1573237486802},{"_id":"public/tags/jenkins/index.html","hash":"97c73ad63b73dfaab201171cfa44d4a147b8a640","modified":1573237486802},{"_id":"public/tags/pipeline/index.html","hash":"03f68396752829dd3b7e074e67aaccb6f6babdb7","modified":1573237486802},{"_id":"public/tags/docker/index.html","hash":"517dacace11cfff05205e1148be15640950c4187","modified":1573237486802},{"_id":"public/tags/日志/index.html","hash":"8a0e5983938ea96002b795a44462a329cb4fddb7","modified":1573237486802},{"_id":"public/tags/kube-adm/index.html","hash":"b14b1563083d662902405575a910955bd822477b","modified":1573237486802},{"_id":"public/tags/haproxy/index.html","hash":"112b2d9d0339507a7c175e199ef59baa6360b862","modified":1573237486802},{"_id":"public/tags/nginx/index.html","hash":"28c3114552b63455b9bc53864827397c2bd493a7","modified":1573237486802},{"_id":"public/tags/openresty/index.html","hash":"7f90ad4224215943685f14addea444bb41775df2","modified":1573237486802},{"_id":"public/tags/php/index.html","hash":"e1032ff33a5cf7946c3963a3d4d8eb1e9fffd997","modified":1573237486802},{"_id":"public/tags/laravel/index.html","hash":"8ae209e173d1c154e05a567858bf35df09d72d24","modified":1573237486802},{"_id":"public/tags/linux/index.html","hash":"f9890e0c1ea66336d79c88e1f3b9fc229cfa0349","modified":1573237486802},{"_id":"public/tags/tcp-ip/index.html","hash":"733bd9a0cebcce71dccc82e899e7741086f0b11c","modified":1573237486802},{"_id":"public/tags/监控/index.html","hash":"c477300c256cb7e3303d97bcaadb02fac49d0786","modified":1573237486803},{"_id":"public/2019/11/k8s-migration-1/index.html","hash":"1e894cdd3161faca2fddb015b74e6460bb976be4","modified":1573237486803},{"_id":"public/2019/10/hexo/index.html","hash":"4a6b0bb8ae1fd5532e9bc48cbd91e2f8346f5859","modified":1573237486803},{"_id":"public/2019/10/loki/index.html","hash":"5000215021101f86cab22fe542e864f755b01e3e","modified":1573237486803},{"_id":"public/2019/10/core-dns/index.html","hash":"f6e5e3c2d298269e6d8d0e7f1084f1db3d18aafd","modified":1573237486803},{"_id":"public/2019/10/gitrunner-helm-install/index.html","hash":"a38c18381894e082fc8b61dc76784c55ee2987b1","modified":1573237486803},{"_id":"public/2019/10/helm/index.html","hash":"1a9c795dff1875e5eecc16990b5c2993f870d216","modified":1573237486803},{"_id":"public/2019/02/laravel/index.html","hash":"452e9ee566a09a192a26836df50ccdcf8f11f5fc","modified":1573237486803},{"_id":"public/2019/02/tcp/index.html","hash":"52497b0c68998b539f21c920ce518c8e98b47065","modified":1573237486803},{"_id":"public/2019/02/jenkins-introduction/index.html","hash":"28b9fdc4448838df1f2bb6386895027fc03cfa57","modified":1573237486803},{"_id":"public/2019/02/prometheus/index.html","hash":"4bac7050b7344abe3d8d6ddc4ea36a9179c8ad15","modified":1573237486803},{"_id":"public/2019/02/k8s-notes/index.html","hash":"905007042bc125a39cfc23254656ae58e68338d6","modified":1573237486805},{"_id":"public/2019/01/k8s-introduction/index.html","hash":"9cd36b7e8cd70a2de22c50a479fbb0b5010b09f6","modified":1573237486805},{"_id":"public/index.html","hash":"f38d96dfd371b40f03123effdb541248f938245f","modified":1573237486805},{"_id":"public/page/2/index.html","hash":"efaadbfc4fba59a5c75cd77599713c3c8b5e1631","modified":1573237486805},{"_id":"public/img/grafana/1.png","hash":"6688d162f54a6b31d8a3f58da4a747e2a90b7e0f","modified":1573237486814},{"_id":"public/img/grafana/4.png","hash":"c5767d6d65f0dfa19776c01bf698aa0a7a21144c","modified":1573237486814},{"_id":"public/img/grafana/5.png","hash":"8eafae501beb11d44f1c1cba33ab5d7be7fb436b","modified":1573237486814},{"_id":"public/img/grafana-alerting/2.png","hash":"40bf8a0133c93d206d3f3d3615d9fce997f0ed3f","modified":1573237486814},{"_id":"public/img/grafana-alerting/3.png","hash":"7445b32c9bc421331dde0efa8eedf8928e5a24b6","modified":1573237486814},{"_id":"public/img/grafana-alerting/5.png","hash":"f3e7ace9feb0d40d49022dd26de062de5f240ffd","modified":1573237486814},{"_id":"public/img/grafana-alerting/7.png","hash":"875de873a9eb3b938eaf719dbf96fabcf32fb9a1","modified":1573237486815},{"_id":"public/img/grafana-alerting/6.png","hash":"27515ce8d5f065a40d1139d270941477d5c43045","modified":1573237486815},{"_id":"public/img/k8s/4.png","hash":"a8ac198596f6cbc2b176f60a3af8ef770ba74986","modified":1573237486815},{"_id":"public/img/grafana-alerting/4.png","hash":"8e7beab20bf3c2df3e52e45a63e10b4fbac8d750","modified":1573237486815},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1573237486815},{"_id":"public/img/loki/logo.png","hash":"d3a1ff513556c5bb1c144b9e7caa96d71acb594b","modified":1573237486815},{"_id":"public/img/loki/3.png","hash":"a853262492ce9cf76df0e0fcad9212c07f712430","modified":1573237486815},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1573237486815},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1573237486815},{"_id":"public/img/k8s/3.jpg","hash":"04222abe2ac1cb68bd21655780e275b94d4b7bb9","modified":1573237486815},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1573237486815},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1573237486815},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1573237486815},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1573237486816},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1573237486816},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1573237486816},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1573237486816},{"_id":"public/img/grafana/3.png","hash":"5226ddfc672c157931a1a64d014978105f3e23a1","modified":1573237487278},{"_id":"public/img/grafana/2.png","hash":"ffb7d6e0ca4bdbf08813b7fdccd7d90089528aee","modified":1573237487279},{"_id":"public/img/k8s/1.png","hash":"aaef20704f36c5cd855b30ffdb370925642b4404","modified":1573237487279},{"_id":"public/img/grafana-alerting/8.png","hash":"d5b36c2709a622f0b7e3be5be8aa06dfe2b1fb93","modified":1573237487279},{"_id":"public/img/k8s/2.png","hash":"a0cc8e0bc5608f991b98602237ed12b4757e56f2","modified":1573237487280},{"_id":"public/img/k8s/6.png","hash":"88cc3026320b900ac1280757e90b8ac9d08504b4","modified":1573237487280},{"_id":"public/img/loki/2.png","hash":"4f40694f5dc0eaf9f4e8df1d2f9b6e2a6fd041b9","modified":1573237487280},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1573237487281},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1573237487318},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1573237487318},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1573237487318},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1573237487318},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1573237487318},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1573237487318},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1573237487318},{"_id":"public/css/style.css","hash":"fffb3966bf36057a325498aba9ce3a2ea7bd79e1","modified":1573237487318},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1573237487318},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1573237487318},{"_id":"public/img/k8s/5.svg","hash":"d1411cded83856552f37911eb4522d9887ca4e83","modified":1573237487319},{"_id":"public/css/images/banner.jpg","hash":"e86656f9a24e0d0849aff08aa6490a717e6e1f8d","modified":1573237487319},{"_id":"public/img/grafana/2.bak.png","hash":"5dded09e9b81014954c28c39cd6bfe326e730fce","modified":1573237487324},{"_id":"public/css/images/banner_org.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1573237487324},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1573237487324},{"_id":"public/img/loki/1.png","hash":"1698dc20dd0e4e7fccb7ef63b83209a66d784797","modified":1573237487331},{"_id":"public/img/hexo/1.png","hash":"63f36a8ef225402464c3551ab53f1906cc92cf62","modified":1573237487340}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"helm安装gitrunner","date":"2019-10-16T17:52:10.000Z","share":true,"_content":"\n**gitrunner**\n\n\n```\nhelm repo add gitlab https://charts.gitlab.io\n\nhelm upgrade git-runner-test --install --namespace gitlab \\\n--set checkInterval=2 \\\n--set runners.image=alpine:latest --set runners.imagePullPolicy=if-not-present \\\n--set gitlabUrl=https://gitlab.youhaodongxi.com,runnerRegistrationToken=sDz-pAK6qVpYxixxX1dG --set runners.privileged=true \\\ngitlab/gitlab-runner\n```\n\nmount 目录 : 在configmap.yaml 里 entrypoint 最后增加\n\n```\n    cat >>/home/gitlab-runner/.gitlab-runner/config.toml <<EOF\n      [[runners.kubernetes.volumes.host_path]]\n        name = \"docker\"\n        mount_path = \"/volume\"\n        host_path = \"/volume\"\n\n    EOF\n```\n\n提示没有权限创建job\n```\nERROR: Job failed (system failure): pods is forbidden: User \"system:serviceaccount:gitlab:default\" cannot create resource \"pods\" in API group \"\" in the namespace \"gitlab\"\n```\n\n添加权限绑定\n```\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: gitlab\n  name: gitlab-admin-role\nrules:\n- apiGroups:\n  - '*'\n  resources:\n  - '*'\n  verbs:\n  - '*'\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: gitlab-admin-rolebinding\n  namespace: gitlab\nsubjects:\n- kind: ServiceAccount\n  name: default\n  namespace: gitlab\nroleRef:\n  kind: Role\n  name: gitlab-admin-role\n  apiGroup: rbac.authorization.k8s.io\n```\n指定命名空间和帐号安装tiller，建议开启tls认证\n```\nhelm init --tiller-namespace php-sht --service-account=admin\n```\n\n#跳过fetch \n\n```\ndeploy_all:\n  variables:\n    GIT_STRATEGY: none\n    GIT_CHECKOUT: \"false\"\n  stage: deploy\n```","source":"_posts/gitrunner-helm-install.md","raw":"---\ntitle: \"helm安装gitrunner\"\ndate: 2019-10-16 17:52:10\ntags: [gitrunner,helm]\nshare: true\n---\n\n**gitrunner**\n\n\n```\nhelm repo add gitlab https://charts.gitlab.io\n\nhelm upgrade git-runner-test --install --namespace gitlab \\\n--set checkInterval=2 \\\n--set runners.image=alpine:latest --set runners.imagePullPolicy=if-not-present \\\n--set gitlabUrl=https://gitlab.youhaodongxi.com,runnerRegistrationToken=sDz-pAK6qVpYxixxX1dG --set runners.privileged=true \\\ngitlab/gitlab-runner\n```\n\nmount 目录 : 在configmap.yaml 里 entrypoint 最后增加\n\n```\n    cat >>/home/gitlab-runner/.gitlab-runner/config.toml <<EOF\n      [[runners.kubernetes.volumes.host_path]]\n        name = \"docker\"\n        mount_path = \"/volume\"\n        host_path = \"/volume\"\n\n    EOF\n```\n\n提示没有权限创建job\n```\nERROR: Job failed (system failure): pods is forbidden: User \"system:serviceaccount:gitlab:default\" cannot create resource \"pods\" in API group \"\" in the namespace \"gitlab\"\n```\n\n添加权限绑定\n```\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: gitlab\n  name: gitlab-admin-role\nrules:\n- apiGroups:\n  - '*'\n  resources:\n  - '*'\n  verbs:\n  - '*'\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: gitlab-admin-rolebinding\n  namespace: gitlab\nsubjects:\n- kind: ServiceAccount\n  name: default\n  namespace: gitlab\nroleRef:\n  kind: Role\n  name: gitlab-admin-role\n  apiGroup: rbac.authorization.k8s.io\n```\n指定命名空间和帐号安装tiller，建议开启tls认证\n```\nhelm init --tiller-namespace php-sht --service-account=admin\n```\n\n#跳过fetch \n\n```\ndeploy_all:\n  variables:\n    GIT_STRATEGY: none\n    GIT_CHECKOUT: \"false\"\n  stage: deploy\n```","slug":"gitrunner-helm-install","published":1,"updated":"2019-11-08T17:53:52.508Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck2qgz8uz00003covrle75ryq","content":"<p><strong>gitrunner</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm repo add gitlab https://charts.gitlab.io</span><br><span class=\"line\"></span><br><span class=\"line\">helm upgrade git-runner-test --install --namespace gitlab \\</span><br><span class=\"line\">--set checkInterval=2 \\</span><br><span class=\"line\">--set runners.image=alpine:latest --set runners.imagePullPolicy=if-not-present \\</span><br><span class=\"line\">--set gitlabUrl=https://gitlab.youhaodongxi.com,runnerRegistrationToken=sDz-pAK6qVpYxixxX1dG --set runners.privileged=true \\</span><br><span class=\"line\">gitlab/gitlab-runner</span><br></pre></td></tr></table></figure>\n<p>mount 目录 : 在configmap.yaml 里 entrypoint 最后增加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt;&gt;/home/gitlab-runner/.gitlab-runner/config.toml &lt;&lt;EOF</span><br><span class=\"line\">  [[runners.kubernetes.volumes.host_path]]</span><br><span class=\"line\">    name = &quot;docker&quot;</span><br><span class=\"line\">    mount_path = &quot;/volume&quot;</span><br><span class=\"line\">    host_path = &quot;/volume&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n<p>提示没有权限创建job<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ERROR: Job failed (system failure): pods is forbidden: User &quot;system:serviceaccount:gitlab:default&quot; cannot create resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;gitlab&quot;</span><br></pre></td></tr></table></figure></p>\n<p>添加权限绑定<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">  name: gitlab-admin-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: gitlab-admin-rolebinding</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: default</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: gitlab-admin-role</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure></p>\n<p>指定命名空间和帐号安装tiller，建议开启tls认证<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm init --tiller-namespace php-sht --service-account=admin</span><br></pre></td></tr></table></figure></p>\n<p>#跳过fetch </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy_all:</span><br><span class=\"line\">  variables:</span><br><span class=\"line\">    GIT_STRATEGY: none</span><br><span class=\"line\">    GIT_CHECKOUT: &quot;false&quot;</span><br><span class=\"line\">  stage: deploy</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><strong>gitrunner</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm repo add gitlab https://charts.gitlab.io</span><br><span class=\"line\"></span><br><span class=\"line\">helm upgrade git-runner-test --install --namespace gitlab \\</span><br><span class=\"line\">--set checkInterval=2 \\</span><br><span class=\"line\">--set runners.image=alpine:latest --set runners.imagePullPolicy=if-not-present \\</span><br><span class=\"line\">--set gitlabUrl=https://gitlab.youhaodongxi.com,runnerRegistrationToken=sDz-pAK6qVpYxixxX1dG --set runners.privileged=true \\</span><br><span class=\"line\">gitlab/gitlab-runner</span><br></pre></td></tr></table></figure>\n<p>mount 目录 : 在configmap.yaml 里 entrypoint 最后增加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt;&gt;/home/gitlab-runner/.gitlab-runner/config.toml &lt;&lt;EOF</span><br><span class=\"line\">  [[runners.kubernetes.volumes.host_path]]</span><br><span class=\"line\">    name = &quot;docker&quot;</span><br><span class=\"line\">    mount_path = &quot;/volume&quot;</span><br><span class=\"line\">    host_path = &quot;/volume&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n<p>提示没有权限创建job<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ERROR: Job failed (system failure): pods is forbidden: User &quot;system:serviceaccount:gitlab:default&quot; cannot create resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;gitlab&quot;</span><br></pre></td></tr></table></figure></p>\n<p>添加权限绑定<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">  name: gitlab-admin-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: gitlab-admin-rolebinding</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: default</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: gitlab-admin-role</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure></p>\n<p>指定命名空间和帐号安装tiller，建议开启tls认证<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm init --tiller-namespace php-sht --service-account=admin</span><br></pre></td></tr></table></figure></p>\n<p>#跳过fetch </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy_all:</span><br><span class=\"line\">  variables:</span><br><span class=\"line\">    GIT_STRATEGY: none</span><br><span class=\"line\">    GIT_CHECKOUT: &quot;false&quot;</span><br><span class=\"line\">  stage: deploy</span><br></pre></td></tr></table></figure>"},{"layout":"post","title":"B 树","description":"","date":"2019-02-27T00:00:00.000Z","comments":0,"share":true,"_content":"\ngRPC是一个高性能、通用的开源 RPC 框架，其由 Google 主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers) 序列化协议开发，且支持众多开发语言。 使用 protoc --go_out=. *.proto 把proto文件转成 go 文件，定义格式如下：\n\n```\nmessage HelloRequest {\n  string greeting = 1;\n}\nmessage HelloResponse {\n  string reply = 1;\n}\nservice HelloService {\n  rpc SayHello(HelloRequest) returns (HelloResponse);\n}\n```\n\nhttps://zhuanlan.zhihu.com/p/27700617\n\nB树中每一个内部节点会包含一定数量的键，键将节点的子树分开。例如，如果一个内部节点有3个子节点（子树），那么它就必须有两个键： a1 和 a2 。左边子树的所有值都必须小于 a1 ，中间子树的所有值都必须在 a1 和a2 之间，右边子树的所有值都必须大于 a2 。\n\n规则：\n\n\n（1）所有节点关键字是按递增次序排列，并遵循左小右大原则；\n\n（2）1<子节点数量<=M ，M>=2，空树除外（注：m阶代表一个树节点最多有多少个查找路径，m阶=m路,当m=2则是2叉树,m=3则是3叉）；\n\n（3）非根节点关键字数量大于等于ceil(m/2)-1且小于等于m-1个；（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2)\n\n（4）非叶节点有N个子节点，则该节点的关键字数等于N-1;\n\n（5）所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子\n\nB+ 树特点\n\n\n\n1、相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；\n\n2、B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;\n\n3、B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。\n\n4、B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历。\n\n5、B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。\n","source":"_posts/btree.md","raw":"---\nlayout: post\ntitle: \"B 树\"\ndescription: \"\"\ndate: 2019-02-27\ntags: [b树,数据结构]\ncomments: false\nshare: true\n---\n\ngRPC是一个高性能、通用的开源 RPC 框架，其由 Google 主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers) 序列化协议开发，且支持众多开发语言。 使用 protoc --go_out=. *.proto 把proto文件转成 go 文件，定义格式如下：\n\n```\nmessage HelloRequest {\n  string greeting = 1;\n}\nmessage HelloResponse {\n  string reply = 1;\n}\nservice HelloService {\n  rpc SayHello(HelloRequest) returns (HelloResponse);\n}\n```\n\nhttps://zhuanlan.zhihu.com/p/27700617\n\nB树中每一个内部节点会包含一定数量的键，键将节点的子树分开。例如，如果一个内部节点有3个子节点（子树），那么它就必须有两个键： a1 和 a2 。左边子树的所有值都必须小于 a1 ，中间子树的所有值都必须在 a1 和a2 之间，右边子树的所有值都必须大于 a2 。\n\n规则：\n\n\n（1）所有节点关键字是按递增次序排列，并遵循左小右大原则；\n\n（2）1<子节点数量<=M ，M>=2，空树除外（注：m阶代表一个树节点最多有多少个查找路径，m阶=m路,当m=2则是2叉树,m=3则是3叉）；\n\n（3）非根节点关键字数量大于等于ceil(m/2)-1且小于等于m-1个；（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2)\n\n（4）非叶节点有N个子节点，则该节点的关键字数等于N-1;\n\n（5）所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子\n\nB+ 树特点\n\n\n\n1、相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；\n\n2、B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;\n\n3、B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。\n\n4、B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历。\n\n5、B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。\n","slug":"btree","published":1,"updated":"2019-11-08T17:53:52.508Z","photos":[],"link":"","_id":"ck2qgz8v400013covpl0dsbvf","content":"<p>gRPC是一个高性能、通用的开源 RPC 框架，其由 Google 主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers) 序列化协议开发，且支持众多开发语言。 使用 protoc –go_out=. *.proto 把proto文件转成 go 文件，定义格式如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">message HelloRequest &#123;</span><br><span class=\"line\">  string greeting = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">message HelloResponse &#123;</span><br><span class=\"line\">  string reply = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">service HelloService &#123;</span><br><span class=\"line\">  rpc SayHello(HelloRequest) returns (HelloResponse);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://zhuanlan.zhihu.com/p/27700617\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/27700617</a></p>\n<p>B树中每一个内部节点会包含一定数量的键，键将节点的子树分开。例如，如果一个内部节点有3个子节点（子树），那么它就必须有两个键： a1 和 a2 。左边子树的所有值都必须小于 a1 ，中间子树的所有值都必须在 a1 和a2 之间，右边子树的所有值都必须大于 a2 。</p>\n<p>规则：</p>\n<p>（1）所有节点关键字是按递增次序排列，并遵循左小右大原则；</p>\n<p>（2）1&lt;子节点数量&lt;=M ，M&gt;=2，空树除外（注：m阶代表一个树节点最多有多少个查找路径，m阶=m路,当m=2则是2叉树,m=3则是3叉）；</p>\n<p>（3）非根节点关键字数量大于等于ceil(m/2)-1且小于等于m-1个；（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2)</p>\n<p>（4）非叶节点有N个子节点，则该节点的关键字数等于N-1;</p>\n<p>（5）所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子</p>\n<p>B+ 树特点</p>\n<p>1、相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；</p>\n<p>2、B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;</p>\n<p>3、B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。</p>\n<p>4、B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历。</p>\n<p>5、B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>gRPC是一个高性能、通用的开源 RPC 框架，其由 Google 主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers) 序列化协议开发，且支持众多开发语言。 使用 protoc –go_out=. *.proto 把proto文件转成 go 文件，定义格式如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">message HelloRequest &#123;</span><br><span class=\"line\">  string greeting = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">message HelloResponse &#123;</span><br><span class=\"line\">  string reply = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">service HelloService &#123;</span><br><span class=\"line\">  rpc SayHello(HelloRequest) returns (HelloResponse);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://zhuanlan.zhihu.com/p/27700617\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/27700617</a></p>\n<p>B树中每一个内部节点会包含一定数量的键，键将节点的子树分开。例如，如果一个内部节点有3个子节点（子树），那么它就必须有两个键： a1 和 a2 。左边子树的所有值都必须小于 a1 ，中间子树的所有值都必须在 a1 和a2 之间，右边子树的所有值都必须大于 a2 。</p>\n<p>规则：</p>\n<p>（1）所有节点关键字是按递增次序排列，并遵循左小右大原则；</p>\n<p>（2）1&lt;子节点数量&lt;=M ，M&gt;=2，空树除外（注：m阶代表一个树节点最多有多少个查找路径，m阶=m路,当m=2则是2叉树,m=3则是3叉）；</p>\n<p>（3）非根节点关键字数量大于等于ceil(m/2)-1且小于等于m-1个；（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2)</p>\n<p>（4）非叶节点有N个子节点，则该节点的关键字数等于N-1;</p>\n<p>（5）所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子</p>\n<p>B+ 树特点</p>\n<p>1、相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；</p>\n<p>2、B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;</p>\n<p>3、B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。</p>\n<p>4、B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历。</p>\n<p>5、B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。</p>\n"},{"title":"core-dns使用","date":"2019-10-16T17:58:10.000Z","share":true,"_content":"\n**core-dns-conf 配置**\n```\n. {\n    forward . 8.8.8.8\n    log\n    hosts {\n        10.111.8.170 www.sms.service\n        ttl 60\n        reload 1m\n        fallthrough\n    }\n}\n```\n\n**docker 方式启动**\n```shell\nsudo systemctl stop systemd-resolved\ndocker run -d \\\n    --net=\"host\" \\\n    -v /etc/hosts:/etc/hosts \\\n    -v /etc/resolv.conf:/etc/resolv.conf \\\n    -v /home/runner/work/coredns/core-dns/etc/core-dns-conf:/etc/core-dns-conf \\\n    --name core-dns \\\n    coredns/coredns -conf /etc/core-dns-conf\n```\n\n**使用etcd做服务发现**\n\n```\nhttps://www.cnblogs.com/leffss/p/10148507.html\netcdctl put /coredns/net/nicetuan/t1/a '{\"host\":\"10.111.8.185\",\"ttl\":30}'\n\n$ ETCDCTL_API=3 \n./etcdctl put /skydns/com/example/services/users \\\n'{\"host\": \"192.0.2.10\",\"port \": 20020,\"priority\": 10,\"weight\": 20}'\nOK\n$ ETCDCTL_API=3 \n./etcdctl get /skydns/com/example/services/users\n/skydns/com/example/services/users\n{\"host\": \"192.0.2.10\",\"port\": 20020,\"priority\": 10,\"weight\": 20}\n\n. {\n    etcd {   # 配置启用etcd插件,后面可以指定域名,例如 etcd test.com {\n        stubzones # 启用存根区域功能。 stubzone仅在位于指定的第一个区域下方的etcd树中完成\n        path /coredns # etcd里面的路径 默认为/skydns，以后所有的dns记录就是存储在该存根路径底下\n        endpoint http://172.16.101.209:2379 # etcd访问地址，多个空格分开\n\n        # upstream设置要使用的上游解析程序解决指向外部域名的在etcd（认为CNAME）中找到的外部域名。\n        upstream 8.8.8.8:53 8.8.4.4:53\n\n        fallthrough # 如果区域匹配但不能生成记录，则将请求传递给下一个插件\n        # tls CERT KEY CACERT # 可选参数，etcd认证证书设置\n    }\n    prometheus  :9153 # 监控插件\n    cache 160\n    loadbalance   # 负载均衡，开启DNS记录轮询策略\n    forward . 8.8.8.8:53 8.8.4.4:53 # 上面etcd未查询到的请求转发给设置的DNS服务器解析\n    log # 打印日志\n}\n```\n\n对于传统的DNS服务器（例如BIND），管理员通常将主区域数据作为文件进行管理。 最近，DNS服务器已开始支持从其他来源（例如数据库）加载主区域数据。\n\n```\ndocker run --rm -u $(id -u):$(id -g) -v $PWD:/go golang:1.12 \\\n    /bin/bash -c \\\n    \"git clone https://github.com/coredns/coredns.git && \\\n    cd coredns && \\\n    git checkout v1.5.0\"\n```\n\n","source":"_posts/core-dns.md","raw":"---\ntitle: \"core-dns使用\"\ndate: 2019-10-16 17:58:10\ntags: [coredns,etcd]\nshare: true\n---\n\n**core-dns-conf 配置**\n```\n. {\n    forward . 8.8.8.8\n    log\n    hosts {\n        10.111.8.170 www.sms.service\n        ttl 60\n        reload 1m\n        fallthrough\n    }\n}\n```\n\n**docker 方式启动**\n```shell\nsudo systemctl stop systemd-resolved\ndocker run -d \\\n    --net=\"host\" \\\n    -v /etc/hosts:/etc/hosts \\\n    -v /etc/resolv.conf:/etc/resolv.conf \\\n    -v /home/runner/work/coredns/core-dns/etc/core-dns-conf:/etc/core-dns-conf \\\n    --name core-dns \\\n    coredns/coredns -conf /etc/core-dns-conf\n```\n\n**使用etcd做服务发现**\n\n```\nhttps://www.cnblogs.com/leffss/p/10148507.html\netcdctl put /coredns/net/nicetuan/t1/a '{\"host\":\"10.111.8.185\",\"ttl\":30}'\n\n$ ETCDCTL_API=3 \n./etcdctl put /skydns/com/example/services/users \\\n'{\"host\": \"192.0.2.10\",\"port \": 20020,\"priority\": 10,\"weight\": 20}'\nOK\n$ ETCDCTL_API=3 \n./etcdctl get /skydns/com/example/services/users\n/skydns/com/example/services/users\n{\"host\": \"192.0.2.10\",\"port\": 20020,\"priority\": 10,\"weight\": 20}\n\n. {\n    etcd {   # 配置启用etcd插件,后面可以指定域名,例如 etcd test.com {\n        stubzones # 启用存根区域功能。 stubzone仅在位于指定的第一个区域下方的etcd树中完成\n        path /coredns # etcd里面的路径 默认为/skydns，以后所有的dns记录就是存储在该存根路径底下\n        endpoint http://172.16.101.209:2379 # etcd访问地址，多个空格分开\n\n        # upstream设置要使用的上游解析程序解决指向外部域名的在etcd（认为CNAME）中找到的外部域名。\n        upstream 8.8.8.8:53 8.8.4.4:53\n\n        fallthrough # 如果区域匹配但不能生成记录，则将请求传递给下一个插件\n        # tls CERT KEY CACERT # 可选参数，etcd认证证书设置\n    }\n    prometheus  :9153 # 监控插件\n    cache 160\n    loadbalance   # 负载均衡，开启DNS记录轮询策略\n    forward . 8.8.8.8:53 8.8.4.4:53 # 上面etcd未查询到的请求转发给设置的DNS服务器解析\n    log # 打印日志\n}\n```\n\n对于传统的DNS服务器（例如BIND），管理员通常将主区域数据作为文件进行管理。 最近，DNS服务器已开始支持从其他来源（例如数据库）加载主区域数据。\n\n```\ndocker run --rm -u $(id -u):$(id -g) -v $PWD:/go golang:1.12 \\\n    /bin/bash -c \\\n    \"git clone https://github.com/coredns/coredns.git && \\\n    cd coredns && \\\n    git checkout v1.5.0\"\n```\n\n","slug":"core-dns","published":1,"updated":"2019-11-08T17:53:52.508Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck2qgz8v900033cov8owxrn7s","content":"<p><strong>core-dns-conf 配置</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">. &#123;</span><br><span class=\"line\">    forward . 8.8.8.8</span><br><span class=\"line\">    log</span><br><span class=\"line\">    hosts &#123;</span><br><span class=\"line\">        10.111.8.170 www.sms.service</span><br><span class=\"line\">        ttl 60</span><br><span class=\"line\">        reload 1m</span><br><span class=\"line\">        fallthrough</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>docker 方式启动</strong><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl stop systemd-resolved</span><br><span class=\"line\">docker run -d \\</span><br><span class=\"line\">    --net=\"host\" \\</span><br><span class=\"line\">    -v /etc/hosts:/etc/hosts \\</span><br><span class=\"line\">    -v /etc/resolv.conf:/etc/resolv.conf \\</span><br><span class=\"line\">    -v /home/runner/work/coredns/core-dns/etc/core-dns-conf:/etc/core-dns-conf \\</span><br><span class=\"line\">    --name core-dns \\</span><br><span class=\"line\">    coredns/coredns -conf /etc/core-dns-conf</span><br></pre></td></tr></table></figure></p>\n<p><strong>使用etcd做服务发现</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://www.cnblogs.com/leffss/p/10148507.html</span><br><span class=\"line\">etcdctl put /coredns/net/nicetuan/t1/a &apos;&#123;&quot;host&quot;:&quot;10.111.8.185&quot;,&quot;ttl&quot;:30&#125;&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">$ ETCDCTL_API=3 </span><br><span class=\"line\">./etcdctl put /skydns/com/example/services/users \\</span><br><span class=\"line\">&apos;&#123;&quot;host&quot;: &quot;192.0.2.10&quot;,&quot;port &quot;: 20020,&quot;priority&quot;: 10,&quot;weight&quot;: 20&#125;&apos;</span><br><span class=\"line\">OK</span><br><span class=\"line\">$ ETCDCTL_API=3 </span><br><span class=\"line\">./etcdctl get /skydns/com/example/services/users</span><br><span class=\"line\">/skydns/com/example/services/users</span><br><span class=\"line\">&#123;&quot;host&quot;: &quot;192.0.2.10&quot;,&quot;port&quot;: 20020,&quot;priority&quot;: 10,&quot;weight&quot;: 20&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">. &#123;</span><br><span class=\"line\">    etcd &#123;   # 配置启用etcd插件,后面可以指定域名,例如 etcd test.com &#123;</span><br><span class=\"line\">        stubzones # 启用存根区域功能。 stubzone仅在位于指定的第一个区域下方的etcd树中完成</span><br><span class=\"line\">        path /coredns # etcd里面的路径 默认为/skydns，以后所有的dns记录就是存储在该存根路径底下</span><br><span class=\"line\">        endpoint http://172.16.101.209:2379 # etcd访问地址，多个空格分开</span><br><span class=\"line\"></span><br><span class=\"line\">        # upstream设置要使用的上游解析程序解决指向外部域名的在etcd（认为CNAME）中找到的外部域名。</span><br><span class=\"line\">        upstream 8.8.8.8:53 8.8.4.4:53</span><br><span class=\"line\"></span><br><span class=\"line\">        fallthrough # 如果区域匹配但不能生成记录，则将请求传递给下一个插件</span><br><span class=\"line\">        # tls CERT KEY CACERT # 可选参数，etcd认证证书设置</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    prometheus  :9153 # 监控插件</span><br><span class=\"line\">    cache 160</span><br><span class=\"line\">    loadbalance   # 负载均衡，开启DNS记录轮询策略</span><br><span class=\"line\">    forward . 8.8.8.8:53 8.8.4.4:53 # 上面etcd未查询到的请求转发给设置的DNS服务器解析</span><br><span class=\"line\">    log # 打印日志</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>对于传统的DNS服务器（例如BIND），管理员通常将主区域数据作为文件进行管理。 最近，DNS服务器已开始支持从其他来源（例如数据库）加载主区域数据。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run --rm -u $(id -u):$(id -g) -v $PWD:/go golang:1.12 \\</span><br><span class=\"line\">    /bin/bash -c \\</span><br><span class=\"line\">    &quot;git clone https://github.com/coredns/coredns.git &amp;&amp; \\</span><br><span class=\"line\">    cd coredns &amp;&amp; \\</span><br><span class=\"line\">    git checkout v1.5.0&quot;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>core-dns-conf 配置</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">. &#123;</span><br><span class=\"line\">    forward . 8.8.8.8</span><br><span class=\"line\">    log</span><br><span class=\"line\">    hosts &#123;</span><br><span class=\"line\">        10.111.8.170 www.sms.service</span><br><span class=\"line\">        ttl 60</span><br><span class=\"line\">        reload 1m</span><br><span class=\"line\">        fallthrough</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>docker 方式启动</strong><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl stop systemd-resolved</span><br><span class=\"line\">docker run -d \\</span><br><span class=\"line\">    --net=\"host\" \\</span><br><span class=\"line\">    -v /etc/hosts:/etc/hosts \\</span><br><span class=\"line\">    -v /etc/resolv.conf:/etc/resolv.conf \\</span><br><span class=\"line\">    -v /home/runner/work/coredns/core-dns/etc/core-dns-conf:/etc/core-dns-conf \\</span><br><span class=\"line\">    --name core-dns \\</span><br><span class=\"line\">    coredns/coredns -conf /etc/core-dns-conf</span><br></pre></td></tr></table></figure></p>\n<p><strong>使用etcd做服务发现</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://www.cnblogs.com/leffss/p/10148507.html</span><br><span class=\"line\">etcdctl put /coredns/net/nicetuan/t1/a &apos;&#123;&quot;host&quot;:&quot;10.111.8.185&quot;,&quot;ttl&quot;:30&#125;&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">$ ETCDCTL_API=3 </span><br><span class=\"line\">./etcdctl put /skydns/com/example/services/users \\</span><br><span class=\"line\">&apos;&#123;&quot;host&quot;: &quot;192.0.2.10&quot;,&quot;port &quot;: 20020,&quot;priority&quot;: 10,&quot;weight&quot;: 20&#125;&apos;</span><br><span class=\"line\">OK</span><br><span class=\"line\">$ ETCDCTL_API=3 </span><br><span class=\"line\">./etcdctl get /skydns/com/example/services/users</span><br><span class=\"line\">/skydns/com/example/services/users</span><br><span class=\"line\">&#123;&quot;host&quot;: &quot;192.0.2.10&quot;,&quot;port&quot;: 20020,&quot;priority&quot;: 10,&quot;weight&quot;: 20&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">. &#123;</span><br><span class=\"line\">    etcd &#123;   # 配置启用etcd插件,后面可以指定域名,例如 etcd test.com &#123;</span><br><span class=\"line\">        stubzones # 启用存根区域功能。 stubzone仅在位于指定的第一个区域下方的etcd树中完成</span><br><span class=\"line\">        path /coredns # etcd里面的路径 默认为/skydns，以后所有的dns记录就是存储在该存根路径底下</span><br><span class=\"line\">        endpoint http://172.16.101.209:2379 # etcd访问地址，多个空格分开</span><br><span class=\"line\"></span><br><span class=\"line\">        # upstream设置要使用的上游解析程序解决指向外部域名的在etcd（认为CNAME）中找到的外部域名。</span><br><span class=\"line\">        upstream 8.8.8.8:53 8.8.4.4:53</span><br><span class=\"line\"></span><br><span class=\"line\">        fallthrough # 如果区域匹配但不能生成记录，则将请求传递给下一个插件</span><br><span class=\"line\">        # tls CERT KEY CACERT # 可选参数，etcd认证证书设置</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    prometheus  :9153 # 监控插件</span><br><span class=\"line\">    cache 160</span><br><span class=\"line\">    loadbalance   # 负载均衡，开启DNS记录轮询策略</span><br><span class=\"line\">    forward . 8.8.8.8:53 8.8.4.4:53 # 上面etcd未查询到的请求转发给设置的DNS服务器解析</span><br><span class=\"line\">    log # 打印日志</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>对于传统的DNS服务器（例如BIND），管理员通常将主区域数据作为文件进行管理。 最近，DNS服务器已开始支持从其他来源（例如数据库）加载主区域数据。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run --rm -u $(id -u):$(id -g) -v $PWD:/go golang:1.12 \\</span><br><span class=\"line\">    /bin/bash -c \\</span><br><span class=\"line\">    &quot;git clone https://github.com/coredns/coredns.git &amp;&amp; \\</span><br><span class=\"line\">    cd coredns &amp;&amp; \\</span><br><span class=\"line\">    git checkout v1.5.0&quot;</span><br></pre></td></tr></table></figure>\n"},{"title":"grafana 模板变量配置","date":"2019-10-22T20:23:10.000Z","share":true,"_content":"\n重新安装了日志采集器，生成了所有日志文件的 metrics 统计信息，在 grafana 中显示如图，比较混乱\n\n![1.png](/img/grafana/1.png)\n\nprometheus 中按标签查询结果，显示了该标签有多个查询结果\n\n![2.png](/img/grafana/2.png)\n<!-- more -->\n\n现在按 filename 字段查询当天的日志文件统计信息，在 grafana 面板中创建日期变量，来源选择 prometheus，按正则选出日期变量，最下方显示了产生变量的预览信息：\n\n![3.png](/img/grafana/3.png)\n\n重新编辑面板，按日期变量来过滤数据\n\n![4.png](/img/grafana/4.png)\n\n保存，面版按当前日期显示正常：\n\n![5.png](/img/grafana/5.png)\n\n\n日志监控的配置参考上篇文章: {% post_link loki  使用Loki查询日志%}","source":"_posts/grafana-variables.md","raw":"---\ntitle: \"grafana 模板变量配置\"\ndate: 2019-10-22 20:23:10\ntags: [loki,promtal,grafana]\nshare: true\n---\n\n重新安装了日志采集器，生成了所有日志文件的 metrics 统计信息，在 grafana 中显示如图，比较混乱\n\n![1.png](/img/grafana/1.png)\n\nprometheus 中按标签查询结果，显示了该标签有多个查询结果\n\n![2.png](/img/grafana/2.png)\n<!-- more -->\n\n现在按 filename 字段查询当天的日志文件统计信息，在 grafana 面板中创建日期变量，来源选择 prometheus，按正则选出日期变量，最下方显示了产生变量的预览信息：\n\n![3.png](/img/grafana/3.png)\n\n重新编辑面板，按日期变量来过滤数据\n\n![4.png](/img/grafana/4.png)\n\n保存，面版按当前日期显示正常：\n\n![5.png](/img/grafana/5.png)\n\n\n日志监控的配置参考上篇文章: {% post_link loki  使用Loki查询日志%}","slug":"grafana-variables","published":1,"updated":"2019-11-08T17:53:52.508Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck2qgz8vb00043covmwz1akqh","content":"<p>重新安装了日志采集器，生成了所有日志文件的 metrics 统计信息，在 grafana 中显示如图，比较混乱</p>\n<p><img src=\"/img/grafana/1.png\" alt=\"1.png\"></p>\n<p>prometheus 中按标签查询结果，显示了该标签有多个查询结果</p>\n<p><img src=\"/img/grafana/2.png\" alt=\"2.png\"><br><a id=\"more\"></a></p>\n<p>现在按 filename 字段查询当天的日志文件统计信息，在 grafana 面板中创建日期变量，来源选择 prometheus，按正则选出日期变量，最下方显示了产生变量的预览信息：</p>\n<p><img src=\"/img/grafana/3.png\" alt=\"3.png\"></p>\n<p>重新编辑面板，按日期变量来过滤数据</p>\n<p><img src=\"/img/grafana/4.png\" alt=\"4.png\"></p>\n<p>保存，面版按当前日期显示正常：</p>\n<p><img src=\"/img/grafana/5.png\" alt=\"5.png\"></p>\n<p>日志监控的配置参考上篇文章: <a href=\"/2019/10/loki/\" title=\"使用Loki查询日志\">使用Loki查询日志</a></p>\n","site":{"data":{}},"excerpt":"<p>重新安装了日志采集器，生成了所有日志文件的 metrics 统计信息，在 grafana 中显示如图，比较混乱</p>\n<p><img src=\"/img/grafana/1.png\" alt=\"1.png\"></p>\n<p>prometheus 中按标签查询结果，显示了该标签有多个查询结果</p>\n<p><img src=\"/img/grafana/2.png\" alt=\"2.png\"><br>","more":"</p>\n<p>现在按 filename 字段查询当天的日志文件统计信息，在 grafana 面板中创建日期变量，来源选择 prometheus，按正则选出日期变量，最下方显示了产生变量的预览信息：</p>\n<p><img src=\"/img/grafana/3.png\" alt=\"3.png\"></p>\n<p>重新编辑面板，按日期变量来过滤数据</p>\n<p><img src=\"/img/grafana/4.png\" alt=\"4.png\"></p>\n<p>保存，面版按当前日期显示正常：</p>\n<p><img src=\"/img/grafana/5.png\" alt=\"5.png\"></p>\n<p>日志监控的配置参考上篇文章: <a href=\"/2019/10/loki/\" title=\"使用Loki查询日志\">使用Loki查询日志</a></p>"},{"title":"helm 命令介绍及使用","date":"2019-10-16T17:35:10.000Z","share":true,"_content":"\n**命令**\n\n```\nhelm repo list\nhelm search \nhelm list #列出已经按照项目\nhelm del --purge istio-init #删除\nhelm fetch stable/grafana #下载到本地\nhelm push mysql-0.3.5.tgz myrepo\nhelm repo add  myrepo https://xx.xx.xx.xx/chartrepo/charts #添加仓库\nhelm repo add bitnami https://charts.bitnami.com/bitnami  #添加仓库\n\nhelm list --deleted\nhelm rollback nginx-ingress 1\n\nhelm create hello_test\nhelm package ./hello_test/ #打包\nhelm install ./hello_test-0.1.0.tgz --debug --dry-run #调试\nhelm get manifest #这条命令可以通过 release 名来打印其相关yaml信息\nhelm status wintering-rodent\n\nhelm plugin install https://github.com/chartmuseum/helm-push #安装push插件\nhelm repo add mylibrary http://harbor.local.com:8082/chartrepo/library\nhelm push --username=runner --password=745632Bn hello_test mylibrary\n\nhelm fetch stable/redis\nhelm push redis-8.1.2.tgz -urunner -p745632Bn  mylibrary  -v 0.2.0\n\n\ndocker run -ti --rm --entrypoint /bin/sh alpine/helm:2.9.0\nexport HELM_HOST=10.102.49.77:44134 #修改 tiller 地址 10.111.8.171:44134\nhelm list\nhelm init --client-only\n\nhelm upgrade -f panda.yaml happpy-panda stable/mariadb #更新\nhelm temlate helm/istio -name istio -namespace istio-system -f my-values.yaml > my-isti.yaml #根据模板生成部署清单，不用依赖 tiller 服务端。\nhelm template istio -name istio -f book-values.yaml -namespace istio-system | kubectl apply -f\n\nhelm delete --purge #版本存储在 kube-system 命名空间内的ConfigMaps中\nhelm status \n\nhelm inspect values . #查看charts的配置选项\nhelm inspect values yhdx/community --version 0.2.0\nhelm get values zeroed-gnat -a #查看 release 的配置值\n\nhelm --set a=b,c=d \nhelm --set name={a,b,c} \nhelm --set server[0].port = 80\n\n--timeout\n--wait\n\nhelm init --service-account \nhelm install . --debug --dry-run --set favoriteDrink=tea #set 替换\nhelm install stable/drupal --set image=my-registry/drupal:0.1.0 --set livenessProbe.exec.command=[cat,docroot/CHANGELOG.txt] --set livenessProbe.httpGet=null\nhelm upgrade sanguine-panther --set image1.tag=0.3 --set imagePullPolicy=Always . \nhelm upgrade nginx-ingress -f ingress-nginx.yaml  stable/nginx-ingress\n\n#启动本地 chartmuseum 仓库\ndocker run --rm -itd \\\n  -p 8089:8080 \\\n  -e DEBUG=1 \\\n  -e STORAGE=local \\\n  -e STORAGE_LOCAL_ROOTDIR=/charts \\\n  -v /home/runner/work/k8s/chartmuseum/charts:/charts \\\n --name my_chartmuseum  chartmuseum/chartmuseum:latest\nhelm repo add myChartMuseum http://172.16.101.197:8089\n\nhelm upgrade install --force\n```\n<!-- more -->\n\n**helm Values Files 值来源**\n\n```\n前面讲了内置对像 Values，它的值有四个来源：\n\nvalues.yaml 文件\n如果这是个子 chart，其父 chart 的 Values.yaml 文件\n在 helm install 或 helm upgrade 时，通过 -f 指定的文件\n通过 --set 指定的参数（ 例：helm install --set foo=bar ./mychart）\n```\n\n\n\n**helm template**\n\n```\nRelease：该对象描述了发布本身。它里面有几个对象：\nRelease.Name：发布名称\nRelease.Time：发布的时间\nRelease.Namespace：要释放到的命名空间（如果清单未覆盖）\nRelease.Service：发布服务的名称（始终Tiller）。\nRelease.Revision：此版本的修订号。它从1开始，每个都递增helm upgrade。\nRelease.IsUpgrade：true如果当前操作是升级或回滚，则设置为。\nRelease.IsInstall：true如果当前操作是安装，则设置为。\n\nChart：Chart.yaml文件的内容。这里的任何数据Chart.yaml都可以访问。例如{{.Chart.Name}}-{{.Chart.Version}}将打印出来mychart-0.1.0。\n\"图表指南”中列出了可用字段 #https://github.com/helm/helm/blob/master/docs/charts.md#the-chartyaml-file\n\n.Files.Get config.ini\n\nTemplate：包含有关正在执行的当前模板的信息\nName：当前模板的命名空间文件路径（例如mychart/templates/mytemplate.yaml）\nBasePath：当前图表的templates目录的命名空间路径（例如mychart/templates）。\n\n内置值始终以大写字母开头,本地名称以小写开头\n\ndrink: {{ quote .Values.favorite.drink }} #值加引号\nfood: {{ .Values.favorite.food | upper | quote }} #管道\ndrink: {{ .Values.favorite.drink | default \"tea\" | quote }} #默认值\n\nif/ else用于创建条件块\nwith 指定范围\nrange，它提供了“for each”式循环\n\n{{- if eq .Values.favorite.drink \"coffee\"}}\nmug: true\n{{- end}}\n\n#with\n{{- with .Values.favorite }}\ndrink: {{ .drink | default \"tea\" | quote }}\nfood: {{ .food | upper | quote }}\n{{- end }}\n\n|-YAML中的标记采用多行字符串。这可以是一种有用的技术，用于在清单中嵌入大块数据，ConfgMaps 使用\ntoppings: |-\n    {{- range .Values.pizzaToppings }}\n    - {{ . | title | quote }}\n    {{- end }\ntoppings: |-\n    {{- range $index, $topping := .Values.pizzaToppings }}\n      {{ $index }}: {{ $topping }}\n    {{- end }}\n\n有一个变量始终是全局$变量 - 该变量将始终指向根上下文\n\n\n#模板\n{{/* Generate basic labels */}}\n{{- define \"mychart.labels\" }}\n  labels:\n    generator: helm\n    date: {{ now | htmlDate }}\n{{- end }}\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ .Release.Name }}-configmap\n  {{- template \"mychart.labels\" }}\n  \n当define呈现命名模板（使用）创建时，它将接收template调用传入的范围。在我们的示例中，我们包含了这样的模板：{{- template \"mychart.labels\" }} 没有传入范围，因此在模板中我们无法访问任何内容.应该改为：{{- template \"mychart.labels\" . }}\n\n最好在Helm模板中使用include over template，以便可以更好地处理YAML文档的输出格式。\nlabels:\n    {{- include \"mychart.app\" . | nindent 4 }}\n    \n    \napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ .Release.Name }}-configmap\ndata:\n  {{- $files := .Files }}\n  {{- range list \"config1.toml\" \"config2.toml\" \"config3.toml\" }}\n  {{ . }}: |-\n    {{ $files.Get . }}\n  {{- end }}\n\n#生成 nginx.conf 配置\napiVersion: v1\nkind: Secret\nmetadata:\n  name: {{ .Release.Name }}-secret\ntype: Opaque\ndata:\n  token: |-\n    {{ .Files.Get \"config1.toml\" | b64enc }}\n    \n{{ .Release.Name }} 随机生产的单词\n{{ include \"community.fullname\" . }} 和项目有关的名称\n```\n\n\n\n**tiller**\n\n```\ntiller 可以安两个一个集群内，一个集群外\n```\n\n\n\n**docker 客户端**\n\n```\ndocker run -it -v ~/.kube:/root/.kube dtzar/helm-kubectl\n```\n\n**依赖管理**\n\n-  直接把依赖的 package 放在 charts / 目录中\n- 使用 requirements.yaml 并用 helm dep up foochart 来自动下载以来的packages\n\n\n\nGrafana 安装\n\n```\nhttps://grafana.com/grafana/dashboards/7249\n\nhelm upgrade --install loki loki/loki-stack --namespace monitoring\n\nhelm install  stable/grafana -n grafana --namespace=monitoring\nhelm upgrade grafana  stable/grafana  --set adminPassword=745632Bn123\nhelm upgrade grafana  stable/grafana  --set ingress.enabled=true --set ingress.hosts[0]=grafana.t1.youhaodongxi.com\n```\n\n","source":"_posts/helm.md","raw":"---\ntitle: \"helm 命令介绍及使用\"\ndate: 2019-10-16 17:35:10\ntags: [k8s,helm,charts]\nshare: true\n---\n\n**命令**\n\n```\nhelm repo list\nhelm search \nhelm list #列出已经按照项目\nhelm del --purge istio-init #删除\nhelm fetch stable/grafana #下载到本地\nhelm push mysql-0.3.5.tgz myrepo\nhelm repo add  myrepo https://xx.xx.xx.xx/chartrepo/charts #添加仓库\nhelm repo add bitnami https://charts.bitnami.com/bitnami  #添加仓库\n\nhelm list --deleted\nhelm rollback nginx-ingress 1\n\nhelm create hello_test\nhelm package ./hello_test/ #打包\nhelm install ./hello_test-0.1.0.tgz --debug --dry-run #调试\nhelm get manifest #这条命令可以通过 release 名来打印其相关yaml信息\nhelm status wintering-rodent\n\nhelm plugin install https://github.com/chartmuseum/helm-push #安装push插件\nhelm repo add mylibrary http://harbor.local.com:8082/chartrepo/library\nhelm push --username=runner --password=745632Bn hello_test mylibrary\n\nhelm fetch stable/redis\nhelm push redis-8.1.2.tgz -urunner -p745632Bn  mylibrary  -v 0.2.0\n\n\ndocker run -ti --rm --entrypoint /bin/sh alpine/helm:2.9.0\nexport HELM_HOST=10.102.49.77:44134 #修改 tiller 地址 10.111.8.171:44134\nhelm list\nhelm init --client-only\n\nhelm upgrade -f panda.yaml happpy-panda stable/mariadb #更新\nhelm temlate helm/istio -name istio -namespace istio-system -f my-values.yaml > my-isti.yaml #根据模板生成部署清单，不用依赖 tiller 服务端。\nhelm template istio -name istio -f book-values.yaml -namespace istio-system | kubectl apply -f\n\nhelm delete --purge #版本存储在 kube-system 命名空间内的ConfigMaps中\nhelm status \n\nhelm inspect values . #查看charts的配置选项\nhelm inspect values yhdx/community --version 0.2.0\nhelm get values zeroed-gnat -a #查看 release 的配置值\n\nhelm --set a=b,c=d \nhelm --set name={a,b,c} \nhelm --set server[0].port = 80\n\n--timeout\n--wait\n\nhelm init --service-account \nhelm install . --debug --dry-run --set favoriteDrink=tea #set 替换\nhelm install stable/drupal --set image=my-registry/drupal:0.1.0 --set livenessProbe.exec.command=[cat,docroot/CHANGELOG.txt] --set livenessProbe.httpGet=null\nhelm upgrade sanguine-panther --set image1.tag=0.3 --set imagePullPolicy=Always . \nhelm upgrade nginx-ingress -f ingress-nginx.yaml  stable/nginx-ingress\n\n#启动本地 chartmuseum 仓库\ndocker run --rm -itd \\\n  -p 8089:8080 \\\n  -e DEBUG=1 \\\n  -e STORAGE=local \\\n  -e STORAGE_LOCAL_ROOTDIR=/charts \\\n  -v /home/runner/work/k8s/chartmuseum/charts:/charts \\\n --name my_chartmuseum  chartmuseum/chartmuseum:latest\nhelm repo add myChartMuseum http://172.16.101.197:8089\n\nhelm upgrade install --force\n```\n<!-- more -->\n\n**helm Values Files 值来源**\n\n```\n前面讲了内置对像 Values，它的值有四个来源：\n\nvalues.yaml 文件\n如果这是个子 chart，其父 chart 的 Values.yaml 文件\n在 helm install 或 helm upgrade 时，通过 -f 指定的文件\n通过 --set 指定的参数（ 例：helm install --set foo=bar ./mychart）\n```\n\n\n\n**helm template**\n\n```\nRelease：该对象描述了发布本身。它里面有几个对象：\nRelease.Name：发布名称\nRelease.Time：发布的时间\nRelease.Namespace：要释放到的命名空间（如果清单未覆盖）\nRelease.Service：发布服务的名称（始终Tiller）。\nRelease.Revision：此版本的修订号。它从1开始，每个都递增helm upgrade。\nRelease.IsUpgrade：true如果当前操作是升级或回滚，则设置为。\nRelease.IsInstall：true如果当前操作是安装，则设置为。\n\nChart：Chart.yaml文件的内容。这里的任何数据Chart.yaml都可以访问。例如{{.Chart.Name}}-{{.Chart.Version}}将打印出来mychart-0.1.0。\n\"图表指南”中列出了可用字段 #https://github.com/helm/helm/blob/master/docs/charts.md#the-chartyaml-file\n\n.Files.Get config.ini\n\nTemplate：包含有关正在执行的当前模板的信息\nName：当前模板的命名空间文件路径（例如mychart/templates/mytemplate.yaml）\nBasePath：当前图表的templates目录的命名空间路径（例如mychart/templates）。\n\n内置值始终以大写字母开头,本地名称以小写开头\n\ndrink: {{ quote .Values.favorite.drink }} #值加引号\nfood: {{ .Values.favorite.food | upper | quote }} #管道\ndrink: {{ .Values.favorite.drink | default \"tea\" | quote }} #默认值\n\nif/ else用于创建条件块\nwith 指定范围\nrange，它提供了“for each”式循环\n\n{{- if eq .Values.favorite.drink \"coffee\"}}\nmug: true\n{{- end}}\n\n#with\n{{- with .Values.favorite }}\ndrink: {{ .drink | default \"tea\" | quote }}\nfood: {{ .food | upper | quote }}\n{{- end }}\n\n|-YAML中的标记采用多行字符串。这可以是一种有用的技术，用于在清单中嵌入大块数据，ConfgMaps 使用\ntoppings: |-\n    {{- range .Values.pizzaToppings }}\n    - {{ . | title | quote }}\n    {{- end }\ntoppings: |-\n    {{- range $index, $topping := .Values.pizzaToppings }}\n      {{ $index }}: {{ $topping }}\n    {{- end }}\n\n有一个变量始终是全局$变量 - 该变量将始终指向根上下文\n\n\n#模板\n{{/* Generate basic labels */}}\n{{- define \"mychart.labels\" }}\n  labels:\n    generator: helm\n    date: {{ now | htmlDate }}\n{{- end }}\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ .Release.Name }}-configmap\n  {{- template \"mychart.labels\" }}\n  \n当define呈现命名模板（使用）创建时，它将接收template调用传入的范围。在我们的示例中，我们包含了这样的模板：{{- template \"mychart.labels\" }} 没有传入范围，因此在模板中我们无法访问任何内容.应该改为：{{- template \"mychart.labels\" . }}\n\n最好在Helm模板中使用include over template，以便可以更好地处理YAML文档的输出格式。\nlabels:\n    {{- include \"mychart.app\" . | nindent 4 }}\n    \n    \napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ .Release.Name }}-configmap\ndata:\n  {{- $files := .Files }}\n  {{- range list \"config1.toml\" \"config2.toml\" \"config3.toml\" }}\n  {{ . }}: |-\n    {{ $files.Get . }}\n  {{- end }}\n\n#生成 nginx.conf 配置\napiVersion: v1\nkind: Secret\nmetadata:\n  name: {{ .Release.Name }}-secret\ntype: Opaque\ndata:\n  token: |-\n    {{ .Files.Get \"config1.toml\" | b64enc }}\n    \n{{ .Release.Name }} 随机生产的单词\n{{ include \"community.fullname\" . }} 和项目有关的名称\n```\n\n\n\n**tiller**\n\n```\ntiller 可以安两个一个集群内，一个集群外\n```\n\n\n\n**docker 客户端**\n\n```\ndocker run -it -v ~/.kube:/root/.kube dtzar/helm-kubectl\n```\n\n**依赖管理**\n\n-  直接把依赖的 package 放在 charts / 目录中\n- 使用 requirements.yaml 并用 helm dep up foochart 来自动下载以来的packages\n\n\n\nGrafana 安装\n\n```\nhttps://grafana.com/grafana/dashboards/7249\n\nhelm upgrade --install loki loki/loki-stack --namespace monitoring\n\nhelm install  stable/grafana -n grafana --namespace=monitoring\nhelm upgrade grafana  stable/grafana  --set adminPassword=745632Bn123\nhelm upgrade grafana  stable/grafana  --set ingress.enabled=true --set ingress.hosts[0]=grafana.t1.youhaodongxi.com\n```\n\n","slug":"helm","published":1,"updated":"2019-11-08T17:53:52.508Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck2qgz8vd00053covpdkqhx7i","content":"<p><strong>命令</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm repo list</span><br><span class=\"line\">helm search </span><br><span class=\"line\">helm list #列出已经按照项目</span><br><span class=\"line\">helm del --purge istio-init #删除</span><br><span class=\"line\">helm fetch stable/grafana #下载到本地</span><br><span class=\"line\">helm push mysql-0.3.5.tgz myrepo</span><br><span class=\"line\">helm repo add  myrepo https://xx.xx.xx.xx/chartrepo/charts #添加仓库</span><br><span class=\"line\">helm repo add bitnami https://charts.bitnami.com/bitnami  #添加仓库</span><br><span class=\"line\"></span><br><span class=\"line\">helm list --deleted</span><br><span class=\"line\">helm rollback nginx-ingress 1</span><br><span class=\"line\"></span><br><span class=\"line\">helm create hello_test</span><br><span class=\"line\">helm package ./hello_test/ #打包</span><br><span class=\"line\">helm install ./hello_test-0.1.0.tgz --debug --dry-run #调试</span><br><span class=\"line\">helm get manifest #这条命令可以通过 release 名来打印其相关yaml信息</span><br><span class=\"line\">helm status wintering-rodent</span><br><span class=\"line\"></span><br><span class=\"line\">helm plugin install https://github.com/chartmuseum/helm-push #安装push插件</span><br><span class=\"line\">helm repo add mylibrary http://harbor.local.com:8082/chartrepo/library</span><br><span class=\"line\">helm push --username=runner --password=745632Bn hello_test mylibrary</span><br><span class=\"line\"></span><br><span class=\"line\">helm fetch stable/redis</span><br><span class=\"line\">helm push redis-8.1.2.tgz -urunner -p745632Bn  mylibrary  -v 0.2.0</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">docker run -ti --rm --entrypoint /bin/sh alpine/helm:2.9.0</span><br><span class=\"line\">export HELM_HOST=10.102.49.77:44134 #修改 tiller 地址 10.111.8.171:44134</span><br><span class=\"line\">helm list</span><br><span class=\"line\">helm init --client-only</span><br><span class=\"line\"></span><br><span class=\"line\">helm upgrade -f panda.yaml happpy-panda stable/mariadb #更新</span><br><span class=\"line\">helm temlate helm/istio -name istio -namespace istio-system -f my-values.yaml &gt; my-isti.yaml #根据模板生成部署清单，不用依赖 tiller 服务端。</span><br><span class=\"line\">helm template istio -name istio -f book-values.yaml -namespace istio-system | kubectl apply -f</span><br><span class=\"line\"></span><br><span class=\"line\">helm delete --purge #版本存储在 kube-system 命名空间内的ConfigMaps中</span><br><span class=\"line\">helm status </span><br><span class=\"line\"></span><br><span class=\"line\">helm inspect values . #查看charts的配置选项</span><br><span class=\"line\">helm inspect values yhdx/community --version 0.2.0</span><br><span class=\"line\">helm get values zeroed-gnat -a #查看 release 的配置值</span><br><span class=\"line\"></span><br><span class=\"line\">helm --set a=b,c=d </span><br><span class=\"line\">helm --set name=&#123;a,b,c&#125; </span><br><span class=\"line\">helm --set server[0].port = 80</span><br><span class=\"line\"></span><br><span class=\"line\">--timeout</span><br><span class=\"line\">--wait</span><br><span class=\"line\"></span><br><span class=\"line\">helm init --service-account </span><br><span class=\"line\">helm install . --debug --dry-run --set favoriteDrink=tea #set 替换</span><br><span class=\"line\">helm install stable/drupal --set image=my-registry/drupal:0.1.0 --set livenessProbe.exec.command=[cat,docroot/CHANGELOG.txt] --set livenessProbe.httpGet=null</span><br><span class=\"line\">helm upgrade sanguine-panther --set image1.tag=0.3 --set imagePullPolicy=Always . </span><br><span class=\"line\">helm upgrade nginx-ingress -f ingress-nginx.yaml  stable/nginx-ingress</span><br><span class=\"line\"></span><br><span class=\"line\">#启动本地 chartmuseum 仓库</span><br><span class=\"line\">docker run --rm -itd \\</span><br><span class=\"line\">  -p 8089:8080 \\</span><br><span class=\"line\">  -e DEBUG=1 \\</span><br><span class=\"line\">  -e STORAGE=local \\</span><br><span class=\"line\">  -e STORAGE_LOCAL_ROOTDIR=/charts \\</span><br><span class=\"line\">  -v /home/runner/work/k8s/chartmuseum/charts:/charts \\</span><br><span class=\"line\"> --name my_chartmuseum  chartmuseum/chartmuseum:latest</span><br><span class=\"line\">helm repo add myChartMuseum http://172.16.101.197:8089</span><br><span class=\"line\"></span><br><span class=\"line\">helm upgrade install --force</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<p><strong>helm Values Files 值来源</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">前面讲了内置对像 Values，它的值有四个来源：</span><br><span class=\"line\"></span><br><span class=\"line\">values.yaml 文件</span><br><span class=\"line\">如果这是个子 chart，其父 chart 的 Values.yaml 文件</span><br><span class=\"line\">在 helm install 或 helm upgrade 时，通过 -f 指定的文件</span><br><span class=\"line\">通过 --set 指定的参数（ 例：helm install --set foo=bar ./mychart）</span><br></pre></td></tr></table></figure>\n<p><strong>helm template</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Release：该对象描述了发布本身。它里面有几个对象：</span><br><span class=\"line\">Release.Name：发布名称</span><br><span class=\"line\">Release.Time：发布的时间</span><br><span class=\"line\">Release.Namespace：要释放到的命名空间（如果清单未覆盖）</span><br><span class=\"line\">Release.Service：发布服务的名称（始终Tiller）。</span><br><span class=\"line\">Release.Revision：此版本的修订号。它从1开始，每个都递增helm upgrade。</span><br><span class=\"line\">Release.IsUpgrade：true如果当前操作是升级或回滚，则设置为。</span><br><span class=\"line\">Release.IsInstall：true如果当前操作是安装，则设置为。</span><br><span class=\"line\"></span><br><span class=\"line\">Chart：Chart.yaml文件的内容。这里的任何数据Chart.yaml都可以访问。例如&#123;&#123;.Chart.Name&#125;&#125;-&#123;&#123;.Chart.Version&#125;&#125;将打印出来mychart-0.1.0。</span><br><span class=\"line\">&quot;图表指南”中列出了可用字段 #https://github.com/helm/helm/blob/master/docs/charts.md#the-chartyaml-file</span><br><span class=\"line\"></span><br><span class=\"line\">.Files.Get config.ini</span><br><span class=\"line\"></span><br><span class=\"line\">Template：包含有关正在执行的当前模板的信息</span><br><span class=\"line\">Name：当前模板的命名空间文件路径（例如mychart/templates/mytemplate.yaml）</span><br><span class=\"line\">BasePath：当前图表的templates目录的命名空间路径（例如mychart/templates）。</span><br><span class=\"line\"></span><br><span class=\"line\">内置值始终以大写字母开头,本地名称以小写开头</span><br><span class=\"line\"></span><br><span class=\"line\">drink: &#123;&#123; quote .Values.favorite.drink &#125;&#125; #值加引号</span><br><span class=\"line\">food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; #管道</span><br><span class=\"line\">drink: &#123;&#123; .Values.favorite.drink | default &quot;tea&quot; | quote &#125;&#125; #默认值</span><br><span class=\"line\"></span><br><span class=\"line\">if/ else用于创建条件块</span><br><span class=\"line\">with 指定范围</span><br><span class=\"line\">range，它提供了“for each”式循环</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;&#123;- if eq .Values.favorite.drink &quot;coffee&quot;&#125;&#125;</span><br><span class=\"line\">mug: true</span><br><span class=\"line\">&#123;&#123;- end&#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">#with</span><br><span class=\"line\">&#123;&#123;- with .Values.favorite &#125;&#125;</span><br><span class=\"line\">drink: &#123;&#123; .drink | default &quot;tea&quot; | quote &#125;&#125;</span><br><span class=\"line\">food: &#123;&#123; .food | upper | quote &#125;&#125;</span><br><span class=\"line\">&#123;&#123;- end &#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">|-YAML中的标记采用多行字符串。这可以是一种有用的技术，用于在清单中嵌入大块数据，ConfgMaps 使用</span><br><span class=\"line\">toppings: |-</span><br><span class=\"line\">    &#123;&#123;- range .Values.pizzaToppings &#125;&#125;</span><br><span class=\"line\">    - &#123;&#123; . | title | quote &#125;&#125;</span><br><span class=\"line\">    &#123;&#123;- end &#125;</span><br><span class=\"line\">toppings: |-</span><br><span class=\"line\">    &#123;&#123;- range $index, $topping := .Values.pizzaToppings &#125;&#125;</span><br><span class=\"line\">      &#123;&#123; $index &#125;&#125;: &#123;&#123; $topping &#125;&#125;</span><br><span class=\"line\">    &#123;&#123;- end &#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">有一个变量始终是全局$变量 - 该变量将始终指向根上下文</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#模板</span><br><span class=\"line\">&#123;&#123;/* Generate basic labels */&#125;&#125;</span><br><span class=\"line\">&#123;&#123;- define &quot;mychart.labels&quot; &#125;&#125;</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    generator: helm</span><br><span class=\"line\">    date: &#123;&#123; now | htmlDate &#125;&#125;</span><br><span class=\"line\">&#123;&#123;- end &#125;&#125;</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class=\"line\">  &#123;&#123;- template &quot;mychart.labels&quot; &#125;&#125;</span><br><span class=\"line\">  </span><br><span class=\"line\">当define呈现命名模板（使用）创建时，它将接收template调用传入的范围。在我们的示例中，我们包含了这样的模板：&#123;&#123;- template &quot;mychart.labels&quot; &#125;&#125; 没有传入范围，因此在模板中我们无法访问任何内容.应该改为：&#123;&#123;- template &quot;mychart.labels&quot; . &#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">最好在Helm模板中使用include over template，以便可以更好地处理YAML文档的输出格式。</span><br><span class=\"line\">labels:</span><br><span class=\"line\">    &#123;&#123;- include &quot;mychart.app&quot; . | nindent 4 &#125;&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class=\"line\">data:</span><br><span class=\"line\">  &#123;&#123;- $files := .Files &#125;&#125;</span><br><span class=\"line\">  &#123;&#123;- range list &quot;config1.toml&quot; &quot;config2.toml&quot; &quot;config3.toml&quot; &#125;&#125;</span><br><span class=\"line\">  &#123;&#123; . &#125;&#125;: |-</span><br><span class=\"line\">    &#123;&#123; $files.Get . &#125;&#125;</span><br><span class=\"line\">  &#123;&#123;- end &#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">#生成 nginx.conf 配置</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: &#123;&#123; .Release.Name &#125;&#125;-secret</span><br><span class=\"line\">type: Opaque</span><br><span class=\"line\">data:</span><br><span class=\"line\">  token: |-</span><br><span class=\"line\">    &#123;&#123; .Files.Get &quot;config1.toml&quot; | b64enc &#125;&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">&#123;&#123; .Release.Name &#125;&#125; 随机生产的单词</span><br><span class=\"line\">&#123;&#123; include &quot;community.fullname&quot; . &#125;&#125; 和项目有关的名称</span><br></pre></td></tr></table></figure>\n<p><strong>tiller</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tiller 可以安两个一个集群内，一个集群外</span><br></pre></td></tr></table></figure>\n<p><strong>docker 客户端</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -it -v ~/.kube:/root/.kube dtzar/helm-kubectl</span><br></pre></td></tr></table></figure>\n<p><strong>依赖管理</strong></p>\n<ul>\n<li>直接把依赖的 package 放在 charts / 目录中</li>\n<li>使用 requirements.yaml 并用 helm dep up foochart 来自动下载以来的packages</li>\n</ul>\n<p>Grafana 安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://grafana.com/grafana/dashboards/7249</span><br><span class=\"line\"></span><br><span class=\"line\">helm upgrade --install loki loki/loki-stack --namespace monitoring</span><br><span class=\"line\"></span><br><span class=\"line\">helm install  stable/grafana -n grafana --namespace=monitoring</span><br><span class=\"line\">helm upgrade grafana  stable/grafana  --set adminPassword=745632Bn123</span><br><span class=\"line\">helm upgrade grafana  stable/grafana  --set ingress.enabled=true --set ingress.hosts[0]=grafana.t1.youhaodongxi.com</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p><strong>命令</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">helm repo list</span><br><span class=\"line\">helm search </span><br><span class=\"line\">helm list #列出已经按照项目</span><br><span class=\"line\">helm del --purge istio-init #删除</span><br><span class=\"line\">helm fetch stable/grafana #下载到本地</span><br><span class=\"line\">helm push mysql-0.3.5.tgz myrepo</span><br><span class=\"line\">helm repo add  myrepo https://xx.xx.xx.xx/chartrepo/charts #添加仓库</span><br><span class=\"line\">helm repo add bitnami https://charts.bitnami.com/bitnami  #添加仓库</span><br><span class=\"line\"></span><br><span class=\"line\">helm list --deleted</span><br><span class=\"line\">helm rollback nginx-ingress 1</span><br><span class=\"line\"></span><br><span class=\"line\">helm create hello_test</span><br><span class=\"line\">helm package ./hello_test/ #打包</span><br><span class=\"line\">helm install ./hello_test-0.1.0.tgz --debug --dry-run #调试</span><br><span class=\"line\">helm get manifest #这条命令可以通过 release 名来打印其相关yaml信息</span><br><span class=\"line\">helm status wintering-rodent</span><br><span class=\"line\"></span><br><span class=\"line\">helm plugin install https://github.com/chartmuseum/helm-push #安装push插件</span><br><span class=\"line\">helm repo add mylibrary http://harbor.local.com:8082/chartrepo/library</span><br><span class=\"line\">helm push --username=runner --password=745632Bn hello_test mylibrary</span><br><span class=\"line\"></span><br><span class=\"line\">helm fetch stable/redis</span><br><span class=\"line\">helm push redis-8.1.2.tgz -urunner -p745632Bn  mylibrary  -v 0.2.0</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">docker run -ti --rm --entrypoint /bin/sh alpine/helm:2.9.0</span><br><span class=\"line\">export HELM_HOST=10.102.49.77:44134 #修改 tiller 地址 10.111.8.171:44134</span><br><span class=\"line\">helm list</span><br><span class=\"line\">helm init --client-only</span><br><span class=\"line\"></span><br><span class=\"line\">helm upgrade -f panda.yaml happpy-panda stable/mariadb #更新</span><br><span class=\"line\">helm temlate helm/istio -name istio -namespace istio-system -f my-values.yaml &gt; my-isti.yaml #根据模板生成部署清单，不用依赖 tiller 服务端。</span><br><span class=\"line\">helm template istio -name istio -f book-values.yaml -namespace istio-system | kubectl apply -f</span><br><span class=\"line\"></span><br><span class=\"line\">helm delete --purge #版本存储在 kube-system 命名空间内的ConfigMaps中</span><br><span class=\"line\">helm status </span><br><span class=\"line\"></span><br><span class=\"line\">helm inspect values . #查看charts的配置选项</span><br><span class=\"line\">helm inspect values yhdx/community --version 0.2.0</span><br><span class=\"line\">helm get values zeroed-gnat -a #查看 release 的配置值</span><br><span class=\"line\"></span><br><span class=\"line\">helm --set a=b,c=d </span><br><span class=\"line\">helm --set name=&#123;a,b,c&#125; </span><br><span class=\"line\">helm --set server[0].port = 80</span><br><span class=\"line\"></span><br><span class=\"line\">--timeout</span><br><span class=\"line\">--wait</span><br><span class=\"line\"></span><br><span class=\"line\">helm init --service-account </span><br><span class=\"line\">helm install . --debug --dry-run --set favoriteDrink=tea #set 替换</span><br><span class=\"line\">helm install stable/drupal --set image=my-registry/drupal:0.1.0 --set livenessProbe.exec.command=[cat,docroot/CHANGELOG.txt] --set livenessProbe.httpGet=null</span><br><span class=\"line\">helm upgrade sanguine-panther --set image1.tag=0.3 --set imagePullPolicy=Always . </span><br><span class=\"line\">helm upgrade nginx-ingress -f ingress-nginx.yaml  stable/nginx-ingress</span><br><span class=\"line\"></span><br><span class=\"line\">#启动本地 chartmuseum 仓库</span><br><span class=\"line\">docker run --rm -itd \\</span><br><span class=\"line\">  -p 8089:8080 \\</span><br><span class=\"line\">  -e DEBUG=1 \\</span><br><span class=\"line\">  -e STORAGE=local \\</span><br><span class=\"line\">  -e STORAGE_LOCAL_ROOTDIR=/charts \\</span><br><span class=\"line\">  -v /home/runner/work/k8s/chartmuseum/charts:/charts \\</span><br><span class=\"line\"> --name my_chartmuseum  chartmuseum/chartmuseum:latest</span><br><span class=\"line\">helm repo add myChartMuseum http://172.16.101.197:8089</span><br><span class=\"line\"></span><br><span class=\"line\">helm upgrade install --force</span><br></pre></td></tr></table></figure>","more":"<p><strong>helm Values Files 值来源</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">前面讲了内置对像 Values，它的值有四个来源：</span><br><span class=\"line\"></span><br><span class=\"line\">values.yaml 文件</span><br><span class=\"line\">如果这是个子 chart，其父 chart 的 Values.yaml 文件</span><br><span class=\"line\">在 helm install 或 helm upgrade 时，通过 -f 指定的文件</span><br><span class=\"line\">通过 --set 指定的参数（ 例：helm install --set foo=bar ./mychart）</span><br></pre></td></tr></table></figure>\n<p><strong>helm template</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Release：该对象描述了发布本身。它里面有几个对象：</span><br><span class=\"line\">Release.Name：发布名称</span><br><span class=\"line\">Release.Time：发布的时间</span><br><span class=\"line\">Release.Namespace：要释放到的命名空间（如果清单未覆盖）</span><br><span class=\"line\">Release.Service：发布服务的名称（始终Tiller）。</span><br><span class=\"line\">Release.Revision：此版本的修订号。它从1开始，每个都递增helm upgrade。</span><br><span class=\"line\">Release.IsUpgrade：true如果当前操作是升级或回滚，则设置为。</span><br><span class=\"line\">Release.IsInstall：true如果当前操作是安装，则设置为。</span><br><span class=\"line\"></span><br><span class=\"line\">Chart：Chart.yaml文件的内容。这里的任何数据Chart.yaml都可以访问。例如&#123;&#123;.Chart.Name&#125;&#125;-&#123;&#123;.Chart.Version&#125;&#125;将打印出来mychart-0.1.0。</span><br><span class=\"line\">&quot;图表指南”中列出了可用字段 #https://github.com/helm/helm/blob/master/docs/charts.md#the-chartyaml-file</span><br><span class=\"line\"></span><br><span class=\"line\">.Files.Get config.ini</span><br><span class=\"line\"></span><br><span class=\"line\">Template：包含有关正在执行的当前模板的信息</span><br><span class=\"line\">Name：当前模板的命名空间文件路径（例如mychart/templates/mytemplate.yaml）</span><br><span class=\"line\">BasePath：当前图表的templates目录的命名空间路径（例如mychart/templates）。</span><br><span class=\"line\"></span><br><span class=\"line\">内置值始终以大写字母开头,本地名称以小写开头</span><br><span class=\"line\"></span><br><span class=\"line\">drink: &#123;&#123; quote .Values.favorite.drink &#125;&#125; #值加引号</span><br><span class=\"line\">food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; #管道</span><br><span class=\"line\">drink: &#123;&#123; .Values.favorite.drink | default &quot;tea&quot; | quote &#125;&#125; #默认值</span><br><span class=\"line\"></span><br><span class=\"line\">if/ else用于创建条件块</span><br><span class=\"line\">with 指定范围</span><br><span class=\"line\">range，它提供了“for each”式循环</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;&#123;- if eq .Values.favorite.drink &quot;coffee&quot;&#125;&#125;</span><br><span class=\"line\">mug: true</span><br><span class=\"line\">&#123;&#123;- end&#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">#with</span><br><span class=\"line\">&#123;&#123;- with .Values.favorite &#125;&#125;</span><br><span class=\"line\">drink: &#123;&#123; .drink | default &quot;tea&quot; | quote &#125;&#125;</span><br><span class=\"line\">food: &#123;&#123; .food | upper | quote &#125;&#125;</span><br><span class=\"line\">&#123;&#123;- end &#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">|-YAML中的标记采用多行字符串。这可以是一种有用的技术，用于在清单中嵌入大块数据，ConfgMaps 使用</span><br><span class=\"line\">toppings: |-</span><br><span class=\"line\">    &#123;&#123;- range .Values.pizzaToppings &#125;&#125;</span><br><span class=\"line\">    - &#123;&#123; . | title | quote &#125;&#125;</span><br><span class=\"line\">    &#123;&#123;- end &#125;</span><br><span class=\"line\">toppings: |-</span><br><span class=\"line\">    &#123;&#123;- range $index, $topping := .Values.pizzaToppings &#125;&#125;</span><br><span class=\"line\">      &#123;&#123; $index &#125;&#125;: &#123;&#123; $topping &#125;&#125;</span><br><span class=\"line\">    &#123;&#123;- end &#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">有一个变量始终是全局$变量 - 该变量将始终指向根上下文</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#模板</span><br><span class=\"line\">&#123;&#123;/* Generate basic labels */&#125;&#125;</span><br><span class=\"line\">&#123;&#123;- define &quot;mychart.labels&quot; &#125;&#125;</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    generator: helm</span><br><span class=\"line\">    date: &#123;&#123; now | htmlDate &#125;&#125;</span><br><span class=\"line\">&#123;&#123;- end &#125;&#125;</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class=\"line\">  &#123;&#123;- template &quot;mychart.labels&quot; &#125;&#125;</span><br><span class=\"line\">  </span><br><span class=\"line\">当define呈现命名模板（使用）创建时，它将接收template调用传入的范围。在我们的示例中，我们包含了这样的模板：&#123;&#123;- template &quot;mychart.labels&quot; &#125;&#125; 没有传入范围，因此在模板中我们无法访问任何内容.应该改为：&#123;&#123;- template &quot;mychart.labels&quot; . &#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">最好在Helm模板中使用include over template，以便可以更好地处理YAML文档的输出格式。</span><br><span class=\"line\">labels:</span><br><span class=\"line\">    &#123;&#123;- include &quot;mychart.app&quot; . | nindent 4 &#125;&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class=\"line\">data:</span><br><span class=\"line\">  &#123;&#123;- $files := .Files &#125;&#125;</span><br><span class=\"line\">  &#123;&#123;- range list &quot;config1.toml&quot; &quot;config2.toml&quot; &quot;config3.toml&quot; &#125;&#125;</span><br><span class=\"line\">  &#123;&#123; . &#125;&#125;: |-</span><br><span class=\"line\">    &#123;&#123; $files.Get . &#125;&#125;</span><br><span class=\"line\">  &#123;&#123;- end &#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">#生成 nginx.conf 配置</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: &#123;&#123; .Release.Name &#125;&#125;-secret</span><br><span class=\"line\">type: Opaque</span><br><span class=\"line\">data:</span><br><span class=\"line\">  token: |-</span><br><span class=\"line\">    &#123;&#123; .Files.Get &quot;config1.toml&quot; | b64enc &#125;&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">&#123;&#123; .Release.Name &#125;&#125; 随机生产的单词</span><br><span class=\"line\">&#123;&#123; include &quot;community.fullname&quot; . &#125;&#125; 和项目有关的名称</span><br></pre></td></tr></table></figure>\n<p><strong>tiller</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tiller 可以安两个一个集群内，一个集群外</span><br></pre></td></tr></table></figure>\n<p><strong>docker 客户端</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -it -v ~/.kube:/root/.kube dtzar/helm-kubectl</span><br></pre></td></tr></table></figure>\n<p><strong>依赖管理</strong></p>\n<ul>\n<li>直接把依赖的 package 放在 charts / 目录中</li>\n<li>使用 requirements.yaml 并用 helm dep up foochart 来自动下载以来的packages</li>\n</ul>\n<p>Grafana 安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://grafana.com/grafana/dashboards/7249</span><br><span class=\"line\"></span><br><span class=\"line\">helm upgrade --install loki loki/loki-stack --namespace monitoring</span><br><span class=\"line\"></span><br><span class=\"line\">helm install  stable/grafana -n grafana --namespace=monitoring</span><br><span class=\"line\">helm upgrade grafana  stable/grafana  --set adminPassword=745632Bn123</span><br><span class=\"line\">helm upgrade grafana  stable/grafana  --set ingress.enabled=true --set ingress.hosts[0]=grafana.t1.youhaodongxi.com</span><br></pre></td></tr></table></figure>"},{"title":"grafana alerting 报警","date":"2019-10-16T17:20:01.000Z","share":true,"_content":"\n使用工具：[prometheus](https://github.com/prometheus/prometheus)、[grafana](https://github.com/grafana/grafana)、[prometheus_client_php](https://github.com/endclothing/prometheus_client_php)\n\n通过 prometheus-php-client 客户端暴露监控元信息，如下表示 order_notify 队列长度为90\n```\n# HELP payment_queue_length it sets\n# TYPE payment_queue_length gauge\npayment_queue_length{name=\"order_notify\"} 90\n```\n\n被 prometheus 采集\n![2](/img/grafana-alerting/2.png)\n<!-- more -->\n\n配置邮件报警规则(间隔5分钟发送一次)\n![8](/img/grafana-alerting/8.png)\n\n配置报警策略,关联邮件报警规则(每30m秒检查一次,报警触发后延迟1分钟后再通知)\n![7](/img/grafana-alerting/7.png)\n\n在grafana中展示（图中设置了值超过100的报警规则）\n![3](/img/grafana-alerting/3.png)\n\n手动修改队列长度为120,触发报警\n![4](/img/grafana-alerting/4.png)\n\n收到报警邮件\n![5](/img/grafana-alerting/5.png)\n\n解除报警\n![6](/img/grafana-alerting/6.png)","source":"_posts/grafana-alerting.md","raw":"---\ntitle: \"grafana alerting 报警\"\ndate: 2019-10-16 17:20:01\ntags: [grafana,prometheus,报警]\nshare: true\n---\n\n使用工具：[prometheus](https://github.com/prometheus/prometheus)、[grafana](https://github.com/grafana/grafana)、[prometheus_client_php](https://github.com/endclothing/prometheus_client_php)\n\n通过 prometheus-php-client 客户端暴露监控元信息，如下表示 order_notify 队列长度为90\n```\n# HELP payment_queue_length it sets\n# TYPE payment_queue_length gauge\npayment_queue_length{name=\"order_notify\"} 90\n```\n\n被 prometheus 采集\n![2](/img/grafana-alerting/2.png)\n<!-- more -->\n\n配置邮件报警规则(间隔5分钟发送一次)\n![8](/img/grafana-alerting/8.png)\n\n配置报警策略,关联邮件报警规则(每30m秒检查一次,报警触发后延迟1分钟后再通知)\n![7](/img/grafana-alerting/7.png)\n\n在grafana中展示（图中设置了值超过100的报警规则）\n![3](/img/grafana-alerting/3.png)\n\n手动修改队列长度为120,触发报警\n![4](/img/grafana-alerting/4.png)\n\n收到报警邮件\n![5](/img/grafana-alerting/5.png)\n\n解除报警\n![6](/img/grafana-alerting/6.png)","slug":"grafana-alerting","published":1,"updated":"2019-11-08T17:53:52.508Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck2qgz8vf00073cov85ocpqql","content":"<p>使用工具：<a href=\"https://github.com/prometheus/prometheus\" target=\"_blank\" rel=\"noopener\">prometheus</a>、<a href=\"https://github.com/grafana/grafana\" target=\"_blank\" rel=\"noopener\">grafana</a>、<a href=\"https://github.com/endclothing/prometheus_client_php\" target=\"_blank\" rel=\"noopener\">prometheus_client_php</a></p>\n<p>通过 prometheus-php-client 客户端暴露监控元信息，如下表示 order_notify 队列长度为90<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># HELP payment_queue_length it sets</span><br><span class=\"line\"># TYPE payment_queue_length gauge</span><br><span class=\"line\">payment_queue_length&#123;name=&quot;order_notify&quot;&#125; 90</span><br></pre></td></tr></table></figure></p>\n<p>被 prometheus 采集<br><img src=\"/img/grafana-alerting/2.png\" alt=\"2\"><br><a id=\"more\"></a></p>\n<p>配置邮件报警规则(间隔5分钟发送一次)<br><img src=\"/img/grafana-alerting/8.png\" alt=\"8\"></p>\n<p>配置报警策略,关联邮件报警规则(每30m秒检查一次,报警触发后延迟1分钟后再通知)<br><img src=\"/img/grafana-alerting/7.png\" alt=\"7\"></p>\n<p>在grafana中展示（图中设置了值超过100的报警规则）<br><img src=\"/img/grafana-alerting/3.png\" alt=\"3\"></p>\n<p>手动修改队列长度为120,触发报警<br><img src=\"/img/grafana-alerting/4.png\" alt=\"4\"></p>\n<p>收到报警邮件<br><img src=\"/img/grafana-alerting/5.png\" alt=\"5\"></p>\n<p>解除报警<br><img src=\"/img/grafana-alerting/6.png\" alt=\"6\"></p>\n","site":{"data":{}},"excerpt":"<p>使用工具：<a href=\"https://github.com/prometheus/prometheus\" target=\"_blank\" rel=\"noopener\">prometheus</a>、<a href=\"https://github.com/grafana/grafana\" target=\"_blank\" rel=\"noopener\">grafana</a>、<a href=\"https://github.com/endclothing/prometheus_client_php\" target=\"_blank\" rel=\"noopener\">prometheus_client_php</a></p>\n<p>通过 prometheus-php-client 客户端暴露监控元信息，如下表示 order_notify 队列长度为90<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># HELP payment_queue_length it sets</span><br><span class=\"line\"># TYPE payment_queue_length gauge</span><br><span class=\"line\">payment_queue_length&#123;name=&quot;order_notify&quot;&#125; 90</span><br></pre></td></tr></table></figure></p>\n<p>被 prometheus 采集<br><img src=\"/img/grafana-alerting/2.png\" alt=\"2\"><br>","more":"</p>\n<p>配置邮件报警规则(间隔5分钟发送一次)<br><img src=\"/img/grafana-alerting/8.png\" alt=\"8\"></p>\n<p>配置报警策略,关联邮件报警规则(每30m秒检查一次,报警触发后延迟1分钟后再通知)<br><img src=\"/img/grafana-alerting/7.png\" alt=\"7\"></p>\n<p>在grafana中展示（图中设置了值超过100的报警规则）<br><img src=\"/img/grafana-alerting/3.png\" alt=\"3\"></p>\n<p>手动修改队列长度为120,触发报警<br><img src=\"/img/grafana-alerting/4.png\" alt=\"4\"></p>\n<p>收到报警邮件<br><img src=\"/img/grafana-alerting/5.png\" alt=\"5\"></p>\n<p>解除报警<br><img src=\"/img/grafana-alerting/6.png\" alt=\"6\"></p>"},{"title":"使用hexo管理博客","date":"2019-10-23T16:09:10.000Z","share":true,"_content":"\n下载 hexo 镜像\n```sh\ndocker pull neofelhz/hexo-docker\n```\n\n启动镜像并映射本地目录\n\n```\ndocker run -itd \\\n    -v /home/runner/work/www/blog:/www/blog \\\n    -w=\"/www/blog\" \\\n    -p 4000:4000 \\\n    --name hexo-test \\\n    neofelhz/hexo-docker \\\n    /bin/sh\n```\n\n进入容器\n\n```\ndocker exec -it hexo-test /bin/sh\n```\n\n执行 `hexo init`，初始化时间较长，应该和网络有关\n\n```\n/www/blog # hexo init \nINFO  Cloning hexo-starter to /www/blog\nCloning into '/www/blog'...\nremote: Enumerating objects: 8, done.\nremote: Counting objects: 100% (8/8), done.\nremote: Compressing objects: 100% (8/8), done.\nremote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 131\nReceiving objects: 100% (139/139), 25.72 KiB | 21.00 KiB/s, done.\nResolving deltas: 100% (64/64), done.\nSubmodule 'themes/landscape' (https://github.com/hexojs/hexo-theme-landscape.git) registered for path 'themes/landscape'\nCloning into '/www/blog/themes/landscape'...\n......\n[3/4] Linking dependencies...\n[4/4] Building fresh packages...\nsuccess Saved lockfile.\nwarning Your current version of Yarn is out of date. The latest version is \"1.19.1\" while you're on \"1.3.2\".\ninfo To upgrade, run the following command:\n$ curl -o- -L https://yarnpkg.com/install.sh | bash\nDone in 112.25s.\nINFO  Start blogging with Hexo!\n```\n<!-- more -->`\n\n初始化完成生成目录如下：\n\n```\n/www/blog/source/_posts # ls -la\ntotal 132\ndrwxr-xr-x   6 runner runner  4096 10月 23 14:33 .\ndrwxr-xr-x  13 runner runner  4096 10月 23 14:15 ..\n-rw-r--r--   1 runner runner  2121 10月 23 14:18 _config.yml\n-rw-r--r--   1 runner runner 12288 10月 23 14:33 ._config.yml.swp\n-rw-r--r--   1 runner runner    65 10月 23 14:18 .gitignore\ndrwxr-xr-x 273 runner runner 12288 10月 23 14:27 node_modules\n-rw-r--r--   1 runner runner   577 10月 23 14:18 package.json\ndrwxr-xr-x   2 runner runner  4096 10月 23 14:18 scaffolds\ndrwxr-xr-x   3 runner runner  4096 10月 23 14:18 source\ndrwxr-xr-x   3 runner runner  4096 10月 23 14:24 themes\n-rw-r--r--   1 runner runner 76595 10月 23 14:27 yarn.lock\n\n```\n\n修改` _config.yml` ，title 改为自己的网站标题，拷贝一个新的 md 文件到 `source/_posts`目录\n\n```\n/www/blog/source/_posts # ls\nhello-world.md  microk8.md\n```\n\n执行`hexo s`启动服务:\n\n```\n/www/blog/source # hexo s\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.\n```\n\n访问 `http://localhost:4000`，我们的 markdown 文章就以 html 格式展示出来了\n\n![1.png](/img/hexo/1.png)\n\n\n\n**上传到 github.io **\n\n1.修改_config.yaml，采用 git 方式部署到自己的 github.io\n\n```\ndeploy:\n  type: git\n  repo: https://github.com/airzhe/airzhe.github.io \n```\n\n2.安装 `hexo-deploy-git` 模块，执行:  `npm install hexo-deployer-git --save`，之后执行 `hexo` 如果报错 `ERROR Local hexo not found *** `, 删除 `node_modules` 目录后，执行 `npm install`\n\n3.执行 `hexo clean && hexo deploy` 按提示配置 git-confg 信息后重试，输入 git 帐号和密码，部署成功！\n\n\n\n**小技巧**:\n\n1.文章注释信息定义：\n\n```\n---\ntitle: \"MicroK8s\"\ndate: 2019-10-23 20:23:10\ntags: [microk8s,k8s]\nshare: true\n---\n```\n\n2.插入图片:  在 source 目录下新建 img 目录，markdown 中以`/img` 为根路径引入对应图片\n\n3.站内链接: {&#37; post_link loki  使用Loki查询日志 &#37;}\n4.更多: `<!-- more -->`\n\n\n\n**文档**\n[hexo中文](https://hexo.io/zh-cn/docs/index.html)\n[hexo特殊符号转义](https://wxnacy.com/2018/01/12/hexo-specific-symbol/)\n\n\n\n**排错**\n\n今天遇到部署时总提示hexo 源码分支指向master分支错误\n\n```\nBranch hexo set up to track remote branch master from https://github.com/airzhe/airzhe.github.io.\n```\n\n或者以下报错，删除 `.deploy_git` 目录，重试解决\n\n```\nError: Spawn failed\n\nat ChildProcess.task.on.code (/www/blog/node_modules/hexo-deployer-git/node_modules/hexo-util/lib/spawn.js:51:21)\n```\n\n参考如下:\n\nhttps://www.cnblogs.com/hushuangpu/p/10316560.html\n\n","source":"_posts/hexo.md","raw":"---\ntitle: \"使用hexo管理博客\"\ndate: 2019-10-23 16:09:10\ntags: [hexo]\nshare: true\n---\n\n下载 hexo 镜像\n```sh\ndocker pull neofelhz/hexo-docker\n```\n\n启动镜像并映射本地目录\n\n```\ndocker run -itd \\\n    -v /home/runner/work/www/blog:/www/blog \\\n    -w=\"/www/blog\" \\\n    -p 4000:4000 \\\n    --name hexo-test \\\n    neofelhz/hexo-docker \\\n    /bin/sh\n```\n\n进入容器\n\n```\ndocker exec -it hexo-test /bin/sh\n```\n\n执行 `hexo init`，初始化时间较长，应该和网络有关\n\n```\n/www/blog # hexo init \nINFO  Cloning hexo-starter to /www/blog\nCloning into '/www/blog'...\nremote: Enumerating objects: 8, done.\nremote: Counting objects: 100% (8/8), done.\nremote: Compressing objects: 100% (8/8), done.\nremote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 131\nReceiving objects: 100% (139/139), 25.72 KiB | 21.00 KiB/s, done.\nResolving deltas: 100% (64/64), done.\nSubmodule 'themes/landscape' (https://github.com/hexojs/hexo-theme-landscape.git) registered for path 'themes/landscape'\nCloning into '/www/blog/themes/landscape'...\n......\n[3/4] Linking dependencies...\n[4/4] Building fresh packages...\nsuccess Saved lockfile.\nwarning Your current version of Yarn is out of date. The latest version is \"1.19.1\" while you're on \"1.3.2\".\ninfo To upgrade, run the following command:\n$ curl -o- -L https://yarnpkg.com/install.sh | bash\nDone in 112.25s.\nINFO  Start blogging with Hexo!\n```\n<!-- more -->`\n\n初始化完成生成目录如下：\n\n```\n/www/blog/source/_posts # ls -la\ntotal 132\ndrwxr-xr-x   6 runner runner  4096 10月 23 14:33 .\ndrwxr-xr-x  13 runner runner  4096 10月 23 14:15 ..\n-rw-r--r--   1 runner runner  2121 10月 23 14:18 _config.yml\n-rw-r--r--   1 runner runner 12288 10月 23 14:33 ._config.yml.swp\n-rw-r--r--   1 runner runner    65 10月 23 14:18 .gitignore\ndrwxr-xr-x 273 runner runner 12288 10月 23 14:27 node_modules\n-rw-r--r--   1 runner runner   577 10月 23 14:18 package.json\ndrwxr-xr-x   2 runner runner  4096 10月 23 14:18 scaffolds\ndrwxr-xr-x   3 runner runner  4096 10月 23 14:18 source\ndrwxr-xr-x   3 runner runner  4096 10月 23 14:24 themes\n-rw-r--r--   1 runner runner 76595 10月 23 14:27 yarn.lock\n\n```\n\n修改` _config.yml` ，title 改为自己的网站标题，拷贝一个新的 md 文件到 `source/_posts`目录\n\n```\n/www/blog/source/_posts # ls\nhello-world.md  microk8.md\n```\n\n执行`hexo s`启动服务:\n\n```\n/www/blog/source # hexo s\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.\n```\n\n访问 `http://localhost:4000`，我们的 markdown 文章就以 html 格式展示出来了\n\n![1.png](/img/hexo/1.png)\n\n\n\n**上传到 github.io **\n\n1.修改_config.yaml，采用 git 方式部署到自己的 github.io\n\n```\ndeploy:\n  type: git\n  repo: https://github.com/airzhe/airzhe.github.io \n```\n\n2.安装 `hexo-deploy-git` 模块，执行:  `npm install hexo-deployer-git --save`，之后执行 `hexo` 如果报错 `ERROR Local hexo not found *** `, 删除 `node_modules` 目录后，执行 `npm install`\n\n3.执行 `hexo clean && hexo deploy` 按提示配置 git-confg 信息后重试，输入 git 帐号和密码，部署成功！\n\n\n\n**小技巧**:\n\n1.文章注释信息定义：\n\n```\n---\ntitle: \"MicroK8s\"\ndate: 2019-10-23 20:23:10\ntags: [microk8s,k8s]\nshare: true\n---\n```\n\n2.插入图片:  在 source 目录下新建 img 目录，markdown 中以`/img` 为根路径引入对应图片\n\n3.站内链接: {&#37; post_link loki  使用Loki查询日志 &#37;}\n4.更多: `<!-- more -->`\n\n\n\n**文档**\n[hexo中文](https://hexo.io/zh-cn/docs/index.html)\n[hexo特殊符号转义](https://wxnacy.com/2018/01/12/hexo-specific-symbol/)\n\n\n\n**排错**\n\n今天遇到部署时总提示hexo 源码分支指向master分支错误\n\n```\nBranch hexo set up to track remote branch master from https://github.com/airzhe/airzhe.github.io.\n```\n\n或者以下报错，删除 `.deploy_git` 目录，重试解决\n\n```\nError: Spawn failed\n\nat ChildProcess.task.on.code (/www/blog/node_modules/hexo-deployer-git/node_modules/hexo-util/lib/spawn.js:51:21)\n```\n\n参考如下:\n\nhttps://www.cnblogs.com/hushuangpu/p/10316560.html\n\n","slug":"hexo","published":1,"updated":"2019-11-08T18:24:36.088Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck2qgz8vg00083covom68sr70","content":"<p>下载 hexo 镜像<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull neofelhz/hexo-docker</span><br></pre></td></tr></table></figure></p>\n<p>启动镜像并映射本地目录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -itd \\</span><br><span class=\"line\">    -v /home/runner/work/www/blog:/www/blog \\</span><br><span class=\"line\">    -w=&quot;/www/blog&quot; \\</span><br><span class=\"line\">    -p 4000:4000 \\</span><br><span class=\"line\">    --name hexo-test \\</span><br><span class=\"line\">    neofelhz/hexo-docker \\</span><br><span class=\"line\">    /bin/sh</span><br></pre></td></tr></table></figure>\n<p>进入容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -it hexo-test /bin/sh</span><br></pre></td></tr></table></figure>\n<p>执行 <code>hexo init</code>，初始化时间较长，应该和网络有关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/www/blog # hexo init </span><br><span class=\"line\">INFO  Cloning hexo-starter to /www/blog</span><br><span class=\"line\">Cloning into &apos;/www/blog&apos;...</span><br><span class=\"line\">remote: Enumerating objects: 8, done.</span><br><span class=\"line\">remote: Counting objects: 100% (8/8), done.</span><br><span class=\"line\">remote: Compressing objects: 100% (8/8), done.</span><br><span class=\"line\">remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 131</span><br><span class=\"line\">Receiving objects: 100% (139/139), 25.72 KiB | 21.00 KiB/s, done.</span><br><span class=\"line\">Resolving deltas: 100% (64/64), done.</span><br><span class=\"line\">Submodule &apos;themes/landscape&apos; (https://github.com/hexojs/hexo-theme-landscape.git) registered for path &apos;themes/landscape&apos;</span><br><span class=\"line\">Cloning into &apos;/www/blog/themes/landscape&apos;...</span><br><span class=\"line\">......</span><br><span class=\"line\">[3/4] Linking dependencies...</span><br><span class=\"line\">[4/4] Building fresh packages...</span><br><span class=\"line\">success Saved lockfile.</span><br><span class=\"line\">warning Your current version of Yarn is out of date. The latest version is &quot;1.19.1&quot; while you&apos;re on &quot;1.3.2&quot;.</span><br><span class=\"line\">info To upgrade, run the following command:</span><br><span class=\"line\">$ curl -o- -L https://yarnpkg.com/install.sh | bash</span><br><span class=\"line\">Done in 112.25s.</span><br><span class=\"line\">INFO  Start blogging with Hexo!</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>`<br><br>初始化完成生成目录如下：<br><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/www/blog/source/_posts # ls -la</span><br><span class=\"line\">total 132</span><br><span class=\"line\">drwxr-xr-x   6 runner runner  4096 10月 23 14:33 .</span><br><span class=\"line\">drwxr-xr-x  13 runner runner  4096 10月 23 14:15 ..</span><br><span class=\"line\">-rw-r--r--   1 runner runner  2121 10月 23 14:18 _config.yml</span><br><span class=\"line\">-rw-r--r--   1 runner runner 12288 10月 23 14:33 ._config.yml.swp</span><br><span class=\"line\">-rw-r--r--   1 runner runner    65 10月 23 14:18 .gitignore</span><br><span class=\"line\">drwxr-xr-x 273 runner runner 12288 10月 23 14:27 node_modules</span><br><span class=\"line\">-rw-r--r--   1 runner runner   577 10月 23 14:18 package.json</span><br><span class=\"line\">drwxr-xr-x   2 runner runner  4096 10月 23 14:18 scaffolds</span><br><span class=\"line\">drwxr-xr-x   3 runner runner  4096 10月 23 14:18 source</span><br><span class=\"line\">drwxr-xr-x   3 runner runner  4096 10月 23 14:24 themes</span><br><span class=\"line\">-rw-r--r--   1 runner runner 76595 10月 23 14:27 yarn.lock</span><br></pre></td></tr></table></figure>\n<p>修改<code>_config.yml</code> ，title 改为自己的网站标题，拷贝一个新的 md 文件到 <code>source/_posts</code>目录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/www/blog/source/_posts # ls</span><br><span class=\"line\">hello-world.md  microk8.md</span><br></pre></td></tr></table></figure>\n<p>执行<code>hexo s</code>启动服务:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/www/blog/source # hexo s</span><br><span class=\"line\">INFO  Start processing</span><br><span class=\"line\">INFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure>\n<p>访问 <code>http://localhost:4000</code>，我们的 markdown 文章就以 html 格式展示出来了</p>\n<p><img src=\"/img/hexo/1.png\" alt=\"1.png\"></p>\n<p><strong>上传到 github.io </strong></p>\n<p>1.修改_config.yaml，采用 git 方式部署到自己的 github.io</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repo: https://github.com/airzhe/airzhe.github.io</span><br></pre></td></tr></table></figure>\n<p>2.安装 <code>hexo-deploy-git</code> 模块，执行:  <code>npm install hexo-deployer-git --save</code>，之后执行 <code>hexo</code> 如果报错 <code>ERROR Local hexo not found ***</code>, 删除 <code>node_modules</code> 目录后，执行 <code>npm install</code></p>\n<p>3.执行 <code>hexo clean &amp;&amp; hexo deploy</code> 按提示配置 git-confg 信息后重试，输入 git 帐号和密码，部署成功！</p>\n<p><strong>小技巧</strong>:</p>\n<p>1.文章注释信息定义：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">title: &quot;MicroK8s&quot;</span><br><span class=\"line\">date: 2019-10-23 20:23:10</span><br><span class=\"line\">tags: [microk8s,k8s]</span><br><span class=\"line\">share: true</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure>\n<p>2.插入图片:  在 source 目录下新建 img 目录，markdown 中以<code>/img</code> 为根路径引入对应图片</p>\n<p>3.站内链接: {&#37; post_link loki  使用Loki查询日志 &#37;}<br>4.更多: <code>&lt;!-- more --&gt;</code></p>\n<p><strong>文档</strong><br><a href=\"https://hexo.io/zh-cn/docs/index.html\" target=\"_blank\" rel=\"noopener\">hexo中文</a><br><a href=\"https://wxnacy.com/2018/01/12/hexo-specific-symbol/\" target=\"_blank\" rel=\"noopener\">hexo特殊符号转义</a></p>\n<p><strong>排错</strong></p>\n<p>今天遇到部署时总提示hexo 源码分支指向master分支错误</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Branch hexo set up to track remote branch master from https://github.com/airzhe/airzhe.github.io.</span><br></pre></td></tr></table></figure>\n<p>或者以下报错，删除 <code>.deploy_git</code> 目录，重试解决</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Error: Spawn failed</span><br><span class=\"line\"></span><br><span class=\"line\">at ChildProcess.task.on.code (/www/blog/node_modules/hexo-deployer-git/node_modules/hexo-util/lib/spawn.js:51:21)</span><br></pre></td></tr></table></figure>\n<p>参考如下:</p>\n<p><a href=\"https://www.cnblogs.com/hushuangpu/p/10316560.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/hushuangpu/p/10316560.html</a></p>\n","site":{"data":{}},"excerpt":"<p>下载 hexo 镜像<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull neofelhz/hexo-docker</span><br></pre></td></tr></table></figure></p>\n<p>启动镜像并映射本地目录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -itd \\</span><br><span class=\"line\">    -v /home/runner/work/www/blog:/www/blog \\</span><br><span class=\"line\">    -w=&quot;/www/blog&quot; \\</span><br><span class=\"line\">    -p 4000:4000 \\</span><br><span class=\"line\">    --name hexo-test \\</span><br><span class=\"line\">    neofelhz/hexo-docker \\</span><br><span class=\"line\">    /bin/sh</span><br></pre></td></tr></table></figure>\n<p>进入容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -it hexo-test /bin/sh</span><br></pre></td></tr></table></figure>\n<p>执行 <code>hexo init</code>，初始化时间较长，应该和网络有关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/www/blog # hexo init </span><br><span class=\"line\">INFO  Cloning hexo-starter to /www/blog</span><br><span class=\"line\">Cloning into &apos;/www/blog&apos;...</span><br><span class=\"line\">remote: Enumerating objects: 8, done.</span><br><span class=\"line\">remote: Counting objects: 100% (8/8), done.</span><br><span class=\"line\">remote: Compressing objects: 100% (8/8), done.</span><br><span class=\"line\">remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 131</span><br><span class=\"line\">Receiving objects: 100% (139/139), 25.72 KiB | 21.00 KiB/s, done.</span><br><span class=\"line\">Resolving deltas: 100% (64/64), done.</span><br><span class=\"line\">Submodule &apos;themes/landscape&apos; (https://github.com/hexojs/hexo-theme-landscape.git) registered for path &apos;themes/landscape&apos;</span><br><span class=\"line\">Cloning into &apos;/www/blog/themes/landscape&apos;...</span><br><span class=\"line\">......</span><br><span class=\"line\">[3/4] Linking dependencies...</span><br><span class=\"line\">[4/4] Building fresh packages...</span><br><span class=\"line\">success Saved lockfile.</span><br><span class=\"line\">warning Your current version of Yarn is out of date. The latest version is &quot;1.19.1&quot; while you&apos;re on &quot;1.3.2&quot;.</span><br><span class=\"line\">info To upgrade, run the following command:</span><br><span class=\"line\">$ curl -o- -L https://yarnpkg.com/install.sh | bash</span><br><span class=\"line\">Done in 112.25s.</span><br><span class=\"line\">INFO  Start blogging with Hexo!</span><br></pre></td></tr></table></figure>","more":"`<br><br>初始化完成生成目录如下：<br><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/www/blog/source/_posts # ls -la</span><br><span class=\"line\">total 132</span><br><span class=\"line\">drwxr-xr-x   6 runner runner  4096 10月 23 14:33 .</span><br><span class=\"line\">drwxr-xr-x  13 runner runner  4096 10月 23 14:15 ..</span><br><span class=\"line\">-rw-r--r--   1 runner runner  2121 10月 23 14:18 _config.yml</span><br><span class=\"line\">-rw-r--r--   1 runner runner 12288 10月 23 14:33 ._config.yml.swp</span><br><span class=\"line\">-rw-r--r--   1 runner runner    65 10月 23 14:18 .gitignore</span><br><span class=\"line\">drwxr-xr-x 273 runner runner 12288 10月 23 14:27 node_modules</span><br><span class=\"line\">-rw-r--r--   1 runner runner   577 10月 23 14:18 package.json</span><br><span class=\"line\">drwxr-xr-x   2 runner runner  4096 10月 23 14:18 scaffolds</span><br><span class=\"line\">drwxr-xr-x   3 runner runner  4096 10月 23 14:18 source</span><br><span class=\"line\">drwxr-xr-x   3 runner runner  4096 10月 23 14:24 themes</span><br><span class=\"line\">-rw-r--r--   1 runner runner 76595 10月 23 14:27 yarn.lock</span><br></pre></td></tr></table></figure>\n<p>修改<code>_config.yml</code> ，title 改为自己的网站标题，拷贝一个新的 md 文件到 <code>source/_posts</code>目录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/www/blog/source/_posts # ls</span><br><span class=\"line\">hello-world.md  microk8.md</span><br></pre></td></tr></table></figure>\n<p>执行<code>hexo s</code>启动服务:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/www/blog/source # hexo s</span><br><span class=\"line\">INFO  Start processing</span><br><span class=\"line\">INFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure>\n<p>访问 <code>http://localhost:4000</code>，我们的 markdown 文章就以 html 格式展示出来了</p>\n<p><img src=\"/img/hexo/1.png\" alt=\"1.png\"></p>\n<p><strong>上传到 github.io </strong></p>\n<p>1.修改_config.yaml，采用 git 方式部署到自己的 github.io</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repo: https://github.com/airzhe/airzhe.github.io</span><br></pre></td></tr></table></figure>\n<p>2.安装 <code>hexo-deploy-git</code> 模块，执行:  <code>npm install hexo-deployer-git --save</code>，之后执行 <code>hexo</code> 如果报错 <code>ERROR Local hexo not found ***</code>, 删除 <code>node_modules</code> 目录后，执行 <code>npm install</code></p>\n<p>3.执行 <code>hexo clean &amp;&amp; hexo deploy</code> 按提示配置 git-confg 信息后重试，输入 git 帐号和密码，部署成功！</p>\n<p><strong>小技巧</strong>:</p>\n<p>1.文章注释信息定义：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">title: &quot;MicroK8s&quot;</span><br><span class=\"line\">date: 2019-10-23 20:23:10</span><br><span class=\"line\">tags: [microk8s,k8s]</span><br><span class=\"line\">share: true</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure>\n<p>2.插入图片:  在 source 目录下新建 img 目录，markdown 中以<code>/img</code> 为根路径引入对应图片</p>\n<p>3.站内链接: {&#37; post_link loki  使用Loki查询日志 &#37;}<br>4.更多: <code>&lt;!-- more --&gt;</code></p>\n<p><strong>文档</strong><br><a href=\"https://hexo.io/zh-cn/docs/index.html\" target=\"_blank\" rel=\"noopener\">hexo中文</a><br><a href=\"https://wxnacy.com/2018/01/12/hexo-specific-symbol/\" target=\"_blank\" rel=\"noopener\">hexo特殊符号转义</a></p>\n<p><strong>排错</strong></p>\n<p>今天遇到部署时总提示hexo 源码分支指向master分支错误</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Branch hexo set up to track remote branch master from https://github.com/airzhe/airzhe.github.io.</span><br></pre></td></tr></table></figure>\n<p>或者以下报错，删除 <code>.deploy_git</code> 目录，重试解决</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Error: Spawn failed</span><br><span class=\"line\"></span><br><span class=\"line\">at ChildProcess.task.on.code (/www/blog/node_modules/hexo-deployer-git/node_modules/hexo-util/lib/spawn.js:51:21)</span><br></pre></td></tr></table></figure>\n<p>参考如下:</p>\n<p><a href=\"https://www.cnblogs.com/hushuangpu/p/10316560.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/hushuangpu/p/10316560.html</a></p>"},{"layout":"post","title":"jenkins pipeline 入门","description":"","date":"2019-02-12T00:00:00.000Z","comments":0,"share":true,"_content":"### Jenkins 特点：\n\n开源免费；\n跨平台，支持所有的平台；\nmaster/slave 支持分布式的 build；\nweb 形式的可视化的管理页面；\n\n\n\n### 安装\n```\ndocker pull jenkins/jenkins:2.138.2\ndocker run -p 9090:8080 -p 50000:50000 -v /User/user/jenkins:/var/jenkins_home jenkins\n\ndocker run --rm --name jenkins -p 9090:8080 -p 50000:50000 --user root -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v /Users/user/jenkins:/var/jenkins_home jenkins/jenkins:2.138.2\n  \n```\n\n### 插件\n\n```\nGo\n\nCloudBees Docker Build and Publish:\n\n```\n\n### 全局工具配置\n\n```\nGo 安装\n安装目录：/var/jenkins_home/go\n```\n\n### 证书\n\n```\n配置访问git证书 SSH Username with private key\nharbor jenkins  密码\n```\n\n\n### 项目配置\n```\n构建环境\nSet up Go programming language tools\n构建：\nDocker Build and Publish\nDocker Host URI 配置 unix:///var/run/docker.sock 或者 tcp://127.0.0.1:2375\n```\n\n\n### Pipeline\n\nPipeline的几个基本概念：\n\n- Stage: 阶段，一个Pipeline可以划分为若干个Stage，每个Stage代表一组操作。注意，Stage是一个逻辑分组的概念，可以跨多个Node。\n- Node: 节点，一个Node就是一个Jenkins节点，或者是Master，或者是Agent，是执行Step的具体运行期环境。\n- Step: 步骤，Step是最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类Jenkins Plugin提供。\n\n```\npipeline {\n    agent { label 'master' }\n    tools {\n       maven 'maven_1'\n    }\n     stages {\n        stage('Build') {\n            steps {\n                checkout([$class: 'GitSCM', branches: [[name: '*/master']], \n                doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], \n                userRemoteConfigs: [[url: 'https://github.com/airzhe/demo-junit']]])\n                sh 'mvn -version'\n                sh 'mvn package -DskipTests'\n            }             \n        }\n        stage('Build docker image') {\n            steps {\n                //sh 'docker login --username airzhe  --password ×××'\n                sh 'docker build -t airzhe/test:${imageversion} .'\n                sh 'docker push airzhe/test:${imageversion}'\n            }             \n        }\n    }\n    post { \n            failure { \n                echo 'fail !'\n            }\n            success{\n                echo 'success !'\n            }\n    }\n}\n```\n\n### 参考\n\ngo 插件安装：  \nhttps://blog.csdn.net/aixiaoyang168/article/details/82965854\n\n","source":"_posts/jenkins-introduction.md","raw":"---\nlayout: post\ntitle: \"jenkins pipeline 入门\"\ndescription: \"\"\ndate: 2019-02-12\ntags: [jenkins,pipeline]\ncomments: false\nshare: true\n---\n### Jenkins 特点：\n\n开源免费；\n跨平台，支持所有的平台；\nmaster/slave 支持分布式的 build；\nweb 形式的可视化的管理页面；\n\n\n\n### 安装\n```\ndocker pull jenkins/jenkins:2.138.2\ndocker run -p 9090:8080 -p 50000:50000 -v /User/user/jenkins:/var/jenkins_home jenkins\n\ndocker run --rm --name jenkins -p 9090:8080 -p 50000:50000 --user root -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v /Users/user/jenkins:/var/jenkins_home jenkins/jenkins:2.138.2\n  \n```\n\n### 插件\n\n```\nGo\n\nCloudBees Docker Build and Publish:\n\n```\n\n### 全局工具配置\n\n```\nGo 安装\n安装目录：/var/jenkins_home/go\n```\n\n### 证书\n\n```\n配置访问git证书 SSH Username with private key\nharbor jenkins  密码\n```\n\n\n### 项目配置\n```\n构建环境\nSet up Go programming language tools\n构建：\nDocker Build and Publish\nDocker Host URI 配置 unix:///var/run/docker.sock 或者 tcp://127.0.0.1:2375\n```\n\n\n### Pipeline\n\nPipeline的几个基本概念：\n\n- Stage: 阶段，一个Pipeline可以划分为若干个Stage，每个Stage代表一组操作。注意，Stage是一个逻辑分组的概念，可以跨多个Node。\n- Node: 节点，一个Node就是一个Jenkins节点，或者是Master，或者是Agent，是执行Step的具体运行期环境。\n- Step: 步骤，Step是最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类Jenkins Plugin提供。\n\n```\npipeline {\n    agent { label 'master' }\n    tools {\n       maven 'maven_1'\n    }\n     stages {\n        stage('Build') {\n            steps {\n                checkout([$class: 'GitSCM', branches: [[name: '*/master']], \n                doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], \n                userRemoteConfigs: [[url: 'https://github.com/airzhe/demo-junit']]])\n                sh 'mvn -version'\n                sh 'mvn package -DskipTests'\n            }             \n        }\n        stage('Build docker image') {\n            steps {\n                //sh 'docker login --username airzhe  --password ×××'\n                sh 'docker build -t airzhe/test:${imageversion} .'\n                sh 'docker push airzhe/test:${imageversion}'\n            }             \n        }\n    }\n    post { \n            failure { \n                echo 'fail !'\n            }\n            success{\n                echo 'success !'\n            }\n    }\n}\n```\n\n### 参考\n\ngo 插件安装：  \nhttps://blog.csdn.net/aixiaoyang168/article/details/82965854\n\n","slug":"jenkins-introduction","published":1,"updated":"2019-11-08T17:53:52.508Z","photos":[],"link":"","_id":"ck2qgz8vi000a3cov9hav0pxs","content":"<h3 id=\"Jenkins-特点：\"><a href=\"#Jenkins-特点：\" class=\"headerlink\" title=\"Jenkins 特点：\"></a>Jenkins 特点：</h3><p>开源免费；<br>跨平台，支持所有的平台；<br>master/slave 支持分布式的 build；<br>web 形式的可视化的管理页面；</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull jenkins/jenkins:2.138.2</span><br><span class=\"line\">docker run -p 9090:8080 -p 50000:50000 -v /User/user/jenkins:/var/jenkins_home jenkins</span><br><span class=\"line\"></span><br><span class=\"line\">docker run --rm --name jenkins -p 9090:8080 -p 50000:50000 --user root -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v /Users/user/jenkins:/var/jenkins_home jenkins/jenkins:2.138.2</span><br></pre></td></tr></table></figure>\n<h3 id=\"插件\"><a href=\"#插件\" class=\"headerlink\" title=\"插件\"></a>插件</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Go</span><br><span class=\"line\"></span><br><span class=\"line\">CloudBees Docker Build and Publish:</span><br></pre></td></tr></table></figure>\n<h3 id=\"全局工具配置\"><a href=\"#全局工具配置\" class=\"headerlink\" title=\"全局工具配置\"></a>全局工具配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Go 安装</span><br><span class=\"line\">安装目录：/var/jenkins_home/go</span><br></pre></td></tr></table></figure>\n<h3 id=\"证书\"><a href=\"#证书\" class=\"headerlink\" title=\"证书\"></a>证书</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">配置访问git证书 SSH Username with private key</span><br><span class=\"line\">harbor jenkins  密码</span><br></pre></td></tr></table></figure>\n<h3 id=\"项目配置\"><a href=\"#项目配置\" class=\"headerlink\" title=\"项目配置\"></a>项目配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">构建环境</span><br><span class=\"line\">Set up Go programming language tools</span><br><span class=\"line\">构建：</span><br><span class=\"line\">Docker Build and Publish</span><br><span class=\"line\">Docker Host URI 配置 unix:///var/run/docker.sock 或者 tcp://127.0.0.1:2375</span><br></pre></td></tr></table></figure>\n<h3 id=\"Pipeline\"><a href=\"#Pipeline\" class=\"headerlink\" title=\"Pipeline\"></a>Pipeline</h3><p>Pipeline的几个基本概念：</p>\n<ul>\n<li>Stage: 阶段，一个Pipeline可以划分为若干个Stage，每个Stage代表一组操作。注意，Stage是一个逻辑分组的概念，可以跨多个Node。</li>\n<li>Node: 节点，一个Node就是一个Jenkins节点，或者是Master，或者是Agent，是执行Step的具体运行期环境。</li>\n<li>Step: 步骤，Step是最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类Jenkins Plugin提供。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pipeline &#123;</span><br><span class=\"line\">    agent &#123; label &apos;master&apos; &#125;</span><br><span class=\"line\">    tools &#123;</span><br><span class=\"line\">       maven &apos;maven_1&apos;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">     stages &#123;</span><br><span class=\"line\">        stage(&apos;Build&apos;) &#123;</span><br><span class=\"line\">            steps &#123;</span><br><span class=\"line\">                checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]], </span><br><span class=\"line\">                doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], </span><br><span class=\"line\">                userRemoteConfigs: [[url: &apos;https://github.com/airzhe/demo-junit&apos;]]])</span><br><span class=\"line\">                sh &apos;mvn -version&apos;</span><br><span class=\"line\">                sh &apos;mvn package -DskipTests&apos;</span><br><span class=\"line\">            &#125;             </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        stage(&apos;Build docker image&apos;) &#123;</span><br><span class=\"line\">            steps &#123;</span><br><span class=\"line\">                //sh &apos;docker login --username airzhe  --password ×××&apos;</span><br><span class=\"line\">                sh &apos;docker build -t airzhe/test:$&#123;imageversion&#125; .&apos;</span><br><span class=\"line\">                sh &apos;docker push airzhe/test:$&#123;imageversion&#125;&apos;</span><br><span class=\"line\">            &#125;             </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    post &#123; </span><br><span class=\"line\">            failure &#123; </span><br><span class=\"line\">                echo &apos;fail !&apos;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            success&#123;</span><br><span class=\"line\">                echo &apos;success !&apos;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><p>go 插件安装：<br><a href=\"https://blog.csdn.net/aixiaoyang168/article/details/82965854\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/aixiaoyang168/article/details/82965854</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Jenkins-特点：\"><a href=\"#Jenkins-特点：\" class=\"headerlink\" title=\"Jenkins 特点：\"></a>Jenkins 特点：</h3><p>开源免费；<br>跨平台，支持所有的平台；<br>master/slave 支持分布式的 build；<br>web 形式的可视化的管理页面；</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull jenkins/jenkins:2.138.2</span><br><span class=\"line\">docker run -p 9090:8080 -p 50000:50000 -v /User/user/jenkins:/var/jenkins_home jenkins</span><br><span class=\"line\"></span><br><span class=\"line\">docker run --rm --name jenkins -p 9090:8080 -p 50000:50000 --user root -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v /Users/user/jenkins:/var/jenkins_home jenkins/jenkins:2.138.2</span><br></pre></td></tr></table></figure>\n<h3 id=\"插件\"><a href=\"#插件\" class=\"headerlink\" title=\"插件\"></a>插件</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Go</span><br><span class=\"line\"></span><br><span class=\"line\">CloudBees Docker Build and Publish:</span><br></pre></td></tr></table></figure>\n<h3 id=\"全局工具配置\"><a href=\"#全局工具配置\" class=\"headerlink\" title=\"全局工具配置\"></a>全局工具配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Go 安装</span><br><span class=\"line\">安装目录：/var/jenkins_home/go</span><br></pre></td></tr></table></figure>\n<h3 id=\"证书\"><a href=\"#证书\" class=\"headerlink\" title=\"证书\"></a>证书</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">配置访问git证书 SSH Username with private key</span><br><span class=\"line\">harbor jenkins  密码</span><br></pre></td></tr></table></figure>\n<h3 id=\"项目配置\"><a href=\"#项目配置\" class=\"headerlink\" title=\"项目配置\"></a>项目配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">构建环境</span><br><span class=\"line\">Set up Go programming language tools</span><br><span class=\"line\">构建：</span><br><span class=\"line\">Docker Build and Publish</span><br><span class=\"line\">Docker Host URI 配置 unix:///var/run/docker.sock 或者 tcp://127.0.0.1:2375</span><br></pre></td></tr></table></figure>\n<h3 id=\"Pipeline\"><a href=\"#Pipeline\" class=\"headerlink\" title=\"Pipeline\"></a>Pipeline</h3><p>Pipeline的几个基本概念：</p>\n<ul>\n<li>Stage: 阶段，一个Pipeline可以划分为若干个Stage，每个Stage代表一组操作。注意，Stage是一个逻辑分组的概念，可以跨多个Node。</li>\n<li>Node: 节点，一个Node就是一个Jenkins节点，或者是Master，或者是Agent，是执行Step的具体运行期环境。</li>\n<li>Step: 步骤，Step是最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类Jenkins Plugin提供。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pipeline &#123;</span><br><span class=\"line\">    agent &#123; label &apos;master&apos; &#125;</span><br><span class=\"line\">    tools &#123;</span><br><span class=\"line\">       maven &apos;maven_1&apos;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">     stages &#123;</span><br><span class=\"line\">        stage(&apos;Build&apos;) &#123;</span><br><span class=\"line\">            steps &#123;</span><br><span class=\"line\">                checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]], </span><br><span class=\"line\">                doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], </span><br><span class=\"line\">                userRemoteConfigs: [[url: &apos;https://github.com/airzhe/demo-junit&apos;]]])</span><br><span class=\"line\">                sh &apos;mvn -version&apos;</span><br><span class=\"line\">                sh &apos;mvn package -DskipTests&apos;</span><br><span class=\"line\">            &#125;             </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        stage(&apos;Build docker image&apos;) &#123;</span><br><span class=\"line\">            steps &#123;</span><br><span class=\"line\">                //sh &apos;docker login --username airzhe  --password ×××&apos;</span><br><span class=\"line\">                sh &apos;docker build -t airzhe/test:$&#123;imageversion&#125; .&apos;</span><br><span class=\"line\">                sh &apos;docker push airzhe/test:$&#123;imageversion&#125;&apos;</span><br><span class=\"line\">            &#125;             </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    post &#123; </span><br><span class=\"line\">            failure &#123; </span><br><span class=\"line\">                echo &apos;fail !&apos;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            success&#123;</span><br><span class=\"line\">                echo &apos;success !&apos;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><p>go 插件安装：<br><a href=\"https://blog.csdn.net/aixiaoyang168/article/details/82965854\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/aixiaoyang168/article/details/82965854</a></p>\n"},{"layout":"post","title":"k8s 介绍","description":"","date":"2019-01-31T00:00:00.000Z","comments":0,"share":true,"_content":"## Kubernetes\n\nKubernetes是一个开源的_用于管理云平台中多个主机上的容器化的应用_Kubernetes的目标是让部署容器化的应用简单并且高效_powerful__Kubernetes提供了应用部署_规划_更新_维护的一种机制\n\n\n## 架构\n![image](/img/k8s/1.png)\n\n\n集群中的机器划分为一个Master 节点和一群工作节点(Node)\n\nMaster 节点，由三个紧密协作的独立组件组合而成，它们分别是负责 API 服务的 **kube-apiserver**、负责调度的 **kube-scheduler**，以及负责容器编排的 **kube-controller-manager**。整个集群的持久化数据，则由 kube-apiserver 处理后保存在 **Ectd** 中。\n\nnode上运行着 kubelet、kube-proxy服务进程，负责pod的创建、启动、监控、重启、销毁、以及实现软件模式的负载均衡器。\n\n在 Kubernetes 项目中，kubelet 主要负责同容器运行时（比如 Docker 项目）打交道，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 **CRI** 接入到 Kubernetes 项目当中。(比如 rkt)\n\n而kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。\n<!-- more -->\n\n#### kubernetes 核心概念\n![image](/img/k8s/2.png)\n\n\n\n## 概念\n\n\n## Namespace\n\nNamespace 通过将系统内部的对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理\n\n**ResourceQuota**\n\nResource Quotas（资源配额，简称quota）是对namespace进行资源配额，限制资源使用的一种策略.\n\n| 字符串                      | API对象                  |\n| ------------------------ | ---------------------- |\n| \"pods\"                   | Pod                    |\n| \"services                | Service                |\n| \"replicationcontrollers\" | ReplicationController  |\n| \"resourcequotas\"         | ResourceQuota          |\n| \"secrets\"                | Secret                 |\n| \"configmaps\"             | ConfigMap              |\n| \"persistentvolumeclaims\" | PersistentVolumeClaim  |\n| \"services.nodeports\"     | NodePort类型的Service     |\n| \"services.loadbalancers\" | LoadBalancer类型的Service |\n\n\n## label\n\nlabel 和 labelSelctor 是 k8s 中的只要分组机制\n\nKubernetes目前支持两种类型的Label Selector：\n\n- 基于等式的Selector（Equality-based）\n- 基于集合的Selector（Set-based）\n\n\n## Pod\n\nPod是k8s的最基本的操作单元，包含一个或多个紧密相关的容器，类似于豌豆荚的概念。\n\n为什么k8s使用Pod在容器之上再封装一层呢？\n\n#### Pod 中几个重要字段的含义和用法\n\n1. NodeSelector： 是一个供用户将 Pod 与 Node 进行绑定的字段\n2. NodeName：一旦 Pod 的这个字段被赋值，Kubernetes 项目就会被认为这个 Pod 已经经过了调度\n3. HostAliases：定义了 Pod 的 hosts\n4. ImagePullPolicy： 的值默认是 Always，即每次创建 Pod 都重新拉取一次镜像，而如果它的值被定义为 Never 或者 IfNotPresent，则意味着 Pod 永远不会主动拉取这个镜像，或者只在宿主机上不存在这个镜像时才拉取。\n5. Lifecycle 字段。它定义的是 Container Lifecycle Hooks 是在容器状态发生变化时触发一系列“钩子。\n\n\n\n#### Pod 具体的创建步骤包括：\n\n![images](/img/k8s/3.jpg)\n\n1. 客户端提交创建请求，可以通过API Server的Restful API，也可以使用kubectl命令行工具。支持的数据类型包括JSON和YAML。\n2. API Server处理用户请求，存储Pod数据到etcd。\n3. 调度器通过API Server查看未绑定的Pod。尝试为Pod分配主机。\n4. 过滤主机 (调度预选)：调度器用一组规则过滤掉不符合要求的主机。比如Pod指定了所需要的资源量，那么可用资源比Pod需要的资源量少的主机会被过滤掉。\n5. 主机打分(调度优选)：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把容一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等。\n6. 选择主机：选择打分最高的主机，进行binding操作，结果存储到etcd中。\n7. kubelet根据调度结果执行Pod创建操作： 绑定成功后，scheduler会调用APIServer的API在etcd中创建一个boundpod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步boundpod信息，一旦发现应该在该工作节点上运行的boundpod对象没有更新，则调用Docker API创建并启动pod内的容器。\n   ​\n\n\nPod模板是pod规范，包含在其他对象中，例如 [Replication Controllers](https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/)，[Jobs](https://kubernetes.io/docs/concepts/jobs/run-to-completion-finite-workloads/)和 [DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)\n\n\npod 也支持host网络的设置，如spec->hostNetwork=true\n\n\n\n**Pause Container**\n\n每个pod 里运行着一个特殊的被称为\nPause 的容器(业务无关且不容易死亡)，其他容器则为业务容器，业务容器共享 Pause 容器的网络栈和Volume挂载卷，创建pod 会自动创建 pause容器。每个pod 都被分配一个唯一的ip地址。\n\n\n可以通过api手动管理pod，也可以委托给控制器来管理pod。\n\n\n\n**Init Container**\n\n在 Pod 中，所有 Init Container 定义的容器，都会比 spec.containers 定义的用户容器先启动。\n\n比如，在我们的这个应用 Pod 中，Tomcat 容器是我们要使用的主容器，而 WAR 包容器的存在，只是为了给它提供一个 WAR 包而已。所以，我们用 Init Container 的方式优先运行 WAR 包容器，扮演了一个 sidecar 的角色\n\n\n\n## Service\n\n一个service 对象拥有如下关键特征\n拥有一个虚拟ip(Cluster ip 、Service ip 或 Vip)和端口号\n\n通过 label selector 筛选关联 pod\n\n创建好service 后集群中其他新创建的pod就可以通过service 的Cluster ip+端口号来连接和访问它了\n\n\n\nspec \ntype=NodePort 和nodePort=30001的两个属性，表明service开启了NodePort方式的外网访问模式\n\nport\ntargetPort 默认与pord 相同\n\n\n\n## API Server\n\nkubernets Api Server 本身也是一个Service，它的名字就是  ”kubernets“.\n\n组件之间的所有操作和通信均由API Server处理的REST API调用.\n\nAPI Server 负责和 /etcd 交互（其他组件不会直接操作 etcd，只有 API Server 这么做），是整个 kubernetes 集群的数据中心，所有的交互都是以 API Server 为核心的。简单来说，API Server 提供了一下的功能：\n\n- 整个集群管理的 API 接口：所有对集群进行的查询和管理都要通过 API 来进行\n- 集群内部各个模块之间通信的枢纽：所有模块之前并不会之间互相调用，而是通过和 API Server 打交道来完成自己那部分的工作\n- 集群安全控制：API Server 提供的验证和授权保证了整个集群的安全\n\n**kubectl客户端**\n\n命令行工具kubectl客户端，通过命令行参数转换为对API Server的REST API调用，并将调用结果输出。\n\n\n\n**kubelet与API Server交互**\n\n每个Node节点上的kubelet定期就会调用API Server的REST接口报告自身状态，API Server接收这些信息后，将节点状态信息更新到etcd中。kubelet也通过API Server的Watch接口监听Pod信息，从而对Node机器上的POD进行管理。\n\n| 监听信息             | kubelet动作          | 备注   |\n| ---------------- | ------------------ | ---- |\n| 新的POD副本被调度绑定到本节点 | 执行POD对应的容器的创建和启动逻辑 | -    |\n| POD对象被删除         | 删除本节点上相应的POD容器     | -    |\n| 修改POD信息          | 修改本节点的POD容器        | -    |\n\n**kube-controller-manager与API Server交互**\n\nkube-controller-manager中的Node Controller模块通过API Server提供的Watch接口，实时监控Node的信息，并做相应处理。\n\n**kube-scheduler与API Server交互**\n\nScheduler通过API Server的Watch接口监听到新建Pod副本的信息后，它会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑。调度成功后将Pod绑定到目标节点上\n\n**Watch API**\n\nWatch API其实就是一种GET请求，只是在query参数里面加了watch。kube-apiserver那边接受到用户的client请求后，可以通过两种方式发送watch event，一种是通过websocket协议发送，另一种就是通过Transfer-Encoding=chunked的方式建立一个长连接，然后发送watch event\n\n\n\n## Controller Manager\n\ncontroller manager是集群内部控制中心，负责集群内的node，pod，服务端点，服务，资源配额，命名空间，服务账号等资源的管理、自动化部署健康监测，异常修复，确保个资源始终处于预期的工作状态。\ncontroller manager 是一个控制器集合包含：rc，node controller，resourcequota controller，namespace conttoller，token \ncontroller，service controller，endpoint controller，serviceaccount controller。\n\n控制器核心工作原理是，每个控制器通过api服务器来查看系统运行状态，并尝试从将系统状态从“现有状态”修正到“期望状态”\n\n\n\n#### k8s RC(Replication Controller)\n\nRC 的定义包含如下几个部分：\npod 期待的副本数\n用于筛选目标pod的 Label Selector\n当pod副本数小于预期时，用于创建新pod的pod模板\n\n Replica Set\n\n官方解释为“下一代的RC”\n唯一区别是Replica Sets支持基于集合的Label selector 而RC 只支持基于等式的\n\nReplica Set 很少单独使用，主要被Deployment 这个更高级的资源对象所使用\n\nReplica Set 和 Deployment 逐步替换了之前RC 的作用\n\n\n\n#### Deployment Controller\n\n扩容:\n\n**使用场景**：\n\n1. 重新调度\n2. 弹性伸缩\n3. 滚动更新\n\n使用场景有以下几个：\n创建Deployment对象来生产对应 Replica Set 并完成 Pod 副本的创建过程\n检查Deployment 的状态来看部署是否完成(pod数量是否达到预期值)\n更新Deployment 以创建新pod 比如镜像升级\n回滚早先 Deployment 版本\n暂停修改 \n查看Deployment的状态，以此作为发布是否成功的指标\n\n\n#### ResourceQuota Controller\n\n目前 k8s 支持 三个层次的资源配额管理\n\n1. 容器级别 ，可以对 cpu ，memory 进行限制\n\n2. Pod 级别，对pod内所有容器进行资源限制\n\n3. Namespace 级别，对Namespace(多租户)级别的资源限制，包括：\n   - pod 数量\n   - service 数量\n   - resourceQuota 数量 等\n\n**Endpoints Controller** 检测到pod的事件，则会更新对应Service 的Endpoints\n\n#### Job Controller && CronJob Controller\n\nJob Controller 控制的对象，直接就是 Pod。\n\n#### DeamonSet controller\n\n\n\n## Scheduler\n\n\nscheduler 的作用是将待调度的 pod（新建的pod，rs为补足副本而创建的pod等）按照待定的调度算法和调度策略绑定（Binding)到集群中的某个合适的Node上，并将绑定信息写入 etcd。\n\n整个过程涉及三个对象：**待调度pod列表**(podQueue)，**可用node列表**，以及**调度算法和调度策略**.\n\n![image](/img/k8s/4.png)\n\n\n1）通过调度算法为待调度Pod列表的每个Pod从Node列表中选择一个最适合的Node，并将信息写入etcd中\n\n2）kubelet通过API Server监听到kubernetes Scheduler产生的Pod绑定信息，然后获取对应的Pod清单，下载Image，并启动容器。\n\n\n\n#### 调度资源监听\n\n`kube-apiserver` 提供了一套 `Watch` 机制给 `kubelet`、`kube-controller-manager`、 `kube-scheduler` 等组件用来监控各种资源(Pod、Node、Service等)的变化，类似于消息中间件里的发布-订阅模式（Push）， `kube-apiserver` 能够**主动通知**这些组件。\n\n\n\n#### 调度节点分配：\n\n调度分为几个部分：首先是过滤掉不满足条件的节点，这个过程称为预选（ predicate）；然后对通过的节点按照优先级排序，这个是优选（ priority）；最后从中选择优先级最高的节点。如果中间任何一步骤有错误，就直接返回错误。\n\npredicate 有一系列的算法可以使用：\n\n- `PodFitsResources`：节点上剩余的资源是否大于 pod 请求的资源\n- `PodFitsHost`：如果 pod 指定了 NodeName，检查节点名称是否和 NodeName 匹配\n- `PodFitsHostPorts`：节点上已经使用的 port 是否和 pod 申请的 port 冲突\n- `PodSelectorMatches`：过滤掉和 pod 指定的 label 不匹配的节点\n- `NoDiskConflict`：已经 mount 的 volume 和 pod 指定的 volume 不冲突，除非它们都是只读\n\n如果在 predicate 过程中没有合适的节点，pod 会一直在 `pending` 状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续 priorities 过程：\n按照优先级大小对节点排序。\n\n优选（ priority)\n\n优先级由一系列键值对组成，键是该优先级项的名称，值是它的权重（该项的重要性）。这些优先级选项包括：\n\n- `LeastRequestedPriority`：通过计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高。换句话说，这个优先级指标倾向于资源使用比例更低的节点\n- `ImageLocalityPriority`：倾向于已经有要使用镜像的节点，镜像总大小值越大，权重越高\n\n通过算法对所有的优先级项目和权重进行计算，得出最终的结果。为待调度的 Pod 分配一个 Node ，同时将分配结果通过 `kube-apiserver` 写入 `etcd`；\n\n\n\n#### 调度策略\n\n**NodeSelector**\n\n`nodeSelector` 是最简单的控制方式。 `nodeSelector` 是 PodSpec 中的一个字段，它指定了键-值对的映射。如果想要 pod 能够运行在某个 node 上，那么这个 node 必须具有所有指定的键-值对的标签（node 也能拥有其它标签）。\n\n列出 node 的时候指定 `--show-labels` 参数就能查看 node 都添加了哪些 label：\n\n\n除了自己定义的 label 之外，kubernetes 还会自动给集群中的节点添加一些 label，比如：\n\n- `kubernetes.io/hostname`：节点的 hostname 名称\n- `beta.kubernetes.io/os`： 节点安装的操作系统\n- `beta.kubernetes.io/arch`：节点的架构类型\n\n除了设置Node Selector之外，还可以通过Node Name 直接指定Node，但还是**建议使用Node Selector**，label进行选择是一种弱绑定，直接指定Node Name是强绑定，Node失效时会导致Pod无法调度。\n\n\n\n**亲和性**特性包含了两种类型的亲和性，”node 亲和性” 和 “pod 间的亲和性/反亲和性”，Pod 间以 pod 标签作为约束。\n\n\n\n**亲和性调度（Affinity）**\n\nNode Affinity\n\n- 硬亲和性：requiredDuringSchedulingIgnoredDuringExecution\n- 软亲和性：preferredDuringSchedulingIgnoredDuringExecution \n   - 如果一个 node 的标签在运行时发生改变，从而导致 pod 的亲和性规则不再被满足时，pod 也仍然会继续运行在 node 上。\n\n\nPod Affinity\n\n- 硬亲和性：requiredDuringSchedulingIgnoredDuringExecution \n- preferredDuringSchedulingIgnoredDuringExecution\n\n**反亲和性（Anti-affinity）**\n\n\n\n**Taint 和 toleration** （比如label idc=idc1,比如GPU资源）\n\n```\n#添加一个 taint\nkubectl taint nodes node1 key=value:NoSchedule\n#这个 taint 的 key 为 key 且 value 为 value，并且这个 taint 的作用是 NoSchedule\n```\n\nPodSpec 指定一个 toleration\n\n```\ntolerations: \n- key: key\n  operator: Exists\n  value: value\n  effect: NoSchedule\n```\n\nPreferNoSchedule （软亲和性）\n\n\n\n## kubelet\n\n在kubernetes集群中，每个Node节点都会启动kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器。kubelet会在API Server上注册节点信息，定期向Master汇报节点资源使用情况，并通过cAdvisor监控容器和节点资源。可以把kubelet理解成【Server-Agent】架构中的agent，是Node上的pod管家。\n\n**容器健康检查**\n\n提供Probe 机制，以更精确的判断Pod和容器：\n**Liveness Prode** ：用于容器的自定义健康检查，如果检查失败，将杀死容器，然后根据pod的重启策略了来决定是否重启容器。还可以指定initialDelaySeconds，用于确定状态检查的宽限期，以便容器执行必要的初始化。\n**Readiness Probe** ：如果检查失败，会将该pod 从服务代理的分发后端去除，不再发送请求给pod。\n\n目前有三种类型检查方式\nHttp 健康检查 ：返回200～399认为成功\nContainer Exec：容器内执行命令，状态0退出，则视为成功\nTcp：如果可以建立连接则认为成功，否则失败。\n\n\n\n**资源上报**\n\n继承 cAdvisor 定时上报节点信息\n\n健康检查监视器由kubelet 代理\n\n\n\n#### kube-proxy\n\nService 在很多情况下知识一个概念，而真正将Service 的作用落实的是背后的 kube-proxy服务进程。\n\n在k8s 集群的每个Node上都会运行一个 kube-proxy 服务进程，可以看作Service 的透明代理兼负载均衡器，核心是讲到某个 service 的访问请求转移到后端的多个pod 实例上。\n\n由于iptables 机制针对的是本都的kube-proxy端口，所以每个Node上都要运行 kube-proxy 组件，这样，在集群内部，我们可以再任意Node上发起对 Service 的访问请求。\n\nkube-proxy  更新iptables 会在本机的 **Iptables** 的NAT表中添加4条规则链路。\n\n1. 从容器中通过 serviceClusterIp 和端口访问Service 的请求\n2. 从主机中通过ServiceClusterIp和端口访问Service的请求\n3. 从容器中通过 Service 的NodePort 端口访问Service的请求\n4. 从主机中通过Service 的NodePort 端口号访问Service的请求\n\n\n运行在每个Node 上的kube-proxy进程其实就是一个智能的软件负载均衡器。\n\n简单的网络代理和负载均衡器，负责Service的实现：实现从Pod到Service，以及NodePort向Service的访问。\n\n采用 iptables 来实现LB\n实现方式：\nkube-proxy 监控服务/端点增删改，对每个服务配置ipitables规则，捕获Service 的ClusterIp 和端口的流量，并将流量重定向到服务的后端之一。默认后端的选择是随机的,可以设置基于客户端ip的会话关联。\n\n默认通过iptables来配置对应的NAT转发，自身不再参与转发过程。\n\n\n\n## yaml配置\n\nDeployment yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        resources:\n           requests:\n             cpu: 0.05\n             memory: 16Mi\n```\n\nService yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-svc\nspec:\n  type: NodePort\n  selector:\n      app: nginx\n  ports:\n      - protocol: TCP\n        port: 8881\n        targetPort: 80\n```\n\n#### 部分命令\n\n```\nkubectl get  all  --all-namespaces=true\nkubectl describe ***\nkubectl get pods -n kube-system\nkubectl apply -f  *.yaml\nkubectl get *** -o yaml\nkubectl edit deployment.apps/nginx-deployment\nkubectl exec ${POD_NAME} -c ${CONTAINER_NAME} -- ${CMD} ${ARG1} ${ARG2} ... ${ARGN}\n```\n\n\n","source":"_posts/k8s-introduction.md","raw":"---\nlayout: post\ntitle: \"k8s 介绍\"\ndescription: \"\"\ndate: 2019-01-31\ntags: [docker,k8s]\ncomments: false\nshare: true\n---\n## Kubernetes\n\nKubernetes是一个开源的_用于管理云平台中多个主机上的容器化的应用_Kubernetes的目标是让部署容器化的应用简单并且高效_powerful__Kubernetes提供了应用部署_规划_更新_维护的一种机制\n\n\n## 架构\n![image](/img/k8s/1.png)\n\n\n集群中的机器划分为一个Master 节点和一群工作节点(Node)\n\nMaster 节点，由三个紧密协作的独立组件组合而成，它们分别是负责 API 服务的 **kube-apiserver**、负责调度的 **kube-scheduler**，以及负责容器编排的 **kube-controller-manager**。整个集群的持久化数据，则由 kube-apiserver 处理后保存在 **Ectd** 中。\n\nnode上运行着 kubelet、kube-proxy服务进程，负责pod的创建、启动、监控、重启、销毁、以及实现软件模式的负载均衡器。\n\n在 Kubernetes 项目中，kubelet 主要负责同容器运行时（比如 Docker 项目）打交道，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 **CRI** 接入到 Kubernetes 项目当中。(比如 rkt)\n\n而kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。\n<!-- more -->\n\n#### kubernetes 核心概念\n![image](/img/k8s/2.png)\n\n\n\n## 概念\n\n\n## Namespace\n\nNamespace 通过将系统内部的对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理\n\n**ResourceQuota**\n\nResource Quotas（资源配额，简称quota）是对namespace进行资源配额，限制资源使用的一种策略.\n\n| 字符串                      | API对象                  |\n| ------------------------ | ---------------------- |\n| \"pods\"                   | Pod                    |\n| \"services                | Service                |\n| \"replicationcontrollers\" | ReplicationController  |\n| \"resourcequotas\"         | ResourceQuota          |\n| \"secrets\"                | Secret                 |\n| \"configmaps\"             | ConfigMap              |\n| \"persistentvolumeclaims\" | PersistentVolumeClaim  |\n| \"services.nodeports\"     | NodePort类型的Service     |\n| \"services.loadbalancers\" | LoadBalancer类型的Service |\n\n\n## label\n\nlabel 和 labelSelctor 是 k8s 中的只要分组机制\n\nKubernetes目前支持两种类型的Label Selector：\n\n- 基于等式的Selector（Equality-based）\n- 基于集合的Selector（Set-based）\n\n\n## Pod\n\nPod是k8s的最基本的操作单元，包含一个或多个紧密相关的容器，类似于豌豆荚的概念。\n\n为什么k8s使用Pod在容器之上再封装一层呢？\n\n#### Pod 中几个重要字段的含义和用法\n\n1. NodeSelector： 是一个供用户将 Pod 与 Node 进行绑定的字段\n2. NodeName：一旦 Pod 的这个字段被赋值，Kubernetes 项目就会被认为这个 Pod 已经经过了调度\n3. HostAliases：定义了 Pod 的 hosts\n4. ImagePullPolicy： 的值默认是 Always，即每次创建 Pod 都重新拉取一次镜像，而如果它的值被定义为 Never 或者 IfNotPresent，则意味着 Pod 永远不会主动拉取这个镜像，或者只在宿主机上不存在这个镜像时才拉取。\n5. Lifecycle 字段。它定义的是 Container Lifecycle Hooks 是在容器状态发生变化时触发一系列“钩子。\n\n\n\n#### Pod 具体的创建步骤包括：\n\n![images](/img/k8s/3.jpg)\n\n1. 客户端提交创建请求，可以通过API Server的Restful API，也可以使用kubectl命令行工具。支持的数据类型包括JSON和YAML。\n2. API Server处理用户请求，存储Pod数据到etcd。\n3. 调度器通过API Server查看未绑定的Pod。尝试为Pod分配主机。\n4. 过滤主机 (调度预选)：调度器用一组规则过滤掉不符合要求的主机。比如Pod指定了所需要的资源量，那么可用资源比Pod需要的资源量少的主机会被过滤掉。\n5. 主机打分(调度优选)：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把容一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等。\n6. 选择主机：选择打分最高的主机，进行binding操作，结果存储到etcd中。\n7. kubelet根据调度结果执行Pod创建操作： 绑定成功后，scheduler会调用APIServer的API在etcd中创建一个boundpod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步boundpod信息，一旦发现应该在该工作节点上运行的boundpod对象没有更新，则调用Docker API创建并启动pod内的容器。\n   ​\n\n\nPod模板是pod规范，包含在其他对象中，例如 [Replication Controllers](https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/)，[Jobs](https://kubernetes.io/docs/concepts/jobs/run-to-completion-finite-workloads/)和 [DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)\n\n\npod 也支持host网络的设置，如spec->hostNetwork=true\n\n\n\n**Pause Container**\n\n每个pod 里运行着一个特殊的被称为\nPause 的容器(业务无关且不容易死亡)，其他容器则为业务容器，业务容器共享 Pause 容器的网络栈和Volume挂载卷，创建pod 会自动创建 pause容器。每个pod 都被分配一个唯一的ip地址。\n\n\n可以通过api手动管理pod，也可以委托给控制器来管理pod。\n\n\n\n**Init Container**\n\n在 Pod 中，所有 Init Container 定义的容器，都会比 spec.containers 定义的用户容器先启动。\n\n比如，在我们的这个应用 Pod 中，Tomcat 容器是我们要使用的主容器，而 WAR 包容器的存在，只是为了给它提供一个 WAR 包而已。所以，我们用 Init Container 的方式优先运行 WAR 包容器，扮演了一个 sidecar 的角色\n\n\n\n## Service\n\n一个service 对象拥有如下关键特征\n拥有一个虚拟ip(Cluster ip 、Service ip 或 Vip)和端口号\n\n通过 label selector 筛选关联 pod\n\n创建好service 后集群中其他新创建的pod就可以通过service 的Cluster ip+端口号来连接和访问它了\n\n\n\nspec \ntype=NodePort 和nodePort=30001的两个属性，表明service开启了NodePort方式的外网访问模式\n\nport\ntargetPort 默认与pord 相同\n\n\n\n## API Server\n\nkubernets Api Server 本身也是一个Service，它的名字就是  ”kubernets“.\n\n组件之间的所有操作和通信均由API Server处理的REST API调用.\n\nAPI Server 负责和 /etcd 交互（其他组件不会直接操作 etcd，只有 API Server 这么做），是整个 kubernetes 集群的数据中心，所有的交互都是以 API Server 为核心的。简单来说，API Server 提供了一下的功能：\n\n- 整个集群管理的 API 接口：所有对集群进行的查询和管理都要通过 API 来进行\n- 集群内部各个模块之间通信的枢纽：所有模块之前并不会之间互相调用，而是通过和 API Server 打交道来完成自己那部分的工作\n- 集群安全控制：API Server 提供的验证和授权保证了整个集群的安全\n\n**kubectl客户端**\n\n命令行工具kubectl客户端，通过命令行参数转换为对API Server的REST API调用，并将调用结果输出。\n\n\n\n**kubelet与API Server交互**\n\n每个Node节点上的kubelet定期就会调用API Server的REST接口报告自身状态，API Server接收这些信息后，将节点状态信息更新到etcd中。kubelet也通过API Server的Watch接口监听Pod信息，从而对Node机器上的POD进行管理。\n\n| 监听信息             | kubelet动作          | 备注   |\n| ---------------- | ------------------ | ---- |\n| 新的POD副本被调度绑定到本节点 | 执行POD对应的容器的创建和启动逻辑 | -    |\n| POD对象被删除         | 删除本节点上相应的POD容器     | -    |\n| 修改POD信息          | 修改本节点的POD容器        | -    |\n\n**kube-controller-manager与API Server交互**\n\nkube-controller-manager中的Node Controller模块通过API Server提供的Watch接口，实时监控Node的信息，并做相应处理。\n\n**kube-scheduler与API Server交互**\n\nScheduler通过API Server的Watch接口监听到新建Pod副本的信息后，它会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑。调度成功后将Pod绑定到目标节点上\n\n**Watch API**\n\nWatch API其实就是一种GET请求，只是在query参数里面加了watch。kube-apiserver那边接受到用户的client请求后，可以通过两种方式发送watch event，一种是通过websocket协议发送，另一种就是通过Transfer-Encoding=chunked的方式建立一个长连接，然后发送watch event\n\n\n\n## Controller Manager\n\ncontroller manager是集群内部控制中心，负责集群内的node，pod，服务端点，服务，资源配额，命名空间，服务账号等资源的管理、自动化部署健康监测，异常修复，确保个资源始终处于预期的工作状态。\ncontroller manager 是一个控制器集合包含：rc，node controller，resourcequota controller，namespace conttoller，token \ncontroller，service controller，endpoint controller，serviceaccount controller。\n\n控制器核心工作原理是，每个控制器通过api服务器来查看系统运行状态，并尝试从将系统状态从“现有状态”修正到“期望状态”\n\n\n\n#### k8s RC(Replication Controller)\n\nRC 的定义包含如下几个部分：\npod 期待的副本数\n用于筛选目标pod的 Label Selector\n当pod副本数小于预期时，用于创建新pod的pod模板\n\n Replica Set\n\n官方解释为“下一代的RC”\n唯一区别是Replica Sets支持基于集合的Label selector 而RC 只支持基于等式的\n\nReplica Set 很少单独使用，主要被Deployment 这个更高级的资源对象所使用\n\nReplica Set 和 Deployment 逐步替换了之前RC 的作用\n\n\n\n#### Deployment Controller\n\n扩容:\n\n**使用场景**：\n\n1. 重新调度\n2. 弹性伸缩\n3. 滚动更新\n\n使用场景有以下几个：\n创建Deployment对象来生产对应 Replica Set 并完成 Pod 副本的创建过程\n检查Deployment 的状态来看部署是否完成(pod数量是否达到预期值)\n更新Deployment 以创建新pod 比如镜像升级\n回滚早先 Deployment 版本\n暂停修改 \n查看Deployment的状态，以此作为发布是否成功的指标\n\n\n#### ResourceQuota Controller\n\n目前 k8s 支持 三个层次的资源配额管理\n\n1. 容器级别 ，可以对 cpu ，memory 进行限制\n\n2. Pod 级别，对pod内所有容器进行资源限制\n\n3. Namespace 级别，对Namespace(多租户)级别的资源限制，包括：\n   - pod 数量\n   - service 数量\n   - resourceQuota 数量 等\n\n**Endpoints Controller** 检测到pod的事件，则会更新对应Service 的Endpoints\n\n#### Job Controller && CronJob Controller\n\nJob Controller 控制的对象，直接就是 Pod。\n\n#### DeamonSet controller\n\n\n\n## Scheduler\n\n\nscheduler 的作用是将待调度的 pod（新建的pod，rs为补足副本而创建的pod等）按照待定的调度算法和调度策略绑定（Binding)到集群中的某个合适的Node上，并将绑定信息写入 etcd。\n\n整个过程涉及三个对象：**待调度pod列表**(podQueue)，**可用node列表**，以及**调度算法和调度策略**.\n\n![image](/img/k8s/4.png)\n\n\n1）通过调度算法为待调度Pod列表的每个Pod从Node列表中选择一个最适合的Node，并将信息写入etcd中\n\n2）kubelet通过API Server监听到kubernetes Scheduler产生的Pod绑定信息，然后获取对应的Pod清单，下载Image，并启动容器。\n\n\n\n#### 调度资源监听\n\n`kube-apiserver` 提供了一套 `Watch` 机制给 `kubelet`、`kube-controller-manager`、 `kube-scheduler` 等组件用来监控各种资源(Pod、Node、Service等)的变化，类似于消息中间件里的发布-订阅模式（Push）， `kube-apiserver` 能够**主动通知**这些组件。\n\n\n\n#### 调度节点分配：\n\n调度分为几个部分：首先是过滤掉不满足条件的节点，这个过程称为预选（ predicate）；然后对通过的节点按照优先级排序，这个是优选（ priority）；最后从中选择优先级最高的节点。如果中间任何一步骤有错误，就直接返回错误。\n\npredicate 有一系列的算法可以使用：\n\n- `PodFitsResources`：节点上剩余的资源是否大于 pod 请求的资源\n- `PodFitsHost`：如果 pod 指定了 NodeName，检查节点名称是否和 NodeName 匹配\n- `PodFitsHostPorts`：节点上已经使用的 port 是否和 pod 申请的 port 冲突\n- `PodSelectorMatches`：过滤掉和 pod 指定的 label 不匹配的节点\n- `NoDiskConflict`：已经 mount 的 volume 和 pod 指定的 volume 不冲突，除非它们都是只读\n\n如果在 predicate 过程中没有合适的节点，pod 会一直在 `pending` 状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续 priorities 过程：\n按照优先级大小对节点排序。\n\n优选（ priority)\n\n优先级由一系列键值对组成，键是该优先级项的名称，值是它的权重（该项的重要性）。这些优先级选项包括：\n\n- `LeastRequestedPriority`：通过计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高。换句话说，这个优先级指标倾向于资源使用比例更低的节点\n- `ImageLocalityPriority`：倾向于已经有要使用镜像的节点，镜像总大小值越大，权重越高\n\n通过算法对所有的优先级项目和权重进行计算，得出最终的结果。为待调度的 Pod 分配一个 Node ，同时将分配结果通过 `kube-apiserver` 写入 `etcd`；\n\n\n\n#### 调度策略\n\n**NodeSelector**\n\n`nodeSelector` 是最简单的控制方式。 `nodeSelector` 是 PodSpec 中的一个字段，它指定了键-值对的映射。如果想要 pod 能够运行在某个 node 上，那么这个 node 必须具有所有指定的键-值对的标签（node 也能拥有其它标签）。\n\n列出 node 的时候指定 `--show-labels` 参数就能查看 node 都添加了哪些 label：\n\n\n除了自己定义的 label 之外，kubernetes 还会自动给集群中的节点添加一些 label，比如：\n\n- `kubernetes.io/hostname`：节点的 hostname 名称\n- `beta.kubernetes.io/os`： 节点安装的操作系统\n- `beta.kubernetes.io/arch`：节点的架构类型\n\n除了设置Node Selector之外，还可以通过Node Name 直接指定Node，但还是**建议使用Node Selector**，label进行选择是一种弱绑定，直接指定Node Name是强绑定，Node失效时会导致Pod无法调度。\n\n\n\n**亲和性**特性包含了两种类型的亲和性，”node 亲和性” 和 “pod 间的亲和性/反亲和性”，Pod 间以 pod 标签作为约束。\n\n\n\n**亲和性调度（Affinity）**\n\nNode Affinity\n\n- 硬亲和性：requiredDuringSchedulingIgnoredDuringExecution\n- 软亲和性：preferredDuringSchedulingIgnoredDuringExecution \n   - 如果一个 node 的标签在运行时发生改变，从而导致 pod 的亲和性规则不再被满足时，pod 也仍然会继续运行在 node 上。\n\n\nPod Affinity\n\n- 硬亲和性：requiredDuringSchedulingIgnoredDuringExecution \n- preferredDuringSchedulingIgnoredDuringExecution\n\n**反亲和性（Anti-affinity）**\n\n\n\n**Taint 和 toleration** （比如label idc=idc1,比如GPU资源）\n\n```\n#添加一个 taint\nkubectl taint nodes node1 key=value:NoSchedule\n#这个 taint 的 key 为 key 且 value 为 value，并且这个 taint 的作用是 NoSchedule\n```\n\nPodSpec 指定一个 toleration\n\n```\ntolerations: \n- key: key\n  operator: Exists\n  value: value\n  effect: NoSchedule\n```\n\nPreferNoSchedule （软亲和性）\n\n\n\n## kubelet\n\n在kubernetes集群中，每个Node节点都会启动kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器。kubelet会在API Server上注册节点信息，定期向Master汇报节点资源使用情况，并通过cAdvisor监控容器和节点资源。可以把kubelet理解成【Server-Agent】架构中的agent，是Node上的pod管家。\n\n**容器健康检查**\n\n提供Probe 机制，以更精确的判断Pod和容器：\n**Liveness Prode** ：用于容器的自定义健康检查，如果检查失败，将杀死容器，然后根据pod的重启策略了来决定是否重启容器。还可以指定initialDelaySeconds，用于确定状态检查的宽限期，以便容器执行必要的初始化。\n**Readiness Probe** ：如果检查失败，会将该pod 从服务代理的分发后端去除，不再发送请求给pod。\n\n目前有三种类型检查方式\nHttp 健康检查 ：返回200～399认为成功\nContainer Exec：容器内执行命令，状态0退出，则视为成功\nTcp：如果可以建立连接则认为成功，否则失败。\n\n\n\n**资源上报**\n\n继承 cAdvisor 定时上报节点信息\n\n健康检查监视器由kubelet 代理\n\n\n\n#### kube-proxy\n\nService 在很多情况下知识一个概念，而真正将Service 的作用落实的是背后的 kube-proxy服务进程。\n\n在k8s 集群的每个Node上都会运行一个 kube-proxy 服务进程，可以看作Service 的透明代理兼负载均衡器，核心是讲到某个 service 的访问请求转移到后端的多个pod 实例上。\n\n由于iptables 机制针对的是本都的kube-proxy端口，所以每个Node上都要运行 kube-proxy 组件，这样，在集群内部，我们可以再任意Node上发起对 Service 的访问请求。\n\nkube-proxy  更新iptables 会在本机的 **Iptables** 的NAT表中添加4条规则链路。\n\n1. 从容器中通过 serviceClusterIp 和端口访问Service 的请求\n2. 从主机中通过ServiceClusterIp和端口访问Service的请求\n3. 从容器中通过 Service 的NodePort 端口访问Service的请求\n4. 从主机中通过Service 的NodePort 端口号访问Service的请求\n\n\n运行在每个Node 上的kube-proxy进程其实就是一个智能的软件负载均衡器。\n\n简单的网络代理和负载均衡器，负责Service的实现：实现从Pod到Service，以及NodePort向Service的访问。\n\n采用 iptables 来实现LB\n实现方式：\nkube-proxy 监控服务/端点增删改，对每个服务配置ipitables规则，捕获Service 的ClusterIp 和端口的流量，并将流量重定向到服务的后端之一。默认后端的选择是随机的,可以设置基于客户端ip的会话关联。\n\n默认通过iptables来配置对应的NAT转发，自身不再参与转发过程。\n\n\n\n## yaml配置\n\nDeployment yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        resources:\n           requests:\n             cpu: 0.05\n             memory: 16Mi\n```\n\nService yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-svc\nspec:\n  type: NodePort\n  selector:\n      app: nginx\n  ports:\n      - protocol: TCP\n        port: 8881\n        targetPort: 80\n```\n\n#### 部分命令\n\n```\nkubectl get  all  --all-namespaces=true\nkubectl describe ***\nkubectl get pods -n kube-system\nkubectl apply -f  *.yaml\nkubectl get *** -o yaml\nkubectl edit deployment.apps/nginx-deployment\nkubectl exec ${POD_NAME} -c ${CONTAINER_NAME} -- ${CMD} ${ARG1} ${ARG2} ... ${ARGN}\n```\n\n\n","slug":"k8s-introduction","published":1,"updated":"2019-11-08T17:53:52.512Z","photos":[],"link":"","_id":"ck2qgz8vk000c3covx2dh0or8","content":"<h2 id=\"Kubernetes\"><a href=\"#Kubernetes\" class=\"headerlink\" title=\"Kubernetes\"></a>Kubernetes</h2><p>Kubernetes是一个开源的_用于管理云平台中多个主机上的容器化的应用_Kubernetes的目标是让部署容器化的应用简单并且高效<em>powerful__Kubernetes提供了应用部署</em>规划_更新_维护的一种机制</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p><img src=\"/img/k8s/1.png\" alt=\"image\"></p>\n<p>集群中的机器划分为一个Master 节点和一群工作节点(Node)</p>\n<p>Master 节点，由三个紧密协作的独立组件组合而成，它们分别是负责 API 服务的 <strong>kube-apiserver</strong>、负责调度的 <strong>kube-scheduler</strong>，以及负责容器编排的 <strong>kube-controller-manager</strong>。整个集群的持久化数据，则由 kube-apiserver 处理后保存在 <strong>Ectd</strong> 中。</p>\n<p>node上运行着 kubelet、kube-proxy服务进程，负责pod的创建、启动、监控、重启、销毁、以及实现软件模式的负载均衡器。</p>\n<p>在 Kubernetes 项目中，kubelet 主要负责同容器运行时（比如 Docker 项目）打交道，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 <strong>CRI</strong> 接入到 Kubernetes 项目当中。(比如 rkt)</p>\n<p>而kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。<br><a id=\"more\"></a></p>\n<h4 id=\"kubernetes-核心概念\"><a href=\"#kubernetes-核心概念\" class=\"headerlink\" title=\"kubernetes 核心概念\"></a>kubernetes 核心概念</h4><p><img src=\"/img/k8s/2.png\" alt=\"image\"></p>\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><h2 id=\"Namespace\"><a href=\"#Namespace\" class=\"headerlink\" title=\"Namespace\"></a>Namespace</h2><p>Namespace 通过将系统内部的对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理</p>\n<p><strong>ResourceQuota</strong></p>\n<p>Resource Quotas（资源配额，简称quota）是对namespace进行资源配额，限制资源使用的一种策略.</p>\n<table>\n<thead>\n<tr>\n<th>字符串</th>\n<th>API对象</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>“pods”</td>\n<td>Pod</td>\n</tr>\n<tr>\n<td>“services</td>\n<td>Service</td>\n</tr>\n<tr>\n<td>“replicationcontrollers”</td>\n<td>ReplicationController</td>\n</tr>\n<tr>\n<td>“resourcequotas”</td>\n<td>ResourceQuota</td>\n</tr>\n<tr>\n<td>“secrets”</td>\n<td>Secret</td>\n</tr>\n<tr>\n<td>“configmaps”</td>\n<td>ConfigMap</td>\n</tr>\n<tr>\n<td>“persistentvolumeclaims”</td>\n<td>PersistentVolumeClaim</td>\n</tr>\n<tr>\n<td>“services.nodeports”</td>\n<td>NodePort类型的Service</td>\n</tr>\n<tr>\n<td>“services.loadbalancers”</td>\n<td>LoadBalancer类型的Service</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"label\"><a href=\"#label\" class=\"headerlink\" title=\"label\"></a>label</h2><p>label 和 labelSelctor 是 k8s 中的只要分组机制</p>\n<p>Kubernetes目前支持两种类型的Label Selector：</p>\n<ul>\n<li>基于等式的Selector（Equality-based）</li>\n<li>基于集合的Selector（Set-based）</li>\n</ul>\n<h2 id=\"Pod\"><a href=\"#Pod\" class=\"headerlink\" title=\"Pod\"></a>Pod</h2><p>Pod是k8s的最基本的操作单元，包含一个或多个紧密相关的容器，类似于豌豆荚的概念。</p>\n<p>为什么k8s使用Pod在容器之上再封装一层呢？</p>\n<h4 id=\"Pod-中几个重要字段的含义和用法\"><a href=\"#Pod-中几个重要字段的含义和用法\" class=\"headerlink\" title=\"Pod 中几个重要字段的含义和用法\"></a>Pod 中几个重要字段的含义和用法</h4><ol>\n<li>NodeSelector： 是一个供用户将 Pod 与 Node 进行绑定的字段</li>\n<li>NodeName：一旦 Pod 的这个字段被赋值，Kubernetes 项目就会被认为这个 Pod 已经经过了调度</li>\n<li>HostAliases：定义了 Pod 的 hosts</li>\n<li>ImagePullPolicy： 的值默认是 Always，即每次创建 Pod 都重新拉取一次镜像，而如果它的值被定义为 Never 或者 IfNotPresent，则意味着 Pod 永远不会主动拉取这个镜像，或者只在宿主机上不存在这个镜像时才拉取。</li>\n<li>Lifecycle 字段。它定义的是 Container Lifecycle Hooks 是在容器状态发生变化时触发一系列“钩子。</li>\n</ol>\n<h4 id=\"Pod-具体的创建步骤包括：\"><a href=\"#Pod-具体的创建步骤包括：\" class=\"headerlink\" title=\"Pod 具体的创建步骤包括：\"></a>Pod 具体的创建步骤包括：</h4><p><img src=\"/img/k8s/3.jpg\" alt=\"images\"></p>\n<ol>\n<li>客户端提交创建请求，可以通过API Server的Restful API，也可以使用kubectl命令行工具。支持的数据类型包括JSON和YAML。</li>\n<li>API Server处理用户请求，存储Pod数据到etcd。</li>\n<li>调度器通过API Server查看未绑定的Pod。尝试为Pod分配主机。</li>\n<li>过滤主机 (调度预选)：调度器用一组规则过滤掉不符合要求的主机。比如Pod指定了所需要的资源量，那么可用资源比Pod需要的资源量少的主机会被过滤掉。</li>\n<li>主机打分(调度优选)：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把容一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等。</li>\n<li>选择主机：选择打分最高的主机，进行binding操作，结果存储到etcd中。</li>\n<li>kubelet根据调度结果执行Pod创建操作： 绑定成功后，scheduler会调用APIServer的API在etcd中创建一个boundpod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步boundpod信息，一旦发现应该在该工作节点上运行的boundpod对象没有更新，则调用Docker API创建并启动pod内的容器。<br>​</li>\n</ol>\n<p>Pod模板是pod规范，包含在其他对象中，例如 <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/\" target=\"_blank\" rel=\"noopener\">Replication Controllers</a>，<a href=\"https://kubernetes.io/docs/concepts/jobs/run-to-completion-finite-workloads/\" target=\"_blank\" rel=\"noopener\">Jobs</a>和 <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/\" target=\"_blank\" rel=\"noopener\">DaemonSet</a></p>\n<p>pod 也支持host网络的设置，如spec-&gt;hostNetwork=true</p>\n<p><strong>Pause Container</strong></p>\n<p>每个pod 里运行着一个特殊的被称为<br>Pause 的容器(业务无关且不容易死亡)，其他容器则为业务容器，业务容器共享 Pause 容器的网络栈和Volume挂载卷，创建pod 会自动创建 pause容器。每个pod 都被分配一个唯一的ip地址。</p>\n<p>可以通过api手动管理pod，也可以委托给控制器来管理pod。</p>\n<p><strong>Init Container</strong></p>\n<p>在 Pod 中，所有 Init Container 定义的容器，都会比 spec.containers 定义的用户容器先启动。</p>\n<p>比如，在我们的这个应用 Pod 中，Tomcat 容器是我们要使用的主容器，而 WAR 包容器的存在，只是为了给它提供一个 WAR 包而已。所以，我们用 Init Container 的方式优先运行 WAR 包容器，扮演了一个 sidecar 的角色</p>\n<h2 id=\"Service\"><a href=\"#Service\" class=\"headerlink\" title=\"Service\"></a>Service</h2><p>一个service 对象拥有如下关键特征<br>拥有一个虚拟ip(Cluster ip 、Service ip 或 Vip)和端口号</p>\n<p>通过 label selector 筛选关联 pod</p>\n<p>创建好service 后集群中其他新创建的pod就可以通过service 的Cluster ip+端口号来连接和访问它了</p>\n<p>spec<br>type=NodePort 和nodePort=30001的两个属性，表明service开启了NodePort方式的外网访问模式</p>\n<p>port<br>targetPort 默认与pord 相同</p>\n<h2 id=\"API-Server\"><a href=\"#API-Server\" class=\"headerlink\" title=\"API Server\"></a>API Server</h2><p>kubernets Api Server 本身也是一个Service，它的名字就是  ”kubernets“.</p>\n<p>组件之间的所有操作和通信均由API Server处理的REST API调用.</p>\n<p>API Server 负责和 /etcd 交互（其他组件不会直接操作 etcd，只有 API Server 这么做），是整个 kubernetes 集群的数据中心，所有的交互都是以 API Server 为核心的。简单来说，API Server 提供了一下的功能：</p>\n<ul>\n<li>整个集群管理的 API 接口：所有对集群进行的查询和管理都要通过 API 来进行</li>\n<li>集群内部各个模块之间通信的枢纽：所有模块之前并不会之间互相调用，而是通过和 API Server 打交道来完成自己那部分的工作</li>\n<li>集群安全控制：API Server 提供的验证和授权保证了整个集群的安全</li>\n</ul>\n<p><strong>kubectl客户端</strong></p>\n<p>命令行工具kubectl客户端，通过命令行参数转换为对API Server的REST API调用，并将调用结果输出。</p>\n<p><strong>kubelet与API Server交互</strong></p>\n<p>每个Node节点上的kubelet定期就会调用API Server的REST接口报告自身状态，API Server接收这些信息后，将节点状态信息更新到etcd中。kubelet也通过API Server的Watch接口监听Pod信息，从而对Node机器上的POD进行管理。</p>\n<table>\n<thead>\n<tr>\n<th>监听信息</th>\n<th>kubelet动作</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>新的POD副本被调度绑定到本节点</td>\n<td>执行POD对应的容器的创建和启动逻辑</td>\n<td>-</td>\n</tr>\n<tr>\n<td>POD对象被删除</td>\n<td>删除本节点上相应的POD容器</td>\n<td>-</td>\n</tr>\n<tr>\n<td>修改POD信息</td>\n<td>修改本节点的POD容器</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<p><strong>kube-controller-manager与API Server交互</strong></p>\n<p>kube-controller-manager中的Node Controller模块通过API Server提供的Watch接口，实时监控Node的信息，并做相应处理。</p>\n<p><strong>kube-scheduler与API Server交互</strong></p>\n<p>Scheduler通过API Server的Watch接口监听到新建Pod副本的信息后，它会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑。调度成功后将Pod绑定到目标节点上</p>\n<p><strong>Watch API</strong></p>\n<p>Watch API其实就是一种GET请求，只是在query参数里面加了watch。kube-apiserver那边接受到用户的client请求后，可以通过两种方式发送watch event，一种是通过websocket协议发送，另一种就是通过Transfer-Encoding=chunked的方式建立一个长连接，然后发送watch event</p>\n<h2 id=\"Controller-Manager\"><a href=\"#Controller-Manager\" class=\"headerlink\" title=\"Controller Manager\"></a>Controller Manager</h2><p>controller manager是集群内部控制中心，负责集群内的node，pod，服务端点，服务，资源配额，命名空间，服务账号等资源的管理、自动化部署健康监测，异常修复，确保个资源始终处于预期的工作状态。<br>controller manager 是一个控制器集合包含：rc，node controller，resourcequota controller，namespace conttoller，token<br>controller，service controller，endpoint controller，serviceaccount controller。</p>\n<p>控制器核心工作原理是，每个控制器通过api服务器来查看系统运行状态，并尝试从将系统状态从“现有状态”修正到“期望状态”</p>\n<h4 id=\"k8s-RC-Replication-Controller\"><a href=\"#k8s-RC-Replication-Controller\" class=\"headerlink\" title=\"k8s RC(Replication Controller)\"></a>k8s RC(Replication Controller)</h4><p>RC 的定义包含如下几个部分：<br>pod 期待的副本数<br>用于筛选目标pod的 Label Selector<br>当pod副本数小于预期时，用于创建新pod的pod模板</p>\n<p> Replica Set</p>\n<p>官方解释为“下一代的RC”<br>唯一区别是Replica Sets支持基于集合的Label selector 而RC 只支持基于等式的</p>\n<p>Replica Set 很少单独使用，主要被Deployment 这个更高级的资源对象所使用</p>\n<p>Replica Set 和 Deployment 逐步替换了之前RC 的作用</p>\n<h4 id=\"Deployment-Controller\"><a href=\"#Deployment-Controller\" class=\"headerlink\" title=\"Deployment Controller\"></a>Deployment Controller</h4><p>扩容:</p>\n<p><strong>使用场景</strong>：</p>\n<ol>\n<li>重新调度</li>\n<li>弹性伸缩</li>\n<li>滚动更新</li>\n</ol>\n<p>使用场景有以下几个：<br>创建Deployment对象来生产对应 Replica Set 并完成 Pod 副本的创建过程<br>检查Deployment 的状态来看部署是否完成(pod数量是否达到预期值)<br>更新Deployment 以创建新pod 比如镜像升级<br>回滚早先 Deployment 版本<br>暂停修改<br>查看Deployment的状态，以此作为发布是否成功的指标</p>\n<h4 id=\"ResourceQuota-Controller\"><a href=\"#ResourceQuota-Controller\" class=\"headerlink\" title=\"ResourceQuota Controller\"></a>ResourceQuota Controller</h4><p>目前 k8s 支持 三个层次的资源配额管理</p>\n<ol>\n<li><p>容器级别 ，可以对 cpu ，memory 进行限制</p>\n</li>\n<li><p>Pod 级别，对pod内所有容器进行资源限制</p>\n</li>\n<li><p>Namespace 级别，对Namespace(多租户)级别的资源限制，包括：</p>\n<ul>\n<li>pod 数量</li>\n<li>service 数量</li>\n<li>resourceQuota 数量 等</li>\n</ul>\n</li>\n</ol>\n<p><strong>Endpoints Controller</strong> 检测到pod的事件，则会更新对应Service 的Endpoints</p>\n<h4 id=\"Job-Controller-amp-amp-CronJob-Controller\"><a href=\"#Job-Controller-amp-amp-CronJob-Controller\" class=\"headerlink\" title=\"Job Controller &amp;&amp; CronJob Controller\"></a>Job Controller &amp;&amp; CronJob Controller</h4><p>Job Controller 控制的对象，直接就是 Pod。</p>\n<h4 id=\"DeamonSet-controller\"><a href=\"#DeamonSet-controller\" class=\"headerlink\" title=\"DeamonSet controller\"></a>DeamonSet controller</h4><h2 id=\"Scheduler\"><a href=\"#Scheduler\" class=\"headerlink\" title=\"Scheduler\"></a>Scheduler</h2><p>scheduler 的作用是将待调度的 pod（新建的pod，rs为补足副本而创建的pod等）按照待定的调度算法和调度策略绑定（Binding)到集群中的某个合适的Node上，并将绑定信息写入 etcd。</p>\n<p>整个过程涉及三个对象：<strong>待调度pod列表</strong>(podQueue)，<strong>可用node列表</strong>，以及<strong>调度算法和调度策略</strong>.</p>\n<p><img src=\"/img/k8s/4.png\" alt=\"image\"></p>\n<p>1）通过调度算法为待调度Pod列表的每个Pod从Node列表中选择一个最适合的Node，并将信息写入etcd中</p>\n<p>2）kubelet通过API Server监听到kubernetes Scheduler产生的Pod绑定信息，然后获取对应的Pod清单，下载Image，并启动容器。</p>\n<h4 id=\"调度资源监听\"><a href=\"#调度资源监听\" class=\"headerlink\" title=\"调度资源监听\"></a>调度资源监听</h4><p><code>kube-apiserver</code> 提供了一套 <code>Watch</code> 机制给 <code>kubelet</code>、<code>kube-controller-manager</code>、 <code>kube-scheduler</code> 等组件用来监控各种资源(Pod、Node、Service等)的变化，类似于消息中间件里的发布-订阅模式（Push）， <code>kube-apiserver</code> 能够<strong>主动通知</strong>这些组件。</p>\n<h4 id=\"调度节点分配：\"><a href=\"#调度节点分配：\" class=\"headerlink\" title=\"调度节点分配：\"></a>调度节点分配：</h4><p>调度分为几个部分：首先是过滤掉不满足条件的节点，这个过程称为预选（ predicate）；然后对通过的节点按照优先级排序，这个是优选（ priority）；最后从中选择优先级最高的节点。如果中间任何一步骤有错误，就直接返回错误。</p>\n<p>predicate 有一系列的算法可以使用：</p>\n<ul>\n<li><code>PodFitsResources</code>：节点上剩余的资源是否大于 pod 请求的资源</li>\n<li><code>PodFitsHost</code>：如果 pod 指定了 NodeName，检查节点名称是否和 NodeName 匹配</li>\n<li><code>PodFitsHostPorts</code>：节点上已经使用的 port 是否和 pod 申请的 port 冲突</li>\n<li><code>PodSelectorMatches</code>：过滤掉和 pod 指定的 label 不匹配的节点</li>\n<li><code>NoDiskConflict</code>：已经 mount 的 volume 和 pod 指定的 volume 不冲突，除非它们都是只读</li>\n</ul>\n<p>如果在 predicate 过程中没有合适的节点，pod 会一直在 <code>pending</code> 状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续 priorities 过程：<br>按照优先级大小对节点排序。</p>\n<p>优选（ priority)</p>\n<p>优先级由一系列键值对组成，键是该优先级项的名称，值是它的权重（该项的重要性）。这些优先级选项包括：</p>\n<ul>\n<li><code>LeastRequestedPriority</code>：通过计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高。换句话说，这个优先级指标倾向于资源使用比例更低的节点</li>\n<li><code>ImageLocalityPriority</code>：倾向于已经有要使用镜像的节点，镜像总大小值越大，权重越高</li>\n</ul>\n<p>通过算法对所有的优先级项目和权重进行计算，得出最终的结果。为待调度的 Pod 分配一个 Node ，同时将分配结果通过 <code>kube-apiserver</code> 写入 <code>etcd</code>；</p>\n<h4 id=\"调度策略\"><a href=\"#调度策略\" class=\"headerlink\" title=\"调度策略\"></a>调度策略</h4><p><strong>NodeSelector</strong></p>\n<p><code>nodeSelector</code> 是最简单的控制方式。 <code>nodeSelector</code> 是 PodSpec 中的一个字段，它指定了键-值对的映射。如果想要 pod 能够运行在某个 node 上，那么这个 node 必须具有所有指定的键-值对的标签（node 也能拥有其它标签）。</p>\n<p>列出 node 的时候指定 <code>--show-labels</code> 参数就能查看 node 都添加了哪些 label：</p>\n<p>除了自己定义的 label 之外，kubernetes 还会自动给集群中的节点添加一些 label，比如：</p>\n<ul>\n<li><code>kubernetes.io/hostname</code>：节点的 hostname 名称</li>\n<li><code>beta.kubernetes.io/os</code>： 节点安装的操作系统</li>\n<li><code>beta.kubernetes.io/arch</code>：节点的架构类型</li>\n</ul>\n<p>除了设置Node Selector之外，还可以通过Node Name 直接指定Node，但还是<strong>建议使用Node Selector</strong>，label进行选择是一种弱绑定，直接指定Node Name是强绑定，Node失效时会导致Pod无法调度。</p>\n<p><strong>亲和性</strong>特性包含了两种类型的亲和性，”node 亲和性” 和 “pod 间的亲和性/反亲和性”，Pod 间以 pod 标签作为约束。</p>\n<p><strong>亲和性调度（Affinity）</strong></p>\n<p>Node Affinity</p>\n<ul>\n<li>硬亲和性：requiredDuringSchedulingIgnoredDuringExecution</li>\n<li>软亲和性：preferredDuringSchedulingIgnoredDuringExecution <ul>\n<li>如果一个 node 的标签在运行时发生改变，从而导致 pod 的亲和性规则不再被满足时，pod 也仍然会继续运行在 node 上。</li>\n</ul>\n</li>\n</ul>\n<p>Pod Affinity</p>\n<ul>\n<li>硬亲和性：requiredDuringSchedulingIgnoredDuringExecution </li>\n<li>preferredDuringSchedulingIgnoredDuringExecution</li>\n</ul>\n<p><strong>反亲和性（Anti-affinity）</strong></p>\n<p><strong>Taint 和 toleration</strong> （比如label idc=idc1,比如GPU资源）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#添加一个 taint</span><br><span class=\"line\">kubectl taint nodes node1 key=value:NoSchedule</span><br><span class=\"line\">#这个 taint 的 key 为 key 且 value 为 value，并且这个 taint 的作用是 NoSchedule</span><br></pre></td></tr></table></figure>\n<p>PodSpec 指定一个 toleration</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tolerations: </span><br><span class=\"line\">- key: key</span><br><span class=\"line\">  operator: Exists</span><br><span class=\"line\">  value: value</span><br><span class=\"line\">  effect: NoSchedule</span><br></pre></td></tr></table></figure>\n<p>PreferNoSchedule （软亲和性）</p>\n<h2 id=\"kubelet\"><a href=\"#kubelet\" class=\"headerlink\" title=\"kubelet\"></a>kubelet</h2><p>在kubernetes集群中，每个Node节点都会启动kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器。kubelet会在API Server上注册节点信息，定期向Master汇报节点资源使用情况，并通过cAdvisor监控容器和节点资源。可以把kubelet理解成【Server-Agent】架构中的agent，是Node上的pod管家。</p>\n<p><strong>容器健康检查</strong></p>\n<p>提供Probe 机制，以更精确的判断Pod和容器：<br><strong>Liveness Prode</strong> ：用于容器的自定义健康检查，如果检查失败，将杀死容器，然后根据pod的重启策略了来决定是否重启容器。还可以指定initialDelaySeconds，用于确定状态检查的宽限期，以便容器执行必要的初始化。<br><strong>Readiness Probe</strong> ：如果检查失败，会将该pod 从服务代理的分发后端去除，不再发送请求给pod。</p>\n<p>目前有三种类型检查方式<br>Http 健康检查 ：返回200～399认为成功<br>Container Exec：容器内执行命令，状态0退出，则视为成功<br>Tcp：如果可以建立连接则认为成功，否则失败。</p>\n<p><strong>资源上报</strong></p>\n<p>继承 cAdvisor 定时上报节点信息</p>\n<p>健康检查监视器由kubelet 代理</p>\n<h4 id=\"kube-proxy\"><a href=\"#kube-proxy\" class=\"headerlink\" title=\"kube-proxy\"></a>kube-proxy</h4><p>Service 在很多情况下知识一个概念，而真正将Service 的作用落实的是背后的 kube-proxy服务进程。</p>\n<p>在k8s 集群的每个Node上都会运行一个 kube-proxy 服务进程，可以看作Service 的透明代理兼负载均衡器，核心是讲到某个 service 的访问请求转移到后端的多个pod 实例上。</p>\n<p>由于iptables 机制针对的是本都的kube-proxy端口，所以每个Node上都要运行 kube-proxy 组件，这样，在集群内部，我们可以再任意Node上发起对 Service 的访问请求。</p>\n<p>kube-proxy  更新iptables 会在本机的 <strong>Iptables</strong> 的NAT表中添加4条规则链路。</p>\n<ol>\n<li>从容器中通过 serviceClusterIp 和端口访问Service 的请求</li>\n<li>从主机中通过ServiceClusterIp和端口访问Service的请求</li>\n<li>从容器中通过 Service 的NodePort 端口访问Service的请求</li>\n<li>从主机中通过Service 的NodePort 端口号访问Service的请求</li>\n</ol>\n<p>运行在每个Node 上的kube-proxy进程其实就是一个智能的软件负载均衡器。</p>\n<p>简单的网络代理和负载均衡器，负责Service的实现：实现从Pod到Service，以及NodePort向Service的访问。</p>\n<p>采用 iptables 来实现LB<br>实现方式：<br>kube-proxy 监控服务/端点增删改，对每个服务配置ipitables规则，捕获Service 的ClusterIp 和端口的流量，并将流量重定向到服务的后端之一。默认后端的选择是随机的,可以设置基于客户端ip的会话关联。</p>\n<p>默认通过iptables来配置对应的NAT转发，自身不再参与转发过程。</p>\n<h2 id=\"yaml配置\"><a href=\"#yaml配置\" class=\"headerlink\" title=\"yaml配置\"></a>yaml配置</h2><p>Deployment yaml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-deployment</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: nginx</span><br><span class=\"line\">  replicas: 2</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: nginx</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: nginx</span><br><span class=\"line\">        image: nginx:1.7.9</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 80</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">           requests:</span><br><span class=\"line\">             cpu: 0.05</span><br><span class=\"line\">             memory: 16Mi</span><br></pre></td></tr></table></figure>\n<p>Service yaml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-svc</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">      app: nginx</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">      - protocol: TCP</span><br><span class=\"line\">        port: 8881</span><br><span class=\"line\">        targetPort: 80</span><br></pre></td></tr></table></figure>\n<h4 id=\"部分命令\"><a href=\"#部分命令\" class=\"headerlink\" title=\"部分命令\"></a>部分命令</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get  all  --all-namespaces=true</span><br><span class=\"line\">kubectl describe ***</span><br><span class=\"line\">kubectl get pods -n kube-system</span><br><span class=\"line\">kubectl apply -f  *.yaml</span><br><span class=\"line\">kubectl get *** -o yaml</span><br><span class=\"line\">kubectl edit deployment.apps/nginx-deployment</span><br><span class=\"line\">kubectl exec $&#123;POD_NAME&#125; -c $&#123;CONTAINER_NAME&#125; -- $&#123;CMD&#125; $&#123;ARG1&#125; $&#123;ARG2&#125; ... $&#123;ARGN&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<h2 id=\"Kubernetes\"><a href=\"#Kubernetes\" class=\"headerlink\" title=\"Kubernetes\"></a>Kubernetes</h2><p>Kubernetes是一个开源的_用于管理云平台中多个主机上的容器化的应用_Kubernetes的目标是让部署容器化的应用简单并且高效<em>powerful__Kubernetes提供了应用部署</em>规划_更新_维护的一种机制</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p><img src=\"/img/k8s/1.png\" alt=\"image\"></p>\n<p>集群中的机器划分为一个Master 节点和一群工作节点(Node)</p>\n<p>Master 节点，由三个紧密协作的独立组件组合而成，它们分别是负责 API 服务的 <strong>kube-apiserver</strong>、负责调度的 <strong>kube-scheduler</strong>，以及负责容器编排的 <strong>kube-controller-manager</strong>。整个集群的持久化数据，则由 kube-apiserver 处理后保存在 <strong>Ectd</strong> 中。</p>\n<p>node上运行着 kubelet、kube-proxy服务进程，负责pod的创建、启动、监控、重启、销毁、以及实现软件模式的负载均衡器。</p>\n<p>在 Kubernetes 项目中，kubelet 主要负责同容器运行时（比如 Docker 项目）打交道，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 <strong>CRI</strong> 接入到 Kubernetes 项目当中。(比如 rkt)</p>\n<p>而kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。<br>","more":"</p>\n<h4 id=\"kubernetes-核心概念\"><a href=\"#kubernetes-核心概念\" class=\"headerlink\" title=\"kubernetes 核心概念\"></a>kubernetes 核心概念</h4><p><img src=\"/img/k8s/2.png\" alt=\"image\"></p>\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><h2 id=\"Namespace\"><a href=\"#Namespace\" class=\"headerlink\" title=\"Namespace\"></a>Namespace</h2><p>Namespace 通过将系统内部的对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理</p>\n<p><strong>ResourceQuota</strong></p>\n<p>Resource Quotas（资源配额，简称quota）是对namespace进行资源配额，限制资源使用的一种策略.</p>\n<table>\n<thead>\n<tr>\n<th>字符串</th>\n<th>API对象</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>“pods”</td>\n<td>Pod</td>\n</tr>\n<tr>\n<td>“services</td>\n<td>Service</td>\n</tr>\n<tr>\n<td>“replicationcontrollers”</td>\n<td>ReplicationController</td>\n</tr>\n<tr>\n<td>“resourcequotas”</td>\n<td>ResourceQuota</td>\n</tr>\n<tr>\n<td>“secrets”</td>\n<td>Secret</td>\n</tr>\n<tr>\n<td>“configmaps”</td>\n<td>ConfigMap</td>\n</tr>\n<tr>\n<td>“persistentvolumeclaims”</td>\n<td>PersistentVolumeClaim</td>\n</tr>\n<tr>\n<td>“services.nodeports”</td>\n<td>NodePort类型的Service</td>\n</tr>\n<tr>\n<td>“services.loadbalancers”</td>\n<td>LoadBalancer类型的Service</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"label\"><a href=\"#label\" class=\"headerlink\" title=\"label\"></a>label</h2><p>label 和 labelSelctor 是 k8s 中的只要分组机制</p>\n<p>Kubernetes目前支持两种类型的Label Selector：</p>\n<ul>\n<li>基于等式的Selector（Equality-based）</li>\n<li>基于集合的Selector（Set-based）</li>\n</ul>\n<h2 id=\"Pod\"><a href=\"#Pod\" class=\"headerlink\" title=\"Pod\"></a>Pod</h2><p>Pod是k8s的最基本的操作单元，包含一个或多个紧密相关的容器，类似于豌豆荚的概念。</p>\n<p>为什么k8s使用Pod在容器之上再封装一层呢？</p>\n<h4 id=\"Pod-中几个重要字段的含义和用法\"><a href=\"#Pod-中几个重要字段的含义和用法\" class=\"headerlink\" title=\"Pod 中几个重要字段的含义和用法\"></a>Pod 中几个重要字段的含义和用法</h4><ol>\n<li>NodeSelector： 是一个供用户将 Pod 与 Node 进行绑定的字段</li>\n<li>NodeName：一旦 Pod 的这个字段被赋值，Kubernetes 项目就会被认为这个 Pod 已经经过了调度</li>\n<li>HostAliases：定义了 Pod 的 hosts</li>\n<li>ImagePullPolicy： 的值默认是 Always，即每次创建 Pod 都重新拉取一次镜像，而如果它的值被定义为 Never 或者 IfNotPresent，则意味着 Pod 永远不会主动拉取这个镜像，或者只在宿主机上不存在这个镜像时才拉取。</li>\n<li>Lifecycle 字段。它定义的是 Container Lifecycle Hooks 是在容器状态发生变化时触发一系列“钩子。</li>\n</ol>\n<h4 id=\"Pod-具体的创建步骤包括：\"><a href=\"#Pod-具体的创建步骤包括：\" class=\"headerlink\" title=\"Pod 具体的创建步骤包括：\"></a>Pod 具体的创建步骤包括：</h4><p><img src=\"/img/k8s/3.jpg\" alt=\"images\"></p>\n<ol>\n<li>客户端提交创建请求，可以通过API Server的Restful API，也可以使用kubectl命令行工具。支持的数据类型包括JSON和YAML。</li>\n<li>API Server处理用户请求，存储Pod数据到etcd。</li>\n<li>调度器通过API Server查看未绑定的Pod。尝试为Pod分配主机。</li>\n<li>过滤主机 (调度预选)：调度器用一组规则过滤掉不符合要求的主机。比如Pod指定了所需要的资源量，那么可用资源比Pod需要的资源量少的主机会被过滤掉。</li>\n<li>主机打分(调度优选)：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把容一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等。</li>\n<li>选择主机：选择打分最高的主机，进行binding操作，结果存储到etcd中。</li>\n<li>kubelet根据调度结果执行Pod创建操作： 绑定成功后，scheduler会调用APIServer的API在etcd中创建一个boundpod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步boundpod信息，一旦发现应该在该工作节点上运行的boundpod对象没有更新，则调用Docker API创建并启动pod内的容器。<br>​</li>\n</ol>\n<p>Pod模板是pod规范，包含在其他对象中，例如 <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/\" target=\"_blank\" rel=\"noopener\">Replication Controllers</a>，<a href=\"https://kubernetes.io/docs/concepts/jobs/run-to-completion-finite-workloads/\" target=\"_blank\" rel=\"noopener\">Jobs</a>和 <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/\" target=\"_blank\" rel=\"noopener\">DaemonSet</a></p>\n<p>pod 也支持host网络的设置，如spec-&gt;hostNetwork=true</p>\n<p><strong>Pause Container</strong></p>\n<p>每个pod 里运行着一个特殊的被称为<br>Pause 的容器(业务无关且不容易死亡)，其他容器则为业务容器，业务容器共享 Pause 容器的网络栈和Volume挂载卷，创建pod 会自动创建 pause容器。每个pod 都被分配一个唯一的ip地址。</p>\n<p>可以通过api手动管理pod，也可以委托给控制器来管理pod。</p>\n<p><strong>Init Container</strong></p>\n<p>在 Pod 中，所有 Init Container 定义的容器，都会比 spec.containers 定义的用户容器先启动。</p>\n<p>比如，在我们的这个应用 Pod 中，Tomcat 容器是我们要使用的主容器，而 WAR 包容器的存在，只是为了给它提供一个 WAR 包而已。所以，我们用 Init Container 的方式优先运行 WAR 包容器，扮演了一个 sidecar 的角色</p>\n<h2 id=\"Service\"><a href=\"#Service\" class=\"headerlink\" title=\"Service\"></a>Service</h2><p>一个service 对象拥有如下关键特征<br>拥有一个虚拟ip(Cluster ip 、Service ip 或 Vip)和端口号</p>\n<p>通过 label selector 筛选关联 pod</p>\n<p>创建好service 后集群中其他新创建的pod就可以通过service 的Cluster ip+端口号来连接和访问它了</p>\n<p>spec<br>type=NodePort 和nodePort=30001的两个属性，表明service开启了NodePort方式的外网访问模式</p>\n<p>port<br>targetPort 默认与pord 相同</p>\n<h2 id=\"API-Server\"><a href=\"#API-Server\" class=\"headerlink\" title=\"API Server\"></a>API Server</h2><p>kubernets Api Server 本身也是一个Service，它的名字就是  ”kubernets“.</p>\n<p>组件之间的所有操作和通信均由API Server处理的REST API调用.</p>\n<p>API Server 负责和 /etcd 交互（其他组件不会直接操作 etcd，只有 API Server 这么做），是整个 kubernetes 集群的数据中心，所有的交互都是以 API Server 为核心的。简单来说，API Server 提供了一下的功能：</p>\n<ul>\n<li>整个集群管理的 API 接口：所有对集群进行的查询和管理都要通过 API 来进行</li>\n<li>集群内部各个模块之间通信的枢纽：所有模块之前并不会之间互相调用，而是通过和 API Server 打交道来完成自己那部分的工作</li>\n<li>集群安全控制：API Server 提供的验证和授权保证了整个集群的安全</li>\n</ul>\n<p><strong>kubectl客户端</strong></p>\n<p>命令行工具kubectl客户端，通过命令行参数转换为对API Server的REST API调用，并将调用结果输出。</p>\n<p><strong>kubelet与API Server交互</strong></p>\n<p>每个Node节点上的kubelet定期就会调用API Server的REST接口报告自身状态，API Server接收这些信息后，将节点状态信息更新到etcd中。kubelet也通过API Server的Watch接口监听Pod信息，从而对Node机器上的POD进行管理。</p>\n<table>\n<thead>\n<tr>\n<th>监听信息</th>\n<th>kubelet动作</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>新的POD副本被调度绑定到本节点</td>\n<td>执行POD对应的容器的创建和启动逻辑</td>\n<td>-</td>\n</tr>\n<tr>\n<td>POD对象被删除</td>\n<td>删除本节点上相应的POD容器</td>\n<td>-</td>\n</tr>\n<tr>\n<td>修改POD信息</td>\n<td>修改本节点的POD容器</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<p><strong>kube-controller-manager与API Server交互</strong></p>\n<p>kube-controller-manager中的Node Controller模块通过API Server提供的Watch接口，实时监控Node的信息，并做相应处理。</p>\n<p><strong>kube-scheduler与API Server交互</strong></p>\n<p>Scheduler通过API Server的Watch接口监听到新建Pod副本的信息后，它会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑。调度成功后将Pod绑定到目标节点上</p>\n<p><strong>Watch API</strong></p>\n<p>Watch API其实就是一种GET请求，只是在query参数里面加了watch。kube-apiserver那边接受到用户的client请求后，可以通过两种方式发送watch event，一种是通过websocket协议发送，另一种就是通过Transfer-Encoding=chunked的方式建立一个长连接，然后发送watch event</p>\n<h2 id=\"Controller-Manager\"><a href=\"#Controller-Manager\" class=\"headerlink\" title=\"Controller Manager\"></a>Controller Manager</h2><p>controller manager是集群内部控制中心，负责集群内的node，pod，服务端点，服务，资源配额，命名空间，服务账号等资源的管理、自动化部署健康监测，异常修复，确保个资源始终处于预期的工作状态。<br>controller manager 是一个控制器集合包含：rc，node controller，resourcequota controller，namespace conttoller，token<br>controller，service controller，endpoint controller，serviceaccount controller。</p>\n<p>控制器核心工作原理是，每个控制器通过api服务器来查看系统运行状态，并尝试从将系统状态从“现有状态”修正到“期望状态”</p>\n<h4 id=\"k8s-RC-Replication-Controller\"><a href=\"#k8s-RC-Replication-Controller\" class=\"headerlink\" title=\"k8s RC(Replication Controller)\"></a>k8s RC(Replication Controller)</h4><p>RC 的定义包含如下几个部分：<br>pod 期待的副本数<br>用于筛选目标pod的 Label Selector<br>当pod副本数小于预期时，用于创建新pod的pod模板</p>\n<p> Replica Set</p>\n<p>官方解释为“下一代的RC”<br>唯一区别是Replica Sets支持基于集合的Label selector 而RC 只支持基于等式的</p>\n<p>Replica Set 很少单独使用，主要被Deployment 这个更高级的资源对象所使用</p>\n<p>Replica Set 和 Deployment 逐步替换了之前RC 的作用</p>\n<h4 id=\"Deployment-Controller\"><a href=\"#Deployment-Controller\" class=\"headerlink\" title=\"Deployment Controller\"></a>Deployment Controller</h4><p>扩容:</p>\n<p><strong>使用场景</strong>：</p>\n<ol>\n<li>重新调度</li>\n<li>弹性伸缩</li>\n<li>滚动更新</li>\n</ol>\n<p>使用场景有以下几个：<br>创建Deployment对象来生产对应 Replica Set 并完成 Pod 副本的创建过程<br>检查Deployment 的状态来看部署是否完成(pod数量是否达到预期值)<br>更新Deployment 以创建新pod 比如镜像升级<br>回滚早先 Deployment 版本<br>暂停修改<br>查看Deployment的状态，以此作为发布是否成功的指标</p>\n<h4 id=\"ResourceQuota-Controller\"><a href=\"#ResourceQuota-Controller\" class=\"headerlink\" title=\"ResourceQuota Controller\"></a>ResourceQuota Controller</h4><p>目前 k8s 支持 三个层次的资源配额管理</p>\n<ol>\n<li><p>容器级别 ，可以对 cpu ，memory 进行限制</p>\n</li>\n<li><p>Pod 级别，对pod内所有容器进行资源限制</p>\n</li>\n<li><p>Namespace 级别，对Namespace(多租户)级别的资源限制，包括：</p>\n<ul>\n<li>pod 数量</li>\n<li>service 数量</li>\n<li>resourceQuota 数量 等</li>\n</ul>\n</li>\n</ol>\n<p><strong>Endpoints Controller</strong> 检测到pod的事件，则会更新对应Service 的Endpoints</p>\n<h4 id=\"Job-Controller-amp-amp-CronJob-Controller\"><a href=\"#Job-Controller-amp-amp-CronJob-Controller\" class=\"headerlink\" title=\"Job Controller &amp;&amp; CronJob Controller\"></a>Job Controller &amp;&amp; CronJob Controller</h4><p>Job Controller 控制的对象，直接就是 Pod。</p>\n<h4 id=\"DeamonSet-controller\"><a href=\"#DeamonSet-controller\" class=\"headerlink\" title=\"DeamonSet controller\"></a>DeamonSet controller</h4><h2 id=\"Scheduler\"><a href=\"#Scheduler\" class=\"headerlink\" title=\"Scheduler\"></a>Scheduler</h2><p>scheduler 的作用是将待调度的 pod（新建的pod，rs为补足副本而创建的pod等）按照待定的调度算法和调度策略绑定（Binding)到集群中的某个合适的Node上，并将绑定信息写入 etcd。</p>\n<p>整个过程涉及三个对象：<strong>待调度pod列表</strong>(podQueue)，<strong>可用node列表</strong>，以及<strong>调度算法和调度策略</strong>.</p>\n<p><img src=\"/img/k8s/4.png\" alt=\"image\"></p>\n<p>1）通过调度算法为待调度Pod列表的每个Pod从Node列表中选择一个最适合的Node，并将信息写入etcd中</p>\n<p>2）kubelet通过API Server监听到kubernetes Scheduler产生的Pod绑定信息，然后获取对应的Pod清单，下载Image，并启动容器。</p>\n<h4 id=\"调度资源监听\"><a href=\"#调度资源监听\" class=\"headerlink\" title=\"调度资源监听\"></a>调度资源监听</h4><p><code>kube-apiserver</code> 提供了一套 <code>Watch</code> 机制给 <code>kubelet</code>、<code>kube-controller-manager</code>、 <code>kube-scheduler</code> 等组件用来监控各种资源(Pod、Node、Service等)的变化，类似于消息中间件里的发布-订阅模式（Push）， <code>kube-apiserver</code> 能够<strong>主动通知</strong>这些组件。</p>\n<h4 id=\"调度节点分配：\"><a href=\"#调度节点分配：\" class=\"headerlink\" title=\"调度节点分配：\"></a>调度节点分配：</h4><p>调度分为几个部分：首先是过滤掉不满足条件的节点，这个过程称为预选（ predicate）；然后对通过的节点按照优先级排序，这个是优选（ priority）；最后从中选择优先级最高的节点。如果中间任何一步骤有错误，就直接返回错误。</p>\n<p>predicate 有一系列的算法可以使用：</p>\n<ul>\n<li><code>PodFitsResources</code>：节点上剩余的资源是否大于 pod 请求的资源</li>\n<li><code>PodFitsHost</code>：如果 pod 指定了 NodeName，检查节点名称是否和 NodeName 匹配</li>\n<li><code>PodFitsHostPorts</code>：节点上已经使用的 port 是否和 pod 申请的 port 冲突</li>\n<li><code>PodSelectorMatches</code>：过滤掉和 pod 指定的 label 不匹配的节点</li>\n<li><code>NoDiskConflict</code>：已经 mount 的 volume 和 pod 指定的 volume 不冲突，除非它们都是只读</li>\n</ul>\n<p>如果在 predicate 过程中没有合适的节点，pod 会一直在 <code>pending</code> 状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续 priorities 过程：<br>按照优先级大小对节点排序。</p>\n<p>优选（ priority)</p>\n<p>优先级由一系列键值对组成，键是该优先级项的名称，值是它的权重（该项的重要性）。这些优先级选项包括：</p>\n<ul>\n<li><code>LeastRequestedPriority</code>：通过计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高。换句话说，这个优先级指标倾向于资源使用比例更低的节点</li>\n<li><code>ImageLocalityPriority</code>：倾向于已经有要使用镜像的节点，镜像总大小值越大，权重越高</li>\n</ul>\n<p>通过算法对所有的优先级项目和权重进行计算，得出最终的结果。为待调度的 Pod 分配一个 Node ，同时将分配结果通过 <code>kube-apiserver</code> 写入 <code>etcd</code>；</p>\n<h4 id=\"调度策略\"><a href=\"#调度策略\" class=\"headerlink\" title=\"调度策略\"></a>调度策略</h4><p><strong>NodeSelector</strong></p>\n<p><code>nodeSelector</code> 是最简单的控制方式。 <code>nodeSelector</code> 是 PodSpec 中的一个字段，它指定了键-值对的映射。如果想要 pod 能够运行在某个 node 上，那么这个 node 必须具有所有指定的键-值对的标签（node 也能拥有其它标签）。</p>\n<p>列出 node 的时候指定 <code>--show-labels</code> 参数就能查看 node 都添加了哪些 label：</p>\n<p>除了自己定义的 label 之外，kubernetes 还会自动给集群中的节点添加一些 label，比如：</p>\n<ul>\n<li><code>kubernetes.io/hostname</code>：节点的 hostname 名称</li>\n<li><code>beta.kubernetes.io/os</code>： 节点安装的操作系统</li>\n<li><code>beta.kubernetes.io/arch</code>：节点的架构类型</li>\n</ul>\n<p>除了设置Node Selector之外，还可以通过Node Name 直接指定Node，但还是<strong>建议使用Node Selector</strong>，label进行选择是一种弱绑定，直接指定Node Name是强绑定，Node失效时会导致Pod无法调度。</p>\n<p><strong>亲和性</strong>特性包含了两种类型的亲和性，”node 亲和性” 和 “pod 间的亲和性/反亲和性”，Pod 间以 pod 标签作为约束。</p>\n<p><strong>亲和性调度（Affinity）</strong></p>\n<p>Node Affinity</p>\n<ul>\n<li>硬亲和性：requiredDuringSchedulingIgnoredDuringExecution</li>\n<li>软亲和性：preferredDuringSchedulingIgnoredDuringExecution <ul>\n<li>如果一个 node 的标签在运行时发生改变，从而导致 pod 的亲和性规则不再被满足时，pod 也仍然会继续运行在 node 上。</li>\n</ul>\n</li>\n</ul>\n<p>Pod Affinity</p>\n<ul>\n<li>硬亲和性：requiredDuringSchedulingIgnoredDuringExecution </li>\n<li>preferredDuringSchedulingIgnoredDuringExecution</li>\n</ul>\n<p><strong>反亲和性（Anti-affinity）</strong></p>\n<p><strong>Taint 和 toleration</strong> （比如label idc=idc1,比如GPU资源）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#添加一个 taint</span><br><span class=\"line\">kubectl taint nodes node1 key=value:NoSchedule</span><br><span class=\"line\">#这个 taint 的 key 为 key 且 value 为 value，并且这个 taint 的作用是 NoSchedule</span><br></pre></td></tr></table></figure>\n<p>PodSpec 指定一个 toleration</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tolerations: </span><br><span class=\"line\">- key: key</span><br><span class=\"line\">  operator: Exists</span><br><span class=\"line\">  value: value</span><br><span class=\"line\">  effect: NoSchedule</span><br></pre></td></tr></table></figure>\n<p>PreferNoSchedule （软亲和性）</p>\n<h2 id=\"kubelet\"><a href=\"#kubelet\" class=\"headerlink\" title=\"kubelet\"></a>kubelet</h2><p>在kubernetes集群中，每个Node节点都会启动kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器。kubelet会在API Server上注册节点信息，定期向Master汇报节点资源使用情况，并通过cAdvisor监控容器和节点资源。可以把kubelet理解成【Server-Agent】架构中的agent，是Node上的pod管家。</p>\n<p><strong>容器健康检查</strong></p>\n<p>提供Probe 机制，以更精确的判断Pod和容器：<br><strong>Liveness Prode</strong> ：用于容器的自定义健康检查，如果检查失败，将杀死容器，然后根据pod的重启策略了来决定是否重启容器。还可以指定initialDelaySeconds，用于确定状态检查的宽限期，以便容器执行必要的初始化。<br><strong>Readiness Probe</strong> ：如果检查失败，会将该pod 从服务代理的分发后端去除，不再发送请求给pod。</p>\n<p>目前有三种类型检查方式<br>Http 健康检查 ：返回200～399认为成功<br>Container Exec：容器内执行命令，状态0退出，则视为成功<br>Tcp：如果可以建立连接则认为成功，否则失败。</p>\n<p><strong>资源上报</strong></p>\n<p>继承 cAdvisor 定时上报节点信息</p>\n<p>健康检查监视器由kubelet 代理</p>\n<h4 id=\"kube-proxy\"><a href=\"#kube-proxy\" class=\"headerlink\" title=\"kube-proxy\"></a>kube-proxy</h4><p>Service 在很多情况下知识一个概念，而真正将Service 的作用落实的是背后的 kube-proxy服务进程。</p>\n<p>在k8s 集群的每个Node上都会运行一个 kube-proxy 服务进程，可以看作Service 的透明代理兼负载均衡器，核心是讲到某个 service 的访问请求转移到后端的多个pod 实例上。</p>\n<p>由于iptables 机制针对的是本都的kube-proxy端口，所以每个Node上都要运行 kube-proxy 组件，这样，在集群内部，我们可以再任意Node上发起对 Service 的访问请求。</p>\n<p>kube-proxy  更新iptables 会在本机的 <strong>Iptables</strong> 的NAT表中添加4条规则链路。</p>\n<ol>\n<li>从容器中通过 serviceClusterIp 和端口访问Service 的请求</li>\n<li>从主机中通过ServiceClusterIp和端口访问Service的请求</li>\n<li>从容器中通过 Service 的NodePort 端口访问Service的请求</li>\n<li>从主机中通过Service 的NodePort 端口号访问Service的请求</li>\n</ol>\n<p>运行在每个Node 上的kube-proxy进程其实就是一个智能的软件负载均衡器。</p>\n<p>简单的网络代理和负载均衡器，负责Service的实现：实现从Pod到Service，以及NodePort向Service的访问。</p>\n<p>采用 iptables 来实现LB<br>实现方式：<br>kube-proxy 监控服务/端点增删改，对每个服务配置ipitables规则，捕获Service 的ClusterIp 和端口的流量，并将流量重定向到服务的后端之一。默认后端的选择是随机的,可以设置基于客户端ip的会话关联。</p>\n<p>默认通过iptables来配置对应的NAT转发，自身不再参与转发过程。</p>\n<h2 id=\"yaml配置\"><a href=\"#yaml配置\" class=\"headerlink\" title=\"yaml配置\"></a>yaml配置</h2><p>Deployment yaml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-deployment</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: nginx</span><br><span class=\"line\">  replicas: 2</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: nginx</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: nginx</span><br><span class=\"line\">        image: nginx:1.7.9</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 80</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">           requests:</span><br><span class=\"line\">             cpu: 0.05</span><br><span class=\"line\">             memory: 16Mi</span><br></pre></td></tr></table></figure>\n<p>Service yaml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-svc</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">      app: nginx</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">      - protocol: TCP</span><br><span class=\"line\">        port: 8881</span><br><span class=\"line\">        targetPort: 80</span><br></pre></td></tr></table></figure>\n<h4 id=\"部分命令\"><a href=\"#部分命令\" class=\"headerlink\" title=\"部分命令\"></a>部分命令</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get  all  --all-namespaces=true</span><br><span class=\"line\">kubectl describe ***</span><br><span class=\"line\">kubectl get pods -n kube-system</span><br><span class=\"line\">kubectl apply -f  *.yaml</span><br><span class=\"line\">kubectl get *** -o yaml</span><br><span class=\"line\">kubectl edit deployment.apps/nginx-deployment</span><br><span class=\"line\">kubectl exec $&#123;POD_NAME&#125; -c $&#123;CONTAINER_NAME&#125; -- $&#123;CMD&#125; $&#123;ARG1&#125; $&#123;ARG2&#125; ... $&#123;ARGN&#125;</span><br></pre></td></tr></table></figure>"},{"title":"使用Loki查询日志","date":"2019-10-17T19:25:10.000Z","share":true,"_content":"![1.png](/img/loki/logo.png)\n\nloki 是 grafana 公司出的日志查询工具，区别es，只对标签不对数据做索引，更轻量。\n\n![1.png](/img/loki/1.png)\n\n[查询语句](https://github.com/grafana/loki/blob/65ba42a6e7dc975d6f25b15fc6f9b8d72446b3e2/docs/logql.md)：\n\n```\n{job=\"ingress-nginx/nginx-ingress\"} |=\"php-sht-payment-develop-http\" |=\"refund/create\"\n{job=\"php-sht/payment-develop\",stream=\"neo-log\"} !=\"ShopNotifyJob\" \n{job=~\"php-sht/payment-develop.*\"} |~\"shop_refund\" !~\"15712\" #正则\n```\n\n**promtail** 作为loki的数据采集客户端，在k8s部署采用服务发现的形式监控所有容器标准输入输出。业务日志监控可以采用sidecar方式放在服务pod里，把日志文件mount 到本地，推给loki.\n\npromtail.yaml 普通配置\n```\nserver:\n  http_listen_port: 3101\nscrape_configs:\n  - job_name: payment-develop\n    entry_parser: raw\n    static_configs:\n      - targets:\n         - localhost\n        labels:\n          job: php-sht/payment-develop\n          stream: neo-log\n          __path__: /var/www/payment/runtime/logs/*.log\n```\n<!-- more -->\n自定义metrics [pipeline 配置](https://github.com/grafana/loki/blob/b74db24a007511d437c459aa36c693dc7dae8409/docs/logentry/processing-log-lines.md#metrics)\n\n```\nserver:\n  http_listen_port: 3101\nclient:\n  url: http://172.16.101.117:3100/api/prom/push\nscrape_configs:\n- job_name: payment-develop #不参与查询\n  static_configs:\n  - targets:\n      - localhost\n    labels:\n      job: php-sht/payment-develop #生成查询标签\n      stream: neo-log\n      __path__: /var/www/payment/runtime/logs/*.log\n  pipeline_stages:\n  - match:\n      selector: '{stream=\"neo-log\"}'\n      stages:\n       - regex:\n          expression: \"^(?P<message>.*)$\" \n       - regex:\n          expression: \"^.*(?P<warning_msg>(warning|WARNING)).*$\" \n       - regex:\n          expression: \"^.*(?P<error_msg>(error|ERROR)).*$\" \n       - metrics: #根据日志生成mertrics,注意此统计只能针对当前job\n           log_lines_total:\n             type: Counter\n             description: \"log total\"\n             source: message\n             config:\n               action: inc\n           error_log_total:  #统计错误日志总数\n             type: Counter\n             description: \"error message total\"\n             source: error_msg\n             config:\n               action: inc \n           warning_log_total:  #统计warning日志总数\n             type: Counter\n             description: \"warning message total\"\n             source: warning_msg\n             config:\n               action: inc \n```\n服务启动后会在 3101 端口产生自定义metrics数据，以promtail_custom开头，如:promtail_custom_log_lines_total\n\nk8s中配置prometheus服务发现，在service 中配置：\n```\nannotations:\n  prometheus.io/port: \"3101\"\n  prometheus.io/scrape: \"true\"\n```\n\n在 grafana 新建监控指标:\n\n![2.png](/img/loki/2.png)\n\n监控日志总数，warning日志、error日志增长速率:\n\n![3.png](/img/loki/3.png)","source":"_posts/loki.md","raw":"---\ntitle: \"使用Loki查询日志\"\ndate: 2019-10-17 19:25:10\ntags: [loki,promtal,grafana,日志]\nshare: true\n---\n![1.png](/img/loki/logo.png)\n\nloki 是 grafana 公司出的日志查询工具，区别es，只对标签不对数据做索引，更轻量。\n\n![1.png](/img/loki/1.png)\n\n[查询语句](https://github.com/grafana/loki/blob/65ba42a6e7dc975d6f25b15fc6f9b8d72446b3e2/docs/logql.md)：\n\n```\n{job=\"ingress-nginx/nginx-ingress\"} |=\"php-sht-payment-develop-http\" |=\"refund/create\"\n{job=\"php-sht/payment-develop\",stream=\"neo-log\"} !=\"ShopNotifyJob\" \n{job=~\"php-sht/payment-develop.*\"} |~\"shop_refund\" !~\"15712\" #正则\n```\n\n**promtail** 作为loki的数据采集客户端，在k8s部署采用服务发现的形式监控所有容器标准输入输出。业务日志监控可以采用sidecar方式放在服务pod里，把日志文件mount 到本地，推给loki.\n\npromtail.yaml 普通配置\n```\nserver:\n  http_listen_port: 3101\nscrape_configs:\n  - job_name: payment-develop\n    entry_parser: raw\n    static_configs:\n      - targets:\n         - localhost\n        labels:\n          job: php-sht/payment-develop\n          stream: neo-log\n          __path__: /var/www/payment/runtime/logs/*.log\n```\n<!-- more -->\n自定义metrics [pipeline 配置](https://github.com/grafana/loki/blob/b74db24a007511d437c459aa36c693dc7dae8409/docs/logentry/processing-log-lines.md#metrics)\n\n```\nserver:\n  http_listen_port: 3101\nclient:\n  url: http://172.16.101.117:3100/api/prom/push\nscrape_configs:\n- job_name: payment-develop #不参与查询\n  static_configs:\n  - targets:\n      - localhost\n    labels:\n      job: php-sht/payment-develop #生成查询标签\n      stream: neo-log\n      __path__: /var/www/payment/runtime/logs/*.log\n  pipeline_stages:\n  - match:\n      selector: '{stream=\"neo-log\"}'\n      stages:\n       - regex:\n          expression: \"^(?P<message>.*)$\" \n       - regex:\n          expression: \"^.*(?P<warning_msg>(warning|WARNING)).*$\" \n       - regex:\n          expression: \"^.*(?P<error_msg>(error|ERROR)).*$\" \n       - metrics: #根据日志生成mertrics,注意此统计只能针对当前job\n           log_lines_total:\n             type: Counter\n             description: \"log total\"\n             source: message\n             config:\n               action: inc\n           error_log_total:  #统计错误日志总数\n             type: Counter\n             description: \"error message total\"\n             source: error_msg\n             config:\n               action: inc \n           warning_log_total:  #统计warning日志总数\n             type: Counter\n             description: \"warning message total\"\n             source: warning_msg\n             config:\n               action: inc \n```\n服务启动后会在 3101 端口产生自定义metrics数据，以promtail_custom开头，如:promtail_custom_log_lines_total\n\nk8s中配置prometheus服务发现，在service 中配置：\n```\nannotations:\n  prometheus.io/port: \"3101\"\n  prometheus.io/scrape: \"true\"\n```\n\n在 grafana 新建监控指标:\n\n![2.png](/img/loki/2.png)\n\n监控日志总数，warning日志、error日志增长速率:\n\n![3.png](/img/loki/3.png)","slug":"loki","published":1,"updated":"2019-11-08T17:53:52.512Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck2qgz8vn000f3covxc3p5736","content":"<p><img src=\"/img/loki/logo.png\" alt=\"1.png\"></p>\n<p>loki 是 grafana 公司出的日志查询工具，区别es，只对标签不对数据做索引，更轻量。</p>\n<p><img src=\"/img/loki/1.png\" alt=\"1.png\"></p>\n<p><a href=\"https://github.com/grafana/loki/blob/65ba42a6e7dc975d6f25b15fc6f9b8d72446b3e2/docs/logql.md\" target=\"_blank\" rel=\"noopener\">查询语句</a>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;job=&quot;ingress-nginx/nginx-ingress&quot;&#125; |=&quot;php-sht-payment-develop-http&quot; |=&quot;refund/create&quot;</span><br><span class=\"line\">&#123;job=&quot;php-sht/payment-develop&quot;,stream=&quot;neo-log&quot;&#125; !=&quot;ShopNotifyJob&quot; </span><br><span class=\"line\">&#123;job=~&quot;php-sht/payment-develop.*&quot;&#125; |~&quot;shop_refund&quot; !~&quot;15712&quot; #正则</span><br></pre></td></tr></table></figure>\n<p><strong>promtail</strong> 作为loki的数据采集客户端，在k8s部署采用服务发现的形式监控所有容器标准输入输出。业务日志监控可以采用sidecar方式放在服务pod里，把日志文件mount 到本地，推给loki.</p>\n<p>promtail.yaml 普通配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server:</span><br><span class=\"line\">  http_listen_port: 3101</span><br><span class=\"line\">scrape_configs:</span><br><span class=\"line\">  - job_name: payment-develop</span><br><span class=\"line\">    entry_parser: raw</span><br><span class=\"line\">    static_configs:</span><br><span class=\"line\">      - targets:</span><br><span class=\"line\">         - localhost</span><br><span class=\"line\">        labels:</span><br><span class=\"line\">          job: php-sht/payment-develop</span><br><span class=\"line\">          stream: neo-log</span><br><span class=\"line\">          __path__: /var/www/payment/runtime/logs/*.log</span><br></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<p>自定义metrics <a href=\"https://github.com/grafana/loki/blob/b74db24a007511d437c459aa36c693dc7dae8409/docs/logentry/processing-log-lines.md#metrics\" target=\"_blank\" rel=\"noopener\">pipeline 配置</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server:</span><br><span class=\"line\">  http_listen_port: 3101</span><br><span class=\"line\">client:</span><br><span class=\"line\">  url: http://172.16.101.117:3100/api/prom/push</span><br><span class=\"line\">scrape_configs:</span><br><span class=\"line\">- job_name: payment-develop #不参与查询</span><br><span class=\"line\">  static_configs:</span><br><span class=\"line\">  - targets:</span><br><span class=\"line\">      - localhost</span><br><span class=\"line\">    labels:</span><br><span class=\"line\">      job: php-sht/payment-develop #生成查询标签</span><br><span class=\"line\">      stream: neo-log</span><br><span class=\"line\">      __path__: /var/www/payment/runtime/logs/*.log</span><br><span class=\"line\">  pipeline_stages:</span><br><span class=\"line\">  - match:</span><br><span class=\"line\">      selector: &apos;&#123;stream=&quot;neo-log&quot;&#125;&apos;</span><br><span class=\"line\">      stages:</span><br><span class=\"line\">       - regex:</span><br><span class=\"line\">          expression: &quot;^(?P&lt;message&gt;.*)$&quot; </span><br><span class=\"line\">       - regex:</span><br><span class=\"line\">          expression: &quot;^.*(?P&lt;warning_msg&gt;(warning|WARNING)).*$&quot; </span><br><span class=\"line\">       - regex:</span><br><span class=\"line\">          expression: &quot;^.*(?P&lt;error_msg&gt;(error|ERROR)).*$&quot; </span><br><span class=\"line\">       - metrics: #根据日志生成mertrics,注意此统计只能针对当前job</span><br><span class=\"line\">           log_lines_total:</span><br><span class=\"line\">             type: Counter</span><br><span class=\"line\">             description: &quot;log total&quot;</span><br><span class=\"line\">             source: message</span><br><span class=\"line\">             config:</span><br><span class=\"line\">               action: inc</span><br><span class=\"line\">           error_log_total:  #统计错误日志总数</span><br><span class=\"line\">             type: Counter</span><br><span class=\"line\">             description: &quot;error message total&quot;</span><br><span class=\"line\">             source: error_msg</span><br><span class=\"line\">             config:</span><br><span class=\"line\">               action: inc </span><br><span class=\"line\">           warning_log_total:  #统计warning日志总数</span><br><span class=\"line\">             type: Counter</span><br><span class=\"line\">             description: &quot;warning message total&quot;</span><br><span class=\"line\">             source: warning_msg</span><br><span class=\"line\">             config:</span><br><span class=\"line\">               action: inc</span><br></pre></td></tr></table></figure>\n<p>服务启动后会在 3101 端口产生自定义metrics数据，以promtail_custom开头，如:promtail_custom_log_lines_total</p>\n<p>k8s中配置prometheus服务发现，在service 中配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">annotations:</span><br><span class=\"line\">  prometheus.io/port: &quot;3101&quot;</span><br><span class=\"line\">  prometheus.io/scrape: &quot;true&quot;</span><br></pre></td></tr></table></figure></p>\n<p>在 grafana 新建监控指标:</p>\n<p><img src=\"/img/loki/2.png\" alt=\"2.png\"></p>\n<p>监控日志总数，warning日志、error日志增长速率:</p>\n<p><img src=\"/img/loki/3.png\" alt=\"3.png\"></p>\n","site":{"data":{}},"excerpt":"<p><img src=\"/img/loki/logo.png\" alt=\"1.png\"></p>\n<p>loki 是 grafana 公司出的日志查询工具，区别es，只对标签不对数据做索引，更轻量。</p>\n<p><img src=\"/img/loki/1.png\" alt=\"1.png\"></p>\n<p><a href=\"https://github.com/grafana/loki/blob/65ba42a6e7dc975d6f25b15fc6f9b8d72446b3e2/docs/logql.md\" target=\"_blank\" rel=\"noopener\">查询语句</a>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;job=&quot;ingress-nginx/nginx-ingress&quot;&#125; |=&quot;php-sht-payment-develop-http&quot; |=&quot;refund/create&quot;</span><br><span class=\"line\">&#123;job=&quot;php-sht/payment-develop&quot;,stream=&quot;neo-log&quot;&#125; !=&quot;ShopNotifyJob&quot; </span><br><span class=\"line\">&#123;job=~&quot;php-sht/payment-develop.*&quot;&#125; |~&quot;shop_refund&quot; !~&quot;15712&quot; #正则</span><br></pre></td></tr></table></figure>\n<p><strong>promtail</strong> 作为loki的数据采集客户端，在k8s部署采用服务发现的形式监控所有容器标准输入输出。业务日志监控可以采用sidecar方式放在服务pod里，把日志文件mount 到本地，推给loki.</p>\n<p>promtail.yaml 普通配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server:</span><br><span class=\"line\">  http_listen_port: 3101</span><br><span class=\"line\">scrape_configs:</span><br><span class=\"line\">  - job_name: payment-develop</span><br><span class=\"line\">    entry_parser: raw</span><br><span class=\"line\">    static_configs:</span><br><span class=\"line\">      - targets:</span><br><span class=\"line\">         - localhost</span><br><span class=\"line\">        labels:</span><br><span class=\"line\">          job: php-sht/payment-develop</span><br><span class=\"line\">          stream: neo-log</span><br><span class=\"line\">          __path__: /var/www/payment/runtime/logs/*.log</span><br></pre></td></tr></table></figure></p>","more":"<p>自定义metrics <a href=\"https://github.com/grafana/loki/blob/b74db24a007511d437c459aa36c693dc7dae8409/docs/logentry/processing-log-lines.md#metrics\" target=\"_blank\" rel=\"noopener\">pipeline 配置</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server:</span><br><span class=\"line\">  http_listen_port: 3101</span><br><span class=\"line\">client:</span><br><span class=\"line\">  url: http://172.16.101.117:3100/api/prom/push</span><br><span class=\"line\">scrape_configs:</span><br><span class=\"line\">- job_name: payment-develop #不参与查询</span><br><span class=\"line\">  static_configs:</span><br><span class=\"line\">  - targets:</span><br><span class=\"line\">      - localhost</span><br><span class=\"line\">    labels:</span><br><span class=\"line\">      job: php-sht/payment-develop #生成查询标签</span><br><span class=\"line\">      stream: neo-log</span><br><span class=\"line\">      __path__: /var/www/payment/runtime/logs/*.log</span><br><span class=\"line\">  pipeline_stages:</span><br><span class=\"line\">  - match:</span><br><span class=\"line\">      selector: &apos;&#123;stream=&quot;neo-log&quot;&#125;&apos;</span><br><span class=\"line\">      stages:</span><br><span class=\"line\">       - regex:</span><br><span class=\"line\">          expression: &quot;^(?P&lt;message&gt;.*)$&quot; </span><br><span class=\"line\">       - regex:</span><br><span class=\"line\">          expression: &quot;^.*(?P&lt;warning_msg&gt;(warning|WARNING)).*$&quot; </span><br><span class=\"line\">       - regex:</span><br><span class=\"line\">          expression: &quot;^.*(?P&lt;error_msg&gt;(error|ERROR)).*$&quot; </span><br><span class=\"line\">       - metrics: #根据日志生成mertrics,注意此统计只能针对当前job</span><br><span class=\"line\">           log_lines_total:</span><br><span class=\"line\">             type: Counter</span><br><span class=\"line\">             description: &quot;log total&quot;</span><br><span class=\"line\">             source: message</span><br><span class=\"line\">             config:</span><br><span class=\"line\">               action: inc</span><br><span class=\"line\">           error_log_total:  #统计错误日志总数</span><br><span class=\"line\">             type: Counter</span><br><span class=\"line\">             description: &quot;error message total&quot;</span><br><span class=\"line\">             source: error_msg</span><br><span class=\"line\">             config:</span><br><span class=\"line\">               action: inc </span><br><span class=\"line\">           warning_log_total:  #统计warning日志总数</span><br><span class=\"line\">             type: Counter</span><br><span class=\"line\">             description: &quot;warning message total&quot;</span><br><span class=\"line\">             source: warning_msg</span><br><span class=\"line\">             config:</span><br><span class=\"line\">               action: inc</span><br></pre></td></tr></table></figure>\n<p>服务启动后会在 3101 端口产生自定义metrics数据，以promtail_custom开头，如:promtail_custom_log_lines_total</p>\n<p>k8s中配置prometheus服务发现，在service 中配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">annotations:</span><br><span class=\"line\">  prometheus.io/port: &quot;3101&quot;</span><br><span class=\"line\">  prometheus.io/scrape: &quot;true&quot;</span><br></pre></td></tr></table></figure></p>\n<p>在 grafana 新建监控指标:</p>\n<p><img src=\"/img/loki/2.png\" alt=\"2.png\"></p>\n<p>监控日志总数，warning日志、error日志增长速率:</p>\n<p><img src=\"/img/loki/3.png\" alt=\"3.png\"></p>"},{"title":" 测试服务迁移k8s集群记录 (一)","date":"2019-11-08T18:40:10.000Z","share":true,"_content":"\n前言: 组内给了3台新机器，要把之前的服务全迁到新机器。共6个服务，2个在之前的 k8s 集群，其他4个在物理机。\n\n已经迁移完成，记录下实施过程，大致分3步: 新 k8s 集群搭建、监控日志系统部署、业务服务迁移。\n\n### k8s 集群搭建\n\n因为是新机器，准备尝试下 k8s  master 高可用方案，运维给的3台机器信息如下，两个mastet 建立ssh 信任，服务规划参考老集群。\n\n| 主机名        | IP        | 角色     | 服务        |\n| ------------- | --------- | -------- | ----------- |\n| soa-test-a001 | 10.2.4.34 | master01 | 监控、日志  |\n| soa-test-a002 | 10.2.4.35 | master02 | CI、Ingress |\n| soa-test-a003 | 10.2.4.36 | node01   | 业务服务    |\n\n只有两台master， 我们使用的是堆叠式 etcd 拓扑结构，如图：\n\n![kubeadm-ha-topology-stacked-etcd](/img/k8s/5.svg)机器已经安装 docker ，直接开始使用 kubeadm 安装 k8s \n<!-- more -->\n\n**安装 kubeadm**\n\n```\ncat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\n\nname=Kubernetes\n\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\n\nenabled=1\n\ngpgcheck=1\n\nrepo_gpgcheck=1\n\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\n\nEOF\n\nsetenforce 0\nyum install -y kubelet kubeadm kubectl\nsystemctl enable kubelet && systemctl start kubelet\n```\n\n**生成初始化 kubeadm 配置文件**\n\n```\nkubeadm config print init-defaults > kubeadm-config.yaml\n```\n\n使用 master01: 6444 做 api负载，修改如下：\n\n```\napiVersion: kubeadm.k8s.io/v1beta2\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 10.2.4.34 #master01机器ip\n  bindPort: 6443 #apiServer运行的端口\nnodeRegistration:\n  criSocket: /var/run/dockershim.sock\n  name: soa-test-a001\n  taints:\n  - effect: NoSchedule\n    key: node-role.kubernetes.io/master\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta2\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrolPlaneEndpoint: 10.2.4.34:6444 #控制面板api端口，用来做api负载均衡\ncontrollerManager: {}\ndns:\n  type: CoreDNS\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.aliyuncs.com/google_containers #改为阿里云仓库\nkind: ClusterConfiguration\nkubernetesVersion: v1.16.0\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 10.244.0.0/16 #pod网络配置\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\n```\n\n开始安装，由于使用阿里镜像地址，安装较快，默认是 最新版 1.16.2\n\n```\nkubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log\n```\n\n**calico 网络：**\n\n```\nkubectl apply -f https://docs.projectcalico.org/master/manifests/calico.yaml\n```\n\n**master02加入集群**\n\n```\nkubeadm join 10.2.4.34:6444 --token abcdef.0123456789abcdef \\\n    --discovery-token-ca-cert-hash sha256:ee24d007b3eb73******bc7385528dcc549105b1e54642d82b7f23f718 \\\n    --control-plane --certificate-key febdcefffebcfe60c6******5680f1110a4073ebd1e5c578c5c02a897\n```\n\n测试 master02 是否提供服务，可以修改master02 上的 ~/.kube/config 文件，修改server 为本机 ip + 6443端口，执行kubectl get nodes 成功，说明master02 同样提供 apiServer 功能。\n\n**haproxy 做负载**\n\n```\nfrontend kube-api-balance\n    bind *:6444\n    maxconn 30000                    #定义此端口上的maxconn\n    default_backend default_servers  #请求定向至后端服务群default_servers\n\nbackend default_servers    #定义后端服务群default_servers\n    balance roundrobin\n    server def.srv1 10.2.4.34:6443\n    server def.srv2 10.2.4.35:6443\n```\n\n运行haproxy\n\n```\ndocker run -d \\\n    --network=host \\\n    --restart=always \\\n    -v /root/sh/haproxy.cfg:/etc/haproxy/haproxy.cfg \\\n    --name haproxy \\\n    haproxy -f /etc/haproxy/haproxy.cfg\n```\n\n顺便贴下使用 nginx 转发配置\n\n```\nstream {\n        server {\n                listen     6444;\n                proxy_pass stream_backend;\n        }\n        upstream stream_backend {\n                server 10.2.4.34:6443;\n                server 10.2.4.35:6443;\n        }\n\n}\n```\n遗憾的是这里并没有使用 keepalived 对ip做高可用 :( \n\n\n### Dashboard 安装\n\n主要参考[安装dashboard](https://www.cnblogs.com/bluersw/p/11747161.html )，之前使用的1.10版，新版提示更友好，资源编辑更方便。贴一下 `kube-config` 的生成，我们用这个文件来登录 dashboard\n\n```\nkubectl config view --raw=true > kube-config\n```\n\n使用一个有权限的 serviceAccount 来配置，contexts 部分修改 user 为 serviceAccount name，users 部分，修改 name ，增加 token 认证。注意 token:  后面是一个空格，非换行\n\n```\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: lGSUNBVE******UtLS0tLQo=\n    server: https://10.2.4.34:6444\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: dashboard-admin  #改为serviceAccount\n  name: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes\nkind: Config\npreferences: {}\nusers:\n- name: dashboard-admin  #改为serviceAccount\n  user:  #使用token 认证\n    token: eyJhbGciOiJSUzI******LdK0kpfSw\n```\n\n截图：\n\n![6.png](/img/k8s/6.png)\n\n**遇到的问题：**\n\n遇到最大的问题是 在 master02 上执行 命令，延时5秒才返回，在上面起的pod，访问外网总提示超时，后来用kube-adm reset 了下，再次加入集群，莫名好了 -__-\n\n\n\n本篇就写到这，后面会更新监控、日志的安装，已经使用 gitlab runner + helm3 来部署服务.\n\n\n\n**参考：**\nhttps://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/\nhttps://blog.csdn.net/networken/article/details/89599004\nhttps://www.kubernetes.org.cn/5551.html\n安装dashboard:\nhttps://www.cnblogs.com/bluersw/p/11747161.html \nscp 信任:\nhttps://www.cnblogs.com/mchina/archive/2013/03/15/2956017.html \nkubeadm join 使用的 token 过期之后，如何加入集群:\nhttps://blog.csdn.net/wo18237095579/article/details/89884369 \n\n","source":"_posts/k8s-migration-1.md","raw":"---\ntitle: \" 测试服务迁移k8s集群记录 (一)\"\ndate: 2019-11-08 18:40:10\ntags: [k8s,kube-adm,haproxy]\nshare: true\n---\n\n前言: 组内给了3台新机器，要把之前的服务全迁到新机器。共6个服务，2个在之前的 k8s 集群，其他4个在物理机。\n\n已经迁移完成，记录下实施过程，大致分3步: 新 k8s 集群搭建、监控日志系统部署、业务服务迁移。\n\n### k8s 集群搭建\n\n因为是新机器，准备尝试下 k8s  master 高可用方案，运维给的3台机器信息如下，两个mastet 建立ssh 信任，服务规划参考老集群。\n\n| 主机名        | IP        | 角色     | 服务        |\n| ------------- | --------- | -------- | ----------- |\n| soa-test-a001 | 10.2.4.34 | master01 | 监控、日志  |\n| soa-test-a002 | 10.2.4.35 | master02 | CI、Ingress |\n| soa-test-a003 | 10.2.4.36 | node01   | 业务服务    |\n\n只有两台master， 我们使用的是堆叠式 etcd 拓扑结构，如图：\n\n![kubeadm-ha-topology-stacked-etcd](/img/k8s/5.svg)机器已经安装 docker ，直接开始使用 kubeadm 安装 k8s \n<!-- more -->\n\n**安装 kubeadm**\n\n```\ncat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\n\nname=Kubernetes\n\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\n\nenabled=1\n\ngpgcheck=1\n\nrepo_gpgcheck=1\n\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\n\nEOF\n\nsetenforce 0\nyum install -y kubelet kubeadm kubectl\nsystemctl enable kubelet && systemctl start kubelet\n```\n\n**生成初始化 kubeadm 配置文件**\n\n```\nkubeadm config print init-defaults > kubeadm-config.yaml\n```\n\n使用 master01: 6444 做 api负载，修改如下：\n\n```\napiVersion: kubeadm.k8s.io/v1beta2\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 10.2.4.34 #master01机器ip\n  bindPort: 6443 #apiServer运行的端口\nnodeRegistration:\n  criSocket: /var/run/dockershim.sock\n  name: soa-test-a001\n  taints:\n  - effect: NoSchedule\n    key: node-role.kubernetes.io/master\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta2\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrolPlaneEndpoint: 10.2.4.34:6444 #控制面板api端口，用来做api负载均衡\ncontrollerManager: {}\ndns:\n  type: CoreDNS\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.aliyuncs.com/google_containers #改为阿里云仓库\nkind: ClusterConfiguration\nkubernetesVersion: v1.16.0\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 10.244.0.0/16 #pod网络配置\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\n```\n\n开始安装，由于使用阿里镜像地址，安装较快，默认是 最新版 1.16.2\n\n```\nkubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log\n```\n\n**calico 网络：**\n\n```\nkubectl apply -f https://docs.projectcalico.org/master/manifests/calico.yaml\n```\n\n**master02加入集群**\n\n```\nkubeadm join 10.2.4.34:6444 --token abcdef.0123456789abcdef \\\n    --discovery-token-ca-cert-hash sha256:ee24d007b3eb73******bc7385528dcc549105b1e54642d82b7f23f718 \\\n    --control-plane --certificate-key febdcefffebcfe60c6******5680f1110a4073ebd1e5c578c5c02a897\n```\n\n测试 master02 是否提供服务，可以修改master02 上的 ~/.kube/config 文件，修改server 为本机 ip + 6443端口，执行kubectl get nodes 成功，说明master02 同样提供 apiServer 功能。\n\n**haproxy 做负载**\n\n```\nfrontend kube-api-balance\n    bind *:6444\n    maxconn 30000                    #定义此端口上的maxconn\n    default_backend default_servers  #请求定向至后端服务群default_servers\n\nbackend default_servers    #定义后端服务群default_servers\n    balance roundrobin\n    server def.srv1 10.2.4.34:6443\n    server def.srv2 10.2.4.35:6443\n```\n\n运行haproxy\n\n```\ndocker run -d \\\n    --network=host \\\n    --restart=always \\\n    -v /root/sh/haproxy.cfg:/etc/haproxy/haproxy.cfg \\\n    --name haproxy \\\n    haproxy -f /etc/haproxy/haproxy.cfg\n```\n\n顺便贴下使用 nginx 转发配置\n\n```\nstream {\n        server {\n                listen     6444;\n                proxy_pass stream_backend;\n        }\n        upstream stream_backend {\n                server 10.2.4.34:6443;\n                server 10.2.4.35:6443;\n        }\n\n}\n```\n遗憾的是这里并没有使用 keepalived 对ip做高可用 :( \n\n\n### Dashboard 安装\n\n主要参考[安装dashboard](https://www.cnblogs.com/bluersw/p/11747161.html )，之前使用的1.10版，新版提示更友好，资源编辑更方便。贴一下 `kube-config` 的生成，我们用这个文件来登录 dashboard\n\n```\nkubectl config view --raw=true > kube-config\n```\n\n使用一个有权限的 serviceAccount 来配置，contexts 部分修改 user 为 serviceAccount name，users 部分，修改 name ，增加 token 认证。注意 token:  后面是一个空格，非换行\n\n```\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: lGSUNBVE******UtLS0tLQo=\n    server: https://10.2.4.34:6444\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: dashboard-admin  #改为serviceAccount\n  name: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes\nkind: Config\npreferences: {}\nusers:\n- name: dashboard-admin  #改为serviceAccount\n  user:  #使用token 认证\n    token: eyJhbGciOiJSUzI******LdK0kpfSw\n```\n\n截图：\n\n![6.png](/img/k8s/6.png)\n\n**遇到的问题：**\n\n遇到最大的问题是 在 master02 上执行 命令，延时5秒才返回，在上面起的pod，访问外网总提示超时，后来用kube-adm reset 了下，再次加入集群，莫名好了 -__-\n\n\n\n本篇就写到这，后面会更新监控、日志的安装，已经使用 gitlab runner + helm3 来部署服务.\n\n\n\n**参考：**\nhttps://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/\nhttps://blog.csdn.net/networken/article/details/89599004\nhttps://www.kubernetes.org.cn/5551.html\n安装dashboard:\nhttps://www.cnblogs.com/bluersw/p/11747161.html \nscp 信任:\nhttps://www.cnblogs.com/mchina/archive/2013/03/15/2956017.html \nkubeadm join 使用的 token 过期之后，如何加入集群:\nhttps://blog.csdn.net/wo18237095579/article/details/89884369 \n\n","slug":"k8s-migration-1","published":1,"updated":"2019-11-08T18:15:08.701Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck2qgz8vp000g3cov1mth5tql","content":"<p>前言: 组内给了3台新机器，要把之前的服务全迁到新机器。共6个服务，2个在之前的 k8s 集群，其他4个在物理机。</p>\n<p>已经迁移完成，记录下实施过程，大致分3步: 新 k8s 集群搭建、监控日志系统部署、业务服务迁移。</p>\n<h3 id=\"k8s-集群搭建\"><a href=\"#k8s-集群搭建\" class=\"headerlink\" title=\"k8s 集群搭建\"></a>k8s 集群搭建</h3><p>因为是新机器，准备尝试下 k8s  master 高可用方案，运维给的3台机器信息如下，两个mastet 建立ssh 信任，服务规划参考老集群。</p>\n<table>\n<thead>\n<tr>\n<th>主机名</th>\n<th>IP</th>\n<th>角色</th>\n<th>服务</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>soa-test-a001</td>\n<td>10.2.4.34</td>\n<td>master01</td>\n<td>监控、日志</td>\n</tr>\n<tr>\n<td>soa-test-a002</td>\n<td>10.2.4.35</td>\n<td>master02</td>\n<td>CI、Ingress</td>\n</tr>\n<tr>\n<td>soa-test-a003</td>\n<td>10.2.4.36</td>\n<td>node01</td>\n<td>业务服务</td>\n</tr>\n</tbody>\n</table>\n<p>只有两台master， 我们使用的是堆叠式 etcd 拓扑结构，如图：</p>\n<p><img src=\"/img/k8s/5.svg\" alt=\"kubeadm-ha-topology-stacked-etcd\">机器已经安装 docker ，直接开始使用 kubeadm 安装 k8s<br><a id=\"more\"></a></p>\n<p><strong>安装 kubeadm</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\"></span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\"></span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class=\"line\"></span><br><span class=\"line\">enabled=1</span><br><span class=\"line\"></span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\"></span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\"></span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\"></span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">setenforce 0</span><br><span class=\"line\">yum install -y kubelet kubeadm kubectl</span><br><span class=\"line\">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure>\n<p><strong>生成初始化 kubeadm 配置文件</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm config print init-defaults &gt; kubeadm-config.yaml</span><br></pre></td></tr></table></figure>\n<p>使用 master01: 6444 做 api负载，修改如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class=\"line\">bootstrapTokens:</span><br><span class=\"line\">- groups:</span><br><span class=\"line\">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class=\"line\">  token: abcdef.0123456789abcdef</span><br><span class=\"line\">  ttl: 24h0m0s</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - signing</span><br><span class=\"line\">  - authentication</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: 10.2.4.34 #master01机器ip</span><br><span class=\"line\">  bindPort: 6443 #apiServer运行的端口</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: /var/run/dockershim.sock</span><br><span class=\"line\">  name: soa-test-a001</span><br><span class=\"line\">  taints:</span><br><span class=\"line\">  - effect: NoSchedule</span><br><span class=\"line\">    key: node-role.kubernetes.io/master</span><br><span class=\"line\">---</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controlPlaneEndpoint: 10.2.4.34:6444 #控制面板api端口，用来做api负载均衡</span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns:</span><br><span class=\"line\">  type: CoreDNS</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers #改为阿里云仓库</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: v1.16.0</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  dnsDomain: cluster.local</span><br><span class=\"line\">  podSubnet: 10.244.0.0/16 #pod网络配置</span><br><span class=\"line\">  serviceSubnet: 10.96.0.0/12</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>开始安装，由于使用阿里镜像地址，安装较快，默认是 最新版 1.16.2</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log</span><br></pre></td></tr></table></figure>\n<p><strong>calico 网络：</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f https://docs.projectcalico.org/master/manifests/calico.yaml</span><br></pre></td></tr></table></figure>\n<p><strong>master02加入集群</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm join 10.2.4.34:6444 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">    --discovery-token-ca-cert-hash sha256:ee24d007b3eb73******bc7385528dcc549105b1e54642d82b7f23f718 \\</span><br><span class=\"line\">    --control-plane --certificate-key febdcefffebcfe60c6******5680f1110a4073ebd1e5c578c5c02a897</span><br></pre></td></tr></table></figure>\n<p>测试 master02 是否提供服务，可以修改master02 上的 ~/.kube/config 文件，修改server 为本机 ip + 6443端口，执行kubectl get nodes 成功，说明master02 同样提供 apiServer 功能。</p>\n<p><strong>haproxy 做负载</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">frontend kube-api-balance</span><br><span class=\"line\">    bind *:6444</span><br><span class=\"line\">    maxconn 30000                    #定义此端口上的maxconn</span><br><span class=\"line\">    default_backend default_servers  #请求定向至后端服务群default_servers</span><br><span class=\"line\"></span><br><span class=\"line\">backend default_servers    #定义后端服务群default_servers</span><br><span class=\"line\">    balance roundrobin</span><br><span class=\"line\">    server def.srv1 10.2.4.34:6443</span><br><span class=\"line\">    server def.srv2 10.2.4.35:6443</span><br></pre></td></tr></table></figure>\n<p>运行haproxy</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d \\</span><br><span class=\"line\">    --network=host \\</span><br><span class=\"line\">    --restart=always \\</span><br><span class=\"line\">    -v /root/sh/haproxy.cfg:/etc/haproxy/haproxy.cfg \\</span><br><span class=\"line\">    --name haproxy \\</span><br><span class=\"line\">    haproxy -f /etc/haproxy/haproxy.cfg</span><br></pre></td></tr></table></figure>\n<p>顺便贴下使用 nginx 转发配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stream &#123;</span><br><span class=\"line\">        server &#123;</span><br><span class=\"line\">                listen     6444;</span><br><span class=\"line\">                proxy_pass stream_backend;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        upstream stream_backend &#123;</span><br><span class=\"line\">                server 10.2.4.34:6443;</span><br><span class=\"line\">                server 10.2.4.35:6443;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>遗憾的是这里并没有使用 keepalived 对ip做高可用 :( </p>\n<h3 id=\"Dashboard-安装\"><a href=\"#Dashboard-安装\" class=\"headerlink\" title=\"Dashboard 安装\"></a>Dashboard 安装</h3><p>主要参考<a href=\"https://www.cnblogs.com/bluersw/p/11747161.html\" target=\"_blank\" rel=\"noopener\">安装dashboard</a>，之前使用的1.10版，新版提示更友好，资源编辑更方便。贴一下 <code>kube-config</code> 的生成，我们用这个文件来登录 dashboard</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl config view --raw=true &gt; kube-config</span><br></pre></td></tr></table></figure>\n<p>使用一个有权限的 serviceAccount 来配置，contexts 部分修改 user 为 serviceAccount name，users 部分，修改 name ，增加 token 认证。注意 token:  后面是一个空格，非换行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: lGSUNBVE******UtLS0tLQo=</span><br><span class=\"line\">    server: https://10.2.4.34:6444</span><br><span class=\"line\">  name: kubernetes</span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: kubernetes</span><br><span class=\"line\">    user: dashboard-admin  #改为serviceAccount</span><br><span class=\"line\">  name: kubernetes-admin@kubernetes</span><br><span class=\"line\">current-context: kubernetes-admin@kubernetes</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\">users:</span><br><span class=\"line\">- name: dashboard-admin  #改为serviceAccount</span><br><span class=\"line\">  user:  #使用token 认证</span><br><span class=\"line\">    token: eyJhbGciOiJSUzI******LdK0kpfSw</span><br></pre></td></tr></table></figure>\n<p>截图：</p>\n<p><img src=\"/img/k8s/6.png\" alt=\"6.png\"></p>\n<p><strong>遇到的问题：</strong></p>\n<p>遇到最大的问题是 在 master02 上执行 命令，延时5秒才返回，在上面起的pod，访问外网总提示超时，后来用kube-adm reset 了下，再次加入集群，莫名好了 -__-</p>\n<p>本篇就写到这，后面会更新监控、日志的安装，已经使用 gitlab runner + helm3 来部署服务.</p>\n<p><strong>参考：</strong><br><a href=\"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/</a><br><a href=\"https://blog.csdn.net/networken/article/details/89599004\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/networken/article/details/89599004</a><br><a href=\"https://www.kubernetes.org.cn/5551.html\" target=\"_blank\" rel=\"noopener\">https://www.kubernetes.org.cn/5551.html</a><br>安装dashboard:<br><a href=\"https://www.cnblogs.com/bluersw/p/11747161.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/bluersw/p/11747161.html</a><br>scp 信任:<br><a href=\"https://www.cnblogs.com/mchina/archive/2013/03/15/2956017.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/mchina/archive/2013/03/15/2956017.html</a><br>kubeadm join 使用的 token 过期之后，如何加入集群:<br><a href=\"https://blog.csdn.net/wo18237095579/article/details/89884369\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/wo18237095579/article/details/89884369</a> </p>\n","site":{"data":{}},"excerpt":"<p>前言: 组内给了3台新机器，要把之前的服务全迁到新机器。共6个服务，2个在之前的 k8s 集群，其他4个在物理机。</p>\n<p>已经迁移完成，记录下实施过程，大致分3步: 新 k8s 集群搭建、监控日志系统部署、业务服务迁移。</p>\n<h3 id=\"k8s-集群搭建\"><a href=\"#k8s-集群搭建\" class=\"headerlink\" title=\"k8s 集群搭建\"></a>k8s 集群搭建</h3><p>因为是新机器，准备尝试下 k8s  master 高可用方案，运维给的3台机器信息如下，两个mastet 建立ssh 信任，服务规划参考老集群。</p>\n<table>\n<thead>\n<tr>\n<th>主机名</th>\n<th>IP</th>\n<th>角色</th>\n<th>服务</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>soa-test-a001</td>\n<td>10.2.4.34</td>\n<td>master01</td>\n<td>监控、日志</td>\n</tr>\n<tr>\n<td>soa-test-a002</td>\n<td>10.2.4.35</td>\n<td>master02</td>\n<td>CI、Ingress</td>\n</tr>\n<tr>\n<td>soa-test-a003</td>\n<td>10.2.4.36</td>\n<td>node01</td>\n<td>业务服务</td>\n</tr>\n</tbody>\n</table>\n<p>只有两台master， 我们使用的是堆叠式 etcd 拓扑结构，如图：</p>\n<p><img src=\"/img/k8s/5.svg\" alt=\"kubeadm-ha-topology-stacked-etcd\">机器已经安装 docker ，直接开始使用 kubeadm 安装 k8s<br>","more":"</p>\n<p><strong>安装 kubeadm</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\"></span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\"></span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class=\"line\"></span><br><span class=\"line\">enabled=1</span><br><span class=\"line\"></span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\"></span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\"></span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\"></span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">setenforce 0</span><br><span class=\"line\">yum install -y kubelet kubeadm kubectl</span><br><span class=\"line\">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure>\n<p><strong>生成初始化 kubeadm 配置文件</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm config print init-defaults &gt; kubeadm-config.yaml</span><br></pre></td></tr></table></figure>\n<p>使用 master01: 6444 做 api负载，修改如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class=\"line\">bootstrapTokens:</span><br><span class=\"line\">- groups:</span><br><span class=\"line\">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class=\"line\">  token: abcdef.0123456789abcdef</span><br><span class=\"line\">  ttl: 24h0m0s</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - signing</span><br><span class=\"line\">  - authentication</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: 10.2.4.34 #master01机器ip</span><br><span class=\"line\">  bindPort: 6443 #apiServer运行的端口</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: /var/run/dockershim.sock</span><br><span class=\"line\">  name: soa-test-a001</span><br><span class=\"line\">  taints:</span><br><span class=\"line\">  - effect: NoSchedule</span><br><span class=\"line\">    key: node-role.kubernetes.io/master</span><br><span class=\"line\">---</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controlPlaneEndpoint: 10.2.4.34:6444 #控制面板api端口，用来做api负载均衡</span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns:</span><br><span class=\"line\">  type: CoreDNS</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers #改为阿里云仓库</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: v1.16.0</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  dnsDomain: cluster.local</span><br><span class=\"line\">  podSubnet: 10.244.0.0/16 #pod网络配置</span><br><span class=\"line\">  serviceSubnet: 10.96.0.0/12</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>开始安装，由于使用阿里镜像地址，安装较快，默认是 最新版 1.16.2</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log</span><br></pre></td></tr></table></figure>\n<p><strong>calico 网络：</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f https://docs.projectcalico.org/master/manifests/calico.yaml</span><br></pre></td></tr></table></figure>\n<p><strong>master02加入集群</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm join 10.2.4.34:6444 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">    --discovery-token-ca-cert-hash sha256:ee24d007b3eb73******bc7385528dcc549105b1e54642d82b7f23f718 \\</span><br><span class=\"line\">    --control-plane --certificate-key febdcefffebcfe60c6******5680f1110a4073ebd1e5c578c5c02a897</span><br></pre></td></tr></table></figure>\n<p>测试 master02 是否提供服务，可以修改master02 上的 ~/.kube/config 文件，修改server 为本机 ip + 6443端口，执行kubectl get nodes 成功，说明master02 同样提供 apiServer 功能。</p>\n<p><strong>haproxy 做负载</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">frontend kube-api-balance</span><br><span class=\"line\">    bind *:6444</span><br><span class=\"line\">    maxconn 30000                    #定义此端口上的maxconn</span><br><span class=\"line\">    default_backend default_servers  #请求定向至后端服务群default_servers</span><br><span class=\"line\"></span><br><span class=\"line\">backend default_servers    #定义后端服务群default_servers</span><br><span class=\"line\">    balance roundrobin</span><br><span class=\"line\">    server def.srv1 10.2.4.34:6443</span><br><span class=\"line\">    server def.srv2 10.2.4.35:6443</span><br></pre></td></tr></table></figure>\n<p>运行haproxy</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d \\</span><br><span class=\"line\">    --network=host \\</span><br><span class=\"line\">    --restart=always \\</span><br><span class=\"line\">    -v /root/sh/haproxy.cfg:/etc/haproxy/haproxy.cfg \\</span><br><span class=\"line\">    --name haproxy \\</span><br><span class=\"line\">    haproxy -f /etc/haproxy/haproxy.cfg</span><br></pre></td></tr></table></figure>\n<p>顺便贴下使用 nginx 转发配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stream &#123;</span><br><span class=\"line\">        server &#123;</span><br><span class=\"line\">                listen     6444;</span><br><span class=\"line\">                proxy_pass stream_backend;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        upstream stream_backend &#123;</span><br><span class=\"line\">                server 10.2.4.34:6443;</span><br><span class=\"line\">                server 10.2.4.35:6443;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>遗憾的是这里并没有使用 keepalived 对ip做高可用 :( </p>\n<h3 id=\"Dashboard-安装\"><a href=\"#Dashboard-安装\" class=\"headerlink\" title=\"Dashboard 安装\"></a>Dashboard 安装</h3><p>主要参考<a href=\"https://www.cnblogs.com/bluersw/p/11747161.html\" target=\"_blank\" rel=\"noopener\">安装dashboard</a>，之前使用的1.10版，新版提示更友好，资源编辑更方便。贴一下 <code>kube-config</code> 的生成，我们用这个文件来登录 dashboard</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl config view --raw=true &gt; kube-config</span><br></pre></td></tr></table></figure>\n<p>使用一个有权限的 serviceAccount 来配置，contexts 部分修改 user 为 serviceAccount name，users 部分，修改 name ，增加 token 认证。注意 token:  后面是一个空格，非换行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: lGSUNBVE******UtLS0tLQo=</span><br><span class=\"line\">    server: https://10.2.4.34:6444</span><br><span class=\"line\">  name: kubernetes</span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: kubernetes</span><br><span class=\"line\">    user: dashboard-admin  #改为serviceAccount</span><br><span class=\"line\">  name: kubernetes-admin@kubernetes</span><br><span class=\"line\">current-context: kubernetes-admin@kubernetes</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\">users:</span><br><span class=\"line\">- name: dashboard-admin  #改为serviceAccount</span><br><span class=\"line\">  user:  #使用token 认证</span><br><span class=\"line\">    token: eyJhbGciOiJSUzI******LdK0kpfSw</span><br></pre></td></tr></table></figure>\n<p>截图：</p>\n<p><img src=\"/img/k8s/6.png\" alt=\"6.png\"></p>\n<p><strong>遇到的问题：</strong></p>\n<p>遇到最大的问题是 在 master02 上执行 命令，延时5秒才返回，在上面起的pod，访问外网总提示超时，后来用kube-adm reset 了下，再次加入集群，莫名好了 -__-</p>\n<p>本篇就写到这，后面会更新监控、日志的安装，已经使用 gitlab runner + helm3 来部署服务.</p>\n<p><strong>参考：</strong><br><a href=\"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/</a><br><a href=\"https://blog.csdn.net/networken/article/details/89599004\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/networken/article/details/89599004</a><br><a href=\"https://www.kubernetes.org.cn/5551.html\" target=\"_blank\" rel=\"noopener\">https://www.kubernetes.org.cn/5551.html</a><br>安装dashboard:<br><a href=\"https://www.cnblogs.com/bluersw/p/11747161.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/bluersw/p/11747161.html</a><br>scp 信任:<br><a href=\"https://www.cnblogs.com/mchina/archive/2013/03/15/2956017.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/mchina/archive/2013/03/15/2956017.html</a><br>kubeadm join 使用的 token 过期之后，如何加入集群:<br><a href=\"https://blog.csdn.net/wo18237095579/article/details/89884369\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/wo18237095579/article/details/89884369</a> </p>"},{"layout":"post","title":"nginx 学习","description":"","date":"2019-02-27T00:00:00.000Z","comments":0,"share":true,"_content":"\nPOST_READ 阶段：\n\nx-forwarded-for x-real-ip \n\nrealip 模块启用 \n\nreturn 302 /a.html\n\n302 浏览器缓存\n\nerror_page 404=/404.php\n\nrewrite regex replacement\n\n如果 replacement 是以http开头，直接返回302\n\nlast 持续 break 停止当前脚本指令执行,后面的指令不会执行，直接读取文件返回  redirect 302 permant 301\n\nhttp permanent 同时出现返回301\n\nrewrite log 指令 开启rewrite 日志\n\n\n**if 使用场景**\n\n1. 检查变量为空或者值是否为0，直接使用\n2. 将变量和字符串做匹配，使用=或者!=\n3. 将变量与正则表达式做匹配 ~ 或~*\n4. 检查文件是否存在 -f\n5. 检查目录是否存在 -d\n6. 检查文件、目录、软连是否存在 -e \n7. 检查是否为可执行文件 -x\n\n- 忽略大小写\n- ^~ 禁止正则表达式匹配\n---\n- limit_conn 限制并发连接数以ip为单位\n- limit_req 把突发的 流量限制为每秒多少请求 用户请求会变慢，不会被拒绝 nodelay 盆里的请求是否立即返回 burst=3没分钟请求3次，在limit_conn 之前\n- mirror 流量拷贝\n- sub 替换\n- sub_filter \n- additon 模块在响应前或后添加 自请求的内容\n- referer 模块 对于大多数网站来说都是有效的\n- valid_referers  if($invalid_referer){return 403}\n- secure_link\n- rewrite 不会修改 url地址，如dns cname记录 ，proxy_pass 会修改请求的url\n- mirror_request body off\n- map 模块\n---\n\n- nginx  Upstream Consistent Hash\n- proxy_cache_use_state\n- strace -p\n- ngx_http_cache_purge_module 清除nginx缓存\n\n\n","source":"_posts/nginx.md","raw":"---\nlayout: post\ntitle: \"nginx 学习\"\ndescription: \"\"\ndate: 2019-02-27\ntags: [nginx,openresty]\ncomments: false\nshare: true\n---\n\nPOST_READ 阶段：\n\nx-forwarded-for x-real-ip \n\nrealip 模块启用 \n\nreturn 302 /a.html\n\n302 浏览器缓存\n\nerror_page 404=/404.php\n\nrewrite regex replacement\n\n如果 replacement 是以http开头，直接返回302\n\nlast 持续 break 停止当前脚本指令执行,后面的指令不会执行，直接读取文件返回  redirect 302 permant 301\n\nhttp permanent 同时出现返回301\n\nrewrite log 指令 开启rewrite 日志\n\n\n**if 使用场景**\n\n1. 检查变量为空或者值是否为0，直接使用\n2. 将变量和字符串做匹配，使用=或者!=\n3. 将变量与正则表达式做匹配 ~ 或~*\n4. 检查文件是否存在 -f\n5. 检查目录是否存在 -d\n6. 检查文件、目录、软连是否存在 -e \n7. 检查是否为可执行文件 -x\n\n- 忽略大小写\n- ^~ 禁止正则表达式匹配\n---\n- limit_conn 限制并发连接数以ip为单位\n- limit_req 把突发的 流量限制为每秒多少请求 用户请求会变慢，不会被拒绝 nodelay 盆里的请求是否立即返回 burst=3没分钟请求3次，在limit_conn 之前\n- mirror 流量拷贝\n- sub 替换\n- sub_filter \n- additon 模块在响应前或后添加 自请求的内容\n- referer 模块 对于大多数网站来说都是有效的\n- valid_referers  if($invalid_referer){return 403}\n- secure_link\n- rewrite 不会修改 url地址，如dns cname记录 ，proxy_pass 会修改请求的url\n- mirror_request body off\n- map 模块\n---\n\n- nginx  Upstream Consistent Hash\n- proxy_cache_use_state\n- strace -p\n- ngx_http_cache_purge_module 清除nginx缓存\n\n\n","slug":"nginx","published":1,"updated":"2019-11-08T17:53:52.512Z","photos":[],"link":"","_id":"ck2qgz8vr000i3cov4fi7omen","content":"<p>POST_READ 阶段：</p>\n<p>x-forwarded-for x-real-ip </p>\n<p>realip 模块启用 </p>\n<p>return 302 /a.html</p>\n<p>302 浏览器缓存</p>\n<p>error_page 404=/404.php</p>\n<p>rewrite regex replacement</p>\n<p>如果 replacement 是以http开头，直接返回302</p>\n<p>last 持续 break 停止当前脚本指令执行,后面的指令不会执行，直接读取文件返回  redirect 302 permant 301</p>\n<p>http permanent 同时出现返回301</p>\n<p>rewrite log 指令 开启rewrite 日志</p>\n<p><strong>if 使用场景</strong></p>\n<ol>\n<li>检查变量为空或者值是否为0，直接使用</li>\n<li>将变量和字符串做匹配，使用=或者!=</li>\n<li>将变量与正则表达式做匹配 ~ 或~*</li>\n<li>检查文件是否存在 -f</li>\n<li>检查目录是否存在 -d</li>\n<li>检查文件、目录、软连是否存在 -e </li>\n<li>检查是否为可执行文件 -x</li>\n</ol>\n<ul>\n<li>忽略大小写</li>\n<li>^~ 禁止正则表达式匹配</li>\n</ul>\n<hr>\n<ul>\n<li>limit_conn 限制并发连接数以ip为单位</li>\n<li>limit_req 把突发的 流量限制为每秒多少请求 用户请求会变慢，不会被拒绝 nodelay 盆里的请求是否立即返回 burst=3没分钟请求3次，在limit_conn 之前</li>\n<li>mirror 流量拷贝</li>\n<li>sub 替换</li>\n<li>sub_filter </li>\n<li>additon 模块在响应前或后添加 自请求的内容</li>\n<li>referer 模块 对于大多数网站来说都是有效的</li>\n<li>valid_referers  if($invalid_referer){return 403}</li>\n<li>secure_link</li>\n<li>rewrite 不会修改 url地址，如dns cname记录 ，proxy_pass 会修改请求的url</li>\n<li>mirror_request body off</li>\n<li>map 模块</li>\n</ul>\n<hr>\n<ul>\n<li>nginx  Upstream Consistent Hash</li>\n<li>proxy_cache_use_state</li>\n<li>strace -p</li>\n<li>ngx_http_cache_purge_module 清除nginx缓存</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>POST_READ 阶段：</p>\n<p>x-forwarded-for x-real-ip </p>\n<p>realip 模块启用 </p>\n<p>return 302 /a.html</p>\n<p>302 浏览器缓存</p>\n<p>error_page 404=/404.php</p>\n<p>rewrite regex replacement</p>\n<p>如果 replacement 是以http开头，直接返回302</p>\n<p>last 持续 break 停止当前脚本指令执行,后面的指令不会执行，直接读取文件返回  redirect 302 permant 301</p>\n<p>http permanent 同时出现返回301</p>\n<p>rewrite log 指令 开启rewrite 日志</p>\n<p><strong>if 使用场景</strong></p>\n<ol>\n<li>检查变量为空或者值是否为0，直接使用</li>\n<li>将变量和字符串做匹配，使用=或者!=</li>\n<li>将变量与正则表达式做匹配 ~ 或~*</li>\n<li>检查文件是否存在 -f</li>\n<li>检查目录是否存在 -d</li>\n<li>检查文件、目录、软连是否存在 -e </li>\n<li>检查是否为可执行文件 -x</li>\n</ol>\n<ul>\n<li>忽略大小写</li>\n<li>^~ 禁止正则表达式匹配</li>\n</ul>\n<hr>\n<ul>\n<li>limit_conn 限制并发连接数以ip为单位</li>\n<li>limit_req 把突发的 流量限制为每秒多少请求 用户请求会变慢，不会被拒绝 nodelay 盆里的请求是否立即返回 burst=3没分钟请求3次，在limit_conn 之前</li>\n<li>mirror 流量拷贝</li>\n<li>sub 替换</li>\n<li>sub_filter </li>\n<li>additon 模块在响应前或后添加 自请求的内容</li>\n<li>referer 模块 对于大多数网站来说都是有效的</li>\n<li>valid_referers  if($invalid_referer){return 403}</li>\n<li>secure_link</li>\n<li>rewrite 不会修改 url地址，如dns cname记录 ，proxy_pass 会修改请求的url</li>\n<li>mirror_request body off</li>\n<li>map 模块</li>\n</ul>\n<hr>\n<ul>\n<li>nginx  Upstream Consistent Hash</li>\n<li>proxy_cache_use_state</li>\n<li>strace -p</li>\n<li>ngx_http_cache_purge_module 清除nginx缓存</li>\n</ul>\n"},{"title":"k8s 笔记","description":"","date":"2019-02-01T19:38:10.000Z","comments":0,"share":true,"_content":"\n**k8s 容器出现大量 Evicted**\n\n```\n$kubectl describe node/runner-e480\n\nNormal   NodeHasNoDiskPressure    6m19s (x8 over 6m19s)  kubelet, runner-e480     Node runner-e480 status is now: NodeHasNoDiskPressure\n\ndf -h 系统盘使用85%\n\n修改了docker 镜像存储路径\nhttps://blog.csdn.net/glongljl/article/details/80158297\n\n参考:\nhttps://blog.csdn.net/qq_21816375/article/details/82905660\n```\n\n### k8s 命令\n\n```\n#命令行自动补全\nsource <(kubectl completion bash)\necho \"source <(kubectl completion bash)\" >> ~/.bashrc\n\nkubectl get sa --all-namespaces=true\nkubectl get roles --all-namespaces=true\nkubectl get RoleBinding  --all-namespaces=true\nkubectl get secrets --all-namespaces=true\nkubectl describe  ClusterRole/cluster-admin\n\n\n#端口转发 本地2000端口映射到容器3000端口 &……& 目前只能用localhost访问\nexport POD_NAME=$(kubectl get pods --namespace default -l \"app=grafana,release=willing-lamb\" -o jsonpath=\"{.items[0].metadata.name}\")\nkubectl port-forward willing-lamb-grafana-75d49cb58c-7dn6d 2000:3000\n\n\nkubectl get secrets -o json | kubectl update -f -\n\nkubectl exec POD_NAME -c CONTAINER_NAME reboot\nkubectl exec -it [POD_NAME] -c [CONTAINER_NAME] -- /bin/sh -c \"kill 1\"\n\nkubectl explain namespace\n\nkubectl get ns default --show-labels\nkubectl completion -h\n\nkubectl delete pod deviosow-1828 --namespace=kube-system --grace-period=0 --force\n\ndocker images | grep '<none>'| awk '{print $3}' | xargs docker rmi\nkubectl -n kube-system get endpoints -o wide\n\n#dns 验证\nkubectl run curl --image=radial/busyboxplus:curl -it\nnslookup docker-dind-svc.gitlab-managed-apps\n```\n\n\n**RBAC**\n\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  namespace: default\n  name: example-sa\n---\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: default\n  name: example-role\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: example-rolebinding\n  namespace: default\nsubjects:\n- kind: ServiceAccount\n  name: example-sa\n  namespace: default\nroleRef:\n  kind: Role\n  name: example-role\n  apiGroup: rbac.authorization.k8s.io\n  \n---\n#管理员，角色配置可以参考 kubectl describe  ClusterRole/cluster-admin\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: default\n  name: example-role\nrules:\n- apiGroups:\n  - '*'\n  resources:\n  - '*'\n  verbs:\n  - '*'\n  \nserviceAccountName\nserviceAccount #pod请求别的命名空间时的帐号\n\nError: release community-feature-haozhe-wei failed: namespaces \"php-sht\" is forbidden: User \"system:serviceaccount:gitlab-managed-apps:default\" cannot get resource \"namespaces\" in API group \"\" in the namespace \"php-sht\"\n\n更新密钥要小心，因为帐号token会被其他服务关联，比如 tiller account\n```\n\n**跨namespace授权 **\n\n```\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: gitlab\n  name: gitlab-view-role\nrules:\n- apiGroups:\n  - '*'\n  resources:\n  - '*'\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: gitlab-view-php-sht-rolebinding\n  namespace: gitlab\nsubjects:\n- kind: ServiceAccount\n  name: admin\n  namespace: php-sht\nroleRef:\n  kind: Role\n  name: gitlab-view-role\n  apiGroup: rbac.authorization.k8s.io\n```\n\n**角色**\n\n```\nadmin\nmaintainer\ndeveloper\nguest/reporter\n```\n\n### Pod\n\n```\n每个 pod 都以mount形式挂载这个 默认的Servcice Account，\n如：mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\"\n\n单独的pod，恢复过程永远发生在当前节点，不会跑到别的节点上去。如果你想让Pod出现在其他的可用节点上，就必须使用 deployment 这样的控制器来管理 pod，哪怕你只需要一个 pod 副本。\n\n可以通过restartPolicy，改变pod的恢复策略\n\nselector 意味着后面这些追加的定义，只会作用于 selector 所定义的，带有\"role:frontend\"标签的Pod对象\n\ncommand: [\"sh\",\"-c\",\"mkdir /var/www/html ; ln -s /var/www/community/public /var/www/html/public ; nginx -g 'daemon off;'\"]\n\n#多行配置\nenv:\n    - name: COMMAND_SCRIPT\n      value: |-\n        set -xeo pipefail\n        helm init --upgrade\n        for i in $(seq 1 30); do helm version && break; sleep 1s; echo \"Retrying ($i)...\"; done\n        helm repo add runner https://charts.gitlab.io\n        helm repo update\n        helm upgrade runner runner/gitlab-runner --install --reset-values --tls --tls-ca-cert /data/helm/runner/config/ca.pem --tls-cert /data/helm/runner/config/cert.pem --tls-key /data/helm/runner/config/key.pem --version 0.4.1 --set rbac.create\\=true,rbac.enabled\\=true --namespace gitlab-managed-apps -f /data/helm/runner/config/values.yaml\n\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-privileged\nspec:\n  containers:\n    - name: nginx-privileged\n      image: nginx:1.14.2\n      securityContext:\n        privileged: true\n        runAsUser: 1000 #指定容器运行账户\n      \n      \n\npod 的操作只有创建删除\n\n\"hostAliases\": [\n          {\n            \"ip\": \"172.16.101.197\",\n            \"hostnames\": [\n              \"prometheus.local.com\"\n            ]\n          }\n]\n\npod 的标签很很重要，loki用来建立索引，prometheus可以用来指定报警分组.\n```\n\n**TLS**\n\n```\ncurl https://192.168.207.237:2376/info --cert ./cert.pm --key ./key.pem  --cacert ./ca.pem\nkubectl create secret tls tls-secret --cert=path/to/tls.cert --key=path/to/tls.key\n```\n\n**Namspace**\n\n```\npv 不属于 namespace \npvc 属于\n```\n\n**Label** and Annotations 注释 可以用来检索\n\n```\n#标签一定要有 key 可以没有 value\nkubectl label/annotate <resource> foo=bar\nkubectl label/annotate <resource> foo-\n```\n\n### 健康检查\n\n```\nlivenessProbe:\n  - initialDelaySeconds:5 #容器启动5s后开始执行\n    periodSeconds:5 #每5s执行一次\n\nreadlinessProbe: #健康检查结果决定这个pod是不是能被通过Service的方式访问到，而并不影响Pod的生命周期\n```\n\n### ConfigMap Secret Downard Api\n\n```\n\n这三种Project Volume 定义的信息，还可以通过环境变量的方式出现在容器里。但环境变量不具备自动更新的能力。所以一般情况下，都建议你好似用 Volume 文件的方式获取这些信息。\n\nprojected volume可以映射很多volume源到相同的目录下\n\n#从配置文件生成 configmap\n<?php\n$c=file_get_contents(\"conf.php\");\necho json_encode($c,JSON_UNESCAPED_UNICODE).\"\\n\";\n```\n\n### k8s  node 节点加入集群\n\n```\nkubeadm join 172.16.101.197:6443 --token vq0fs8.rzcw1lf6k3lz7986     --discovery-token-ca-cert-hash sha256:68c8228227ae029b091c8d6cdecde4c11ec5dbbbd43fa725060ffdd512fef3cd\n\n节点需要关闭 swap 启动docker服务\n\n\n还需要下载\nk8s.gcr.io/pause:3.1 镜像\nk8s.gcr.io/kube-proxy 镜像\n\n在 master节点观察子节点pod创建情况\n\n移除节点:\nkubectl delete node node-1\n```\n\n### PV\n\n```\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: es-local-pv0\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: local-storage\n  local:\n    path: /data\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - php-cd-node\n```\n\n**redis**\n\n```\n   kubectl run --namespace kube-public redis-client --rm --tty -i --restart='Never' \\\n    --env REDIS_PASSWORD=$REDIS_PASSWORD \\\n   --image docker.io/bitnami/redis:5.0.5-debian-9-r36 -- bash\n```\n\n### 映射外部服务\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: ldap-chang-password\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n\n---\n\napiVersion: v1\nkind: Endpoints\nmetadata:\n  name: ldap-chang-password\n  namespace: kube-system\nsubsets:\n  - addresses:\n    - ip: 10.111.8.166\n    ports:\n    - port: 8080\n      protocol: TCP\n\n---\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: uic\n  namespace: kube-system\nspec:\n  rules:\n  - host: uic.t1.youhaodongxi.com\n    http:\n      paths:\n      - backend:\n          serviceName: ldap-chang-password\n          servicePort: 80\n        path: /\n```\n\n\n\n**API权限**\n\n```\nhttps://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/\n\nAPISERVER=$(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}')\nTOKEN=$(kubectl get secret $(kubectl get serviceaccount default -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.token}' | base64 --decode )\ncurl $APISERVER/api --header \"Authorization: Bearer $TOKEN\" --insecure\n{\n  \"kind\": \"APIVersions\",\n  \"versions\": [\n    \"v1\"\n  ],\n  \"serverAddressByClientCIDRs\": [\n    {\n      \"clientCIDR\": \"0.0.0.0/0\",\n      \"serverAddress\": \"10.0.1.149:443\"\n    }\n  ]\n}\n\n```\n\n\n\n**how-to-create-a-kubectl-config-file-for-serviceaccount**\n\n```\nhttps://stackoverflow.com/questions/47770676/how-to-create-a-kubectl-config-file-for-serviceaccount\n```\n\n\n\n**create-kubectl-by-user**\n\n```\nhttps://docs.bitnami.com/kubernetes/how-to/configure-rbac-in-your-kubernetes-cluster/\n```\n\n\n\n","source":"_posts/k8s-notes.md","raw":"---\ntitle: \"k8s 笔记\"\ndescription: \"\"\ndate: 2019-02-01 19:38:10\ntags: [k8s]\ncomments: false\nshare: true\n---\n\n**k8s 容器出现大量 Evicted**\n\n```\n$kubectl describe node/runner-e480\n\nNormal   NodeHasNoDiskPressure    6m19s (x8 over 6m19s)  kubelet, runner-e480     Node runner-e480 status is now: NodeHasNoDiskPressure\n\ndf -h 系统盘使用85%\n\n修改了docker 镜像存储路径\nhttps://blog.csdn.net/glongljl/article/details/80158297\n\n参考:\nhttps://blog.csdn.net/qq_21816375/article/details/82905660\n```\n\n### k8s 命令\n\n```\n#命令行自动补全\nsource <(kubectl completion bash)\necho \"source <(kubectl completion bash)\" >> ~/.bashrc\n\nkubectl get sa --all-namespaces=true\nkubectl get roles --all-namespaces=true\nkubectl get RoleBinding  --all-namespaces=true\nkubectl get secrets --all-namespaces=true\nkubectl describe  ClusterRole/cluster-admin\n\n\n#端口转发 本地2000端口映射到容器3000端口 &……& 目前只能用localhost访问\nexport POD_NAME=$(kubectl get pods --namespace default -l \"app=grafana,release=willing-lamb\" -o jsonpath=\"{.items[0].metadata.name}\")\nkubectl port-forward willing-lamb-grafana-75d49cb58c-7dn6d 2000:3000\n\n\nkubectl get secrets -o json | kubectl update -f -\n\nkubectl exec POD_NAME -c CONTAINER_NAME reboot\nkubectl exec -it [POD_NAME] -c [CONTAINER_NAME] -- /bin/sh -c \"kill 1\"\n\nkubectl explain namespace\n\nkubectl get ns default --show-labels\nkubectl completion -h\n\nkubectl delete pod deviosow-1828 --namespace=kube-system --grace-period=0 --force\n\ndocker images | grep '<none>'| awk '{print $3}' | xargs docker rmi\nkubectl -n kube-system get endpoints -o wide\n\n#dns 验证\nkubectl run curl --image=radial/busyboxplus:curl -it\nnslookup docker-dind-svc.gitlab-managed-apps\n```\n\n\n**RBAC**\n\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  namespace: default\n  name: example-sa\n---\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: default\n  name: example-role\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: example-rolebinding\n  namespace: default\nsubjects:\n- kind: ServiceAccount\n  name: example-sa\n  namespace: default\nroleRef:\n  kind: Role\n  name: example-role\n  apiGroup: rbac.authorization.k8s.io\n  \n---\n#管理员，角色配置可以参考 kubectl describe  ClusterRole/cluster-admin\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: default\n  name: example-role\nrules:\n- apiGroups:\n  - '*'\n  resources:\n  - '*'\n  verbs:\n  - '*'\n  \nserviceAccountName\nserviceAccount #pod请求别的命名空间时的帐号\n\nError: release community-feature-haozhe-wei failed: namespaces \"php-sht\" is forbidden: User \"system:serviceaccount:gitlab-managed-apps:default\" cannot get resource \"namespaces\" in API group \"\" in the namespace \"php-sht\"\n\n更新密钥要小心，因为帐号token会被其他服务关联，比如 tiller account\n```\n\n**跨namespace授权 **\n\n```\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: gitlab\n  name: gitlab-view-role\nrules:\n- apiGroups:\n  - '*'\n  resources:\n  - '*'\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: gitlab-view-php-sht-rolebinding\n  namespace: gitlab\nsubjects:\n- kind: ServiceAccount\n  name: admin\n  namespace: php-sht\nroleRef:\n  kind: Role\n  name: gitlab-view-role\n  apiGroup: rbac.authorization.k8s.io\n```\n\n**角色**\n\n```\nadmin\nmaintainer\ndeveloper\nguest/reporter\n```\n\n### Pod\n\n```\n每个 pod 都以mount形式挂载这个 默认的Servcice Account，\n如：mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\"\n\n单独的pod，恢复过程永远发生在当前节点，不会跑到别的节点上去。如果你想让Pod出现在其他的可用节点上，就必须使用 deployment 这样的控制器来管理 pod，哪怕你只需要一个 pod 副本。\n\n可以通过restartPolicy，改变pod的恢复策略\n\nselector 意味着后面这些追加的定义，只会作用于 selector 所定义的，带有\"role:frontend\"标签的Pod对象\n\ncommand: [\"sh\",\"-c\",\"mkdir /var/www/html ; ln -s /var/www/community/public /var/www/html/public ; nginx -g 'daemon off;'\"]\n\n#多行配置\nenv:\n    - name: COMMAND_SCRIPT\n      value: |-\n        set -xeo pipefail\n        helm init --upgrade\n        for i in $(seq 1 30); do helm version && break; sleep 1s; echo \"Retrying ($i)...\"; done\n        helm repo add runner https://charts.gitlab.io\n        helm repo update\n        helm upgrade runner runner/gitlab-runner --install --reset-values --tls --tls-ca-cert /data/helm/runner/config/ca.pem --tls-cert /data/helm/runner/config/cert.pem --tls-key /data/helm/runner/config/key.pem --version 0.4.1 --set rbac.create\\=true,rbac.enabled\\=true --namespace gitlab-managed-apps -f /data/helm/runner/config/values.yaml\n\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-privileged\nspec:\n  containers:\n    - name: nginx-privileged\n      image: nginx:1.14.2\n      securityContext:\n        privileged: true\n        runAsUser: 1000 #指定容器运行账户\n      \n      \n\npod 的操作只有创建删除\n\n\"hostAliases\": [\n          {\n            \"ip\": \"172.16.101.197\",\n            \"hostnames\": [\n              \"prometheus.local.com\"\n            ]\n          }\n]\n\npod 的标签很很重要，loki用来建立索引，prometheus可以用来指定报警分组.\n```\n\n**TLS**\n\n```\ncurl https://192.168.207.237:2376/info --cert ./cert.pm --key ./key.pem  --cacert ./ca.pem\nkubectl create secret tls tls-secret --cert=path/to/tls.cert --key=path/to/tls.key\n```\n\n**Namspace**\n\n```\npv 不属于 namespace \npvc 属于\n```\n\n**Label** and Annotations 注释 可以用来检索\n\n```\n#标签一定要有 key 可以没有 value\nkubectl label/annotate <resource> foo=bar\nkubectl label/annotate <resource> foo-\n```\n\n### 健康检查\n\n```\nlivenessProbe:\n  - initialDelaySeconds:5 #容器启动5s后开始执行\n    periodSeconds:5 #每5s执行一次\n\nreadlinessProbe: #健康检查结果决定这个pod是不是能被通过Service的方式访问到，而并不影响Pod的生命周期\n```\n\n### ConfigMap Secret Downard Api\n\n```\n\n这三种Project Volume 定义的信息，还可以通过环境变量的方式出现在容器里。但环境变量不具备自动更新的能力。所以一般情况下，都建议你好似用 Volume 文件的方式获取这些信息。\n\nprojected volume可以映射很多volume源到相同的目录下\n\n#从配置文件生成 configmap\n<?php\n$c=file_get_contents(\"conf.php\");\necho json_encode($c,JSON_UNESCAPED_UNICODE).\"\\n\";\n```\n\n### k8s  node 节点加入集群\n\n```\nkubeadm join 172.16.101.197:6443 --token vq0fs8.rzcw1lf6k3lz7986     --discovery-token-ca-cert-hash sha256:68c8228227ae029b091c8d6cdecde4c11ec5dbbbd43fa725060ffdd512fef3cd\n\n节点需要关闭 swap 启动docker服务\n\n\n还需要下载\nk8s.gcr.io/pause:3.1 镜像\nk8s.gcr.io/kube-proxy 镜像\n\n在 master节点观察子节点pod创建情况\n\n移除节点:\nkubectl delete node node-1\n```\n\n### PV\n\n```\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: es-local-pv0\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: local-storage\n  local:\n    path: /data\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - php-cd-node\n```\n\n**redis**\n\n```\n   kubectl run --namespace kube-public redis-client --rm --tty -i --restart='Never' \\\n    --env REDIS_PASSWORD=$REDIS_PASSWORD \\\n   --image docker.io/bitnami/redis:5.0.5-debian-9-r36 -- bash\n```\n\n### 映射外部服务\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: ldap-chang-password\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n\n---\n\napiVersion: v1\nkind: Endpoints\nmetadata:\n  name: ldap-chang-password\n  namespace: kube-system\nsubsets:\n  - addresses:\n    - ip: 10.111.8.166\n    ports:\n    - port: 8080\n      protocol: TCP\n\n---\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: uic\n  namespace: kube-system\nspec:\n  rules:\n  - host: uic.t1.youhaodongxi.com\n    http:\n      paths:\n      - backend:\n          serviceName: ldap-chang-password\n          servicePort: 80\n        path: /\n```\n\n\n\n**API权限**\n\n```\nhttps://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/\n\nAPISERVER=$(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}')\nTOKEN=$(kubectl get secret $(kubectl get serviceaccount default -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.token}' | base64 --decode )\ncurl $APISERVER/api --header \"Authorization: Bearer $TOKEN\" --insecure\n{\n  \"kind\": \"APIVersions\",\n  \"versions\": [\n    \"v1\"\n  ],\n  \"serverAddressByClientCIDRs\": [\n    {\n      \"clientCIDR\": \"0.0.0.0/0\",\n      \"serverAddress\": \"10.0.1.149:443\"\n    }\n  ]\n}\n\n```\n\n\n\n**how-to-create-a-kubectl-config-file-for-serviceaccount**\n\n```\nhttps://stackoverflow.com/questions/47770676/how-to-create-a-kubectl-config-file-for-serviceaccount\n```\n\n\n\n**create-kubectl-by-user**\n\n```\nhttps://docs.bitnami.com/kubernetes/how-to/configure-rbac-in-your-kubernetes-cluster/\n```\n\n\n\n","slug":"k8s-notes","published":1,"updated":"2019-11-08T17:53:52.512Z","layout":"post","photos":[],"link":"","_id":"ck2qgz8vt000k3cov552hrlp8","content":"<p><strong>k8s 容器出现大量 Evicted</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$kubectl describe node/runner-e480</span><br><span class=\"line\"></span><br><span class=\"line\">Normal   NodeHasNoDiskPressure    6m19s (x8 over 6m19s)  kubelet, runner-e480     Node runner-e480 status is now: NodeHasNoDiskPressure</span><br><span class=\"line\"></span><br><span class=\"line\">df -h 系统盘使用85%</span><br><span class=\"line\"></span><br><span class=\"line\">修改了docker 镜像存储路径</span><br><span class=\"line\">https://blog.csdn.net/glongljl/article/details/80158297</span><br><span class=\"line\"></span><br><span class=\"line\">参考:</span><br><span class=\"line\">https://blog.csdn.net/qq_21816375/article/details/82905660</span><br></pre></td></tr></table></figure>\n<h3 id=\"k8s-命令\"><a href=\"#k8s-命令\" class=\"headerlink\" title=\"k8s 命令\"></a>k8s 命令</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#命令行自动补全</span><br><span class=\"line\">source &lt;(kubectl completion bash)</span><br><span class=\"line\">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl get sa --all-namespaces=true</span><br><span class=\"line\">kubectl get roles --all-namespaces=true</span><br><span class=\"line\">kubectl get RoleBinding  --all-namespaces=true</span><br><span class=\"line\">kubectl get secrets --all-namespaces=true</span><br><span class=\"line\">kubectl describe  ClusterRole/cluster-admin</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#端口转发 本地2000端口映射到容器3000端口 &amp;……&amp; 目前只能用localhost访问</span><br><span class=\"line\">export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=grafana,release=willing-lamb&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class=\"line\">kubectl port-forward willing-lamb-grafana-75d49cb58c-7dn6d 2000:3000</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">kubectl get secrets -o json | kubectl update -f -</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl exec POD_NAME -c CONTAINER_NAME reboot</span><br><span class=\"line\">kubectl exec -it [POD_NAME] -c [CONTAINER_NAME] -- /bin/sh -c &quot;kill 1&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl explain namespace</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl get ns default --show-labels</span><br><span class=\"line\">kubectl completion -h</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl delete pod deviosow-1828 --namespace=kube-system --grace-period=0 --force</span><br><span class=\"line\"></span><br><span class=\"line\">docker images | grep &apos;&lt;none&gt;&apos;| awk &apos;&#123;print $3&#125;&apos; | xargs docker rmi</span><br><span class=\"line\">kubectl -n kube-system get endpoints -o wide</span><br><span class=\"line\"></span><br><span class=\"line\">#dns 验证</span><br><span class=\"line\">kubectl run curl --image=radial/busyboxplus:curl -it</span><br><span class=\"line\">nslookup docker-dind-svc.gitlab-managed-apps</span><br></pre></td></tr></table></figure>\n<p><strong>RBAC</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  name: example-sa</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  name: example-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;pods&quot;]</span><br><span class=\"line\">  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: example-rolebinding</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: example-sa</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: example-role</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  </span><br><span class=\"line\">---</span><br><span class=\"line\">#管理员，角色配置可以参考 kubectl describe  ClusterRole/cluster-admin</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  name: example-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  </span><br><span class=\"line\">serviceAccountName</span><br><span class=\"line\">serviceAccount #pod请求别的命名空间时的帐号</span><br><span class=\"line\"></span><br><span class=\"line\">Error: release community-feature-haozhe-wei failed: namespaces &quot;php-sht&quot; is forbidden: User &quot;system:serviceaccount:gitlab-managed-apps:default&quot; cannot get resource &quot;namespaces&quot; in API group &quot;&quot; in the namespace &quot;php-sht&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">更新密钥要小心，因为帐号token会被其他服务关联，比如 tiller account</span><br></pre></td></tr></table></figure>\n<p><strong>跨namespace授权 </strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">  name: gitlab-view-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: gitlab-view-php-sht-rolebinding</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: admin</span><br><span class=\"line\">  namespace: php-sht</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: gitlab-view-role</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>\n<p><strong>角色</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">admin</span><br><span class=\"line\">maintainer</span><br><span class=\"line\">developer</span><br><span class=\"line\">guest/reporter</span><br></pre></td></tr></table></figure>\n<h3 id=\"Pod\"><a href=\"#Pod\" class=\"headerlink\" title=\"Pod\"></a>Pod</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">每个 pod 都以mount形式挂载这个 默认的Servcice Account，</span><br><span class=\"line\">如：mountPath&quot;: &quot;/var/run/secrets/kubernetes.io/serviceaccount&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">单独的pod，恢复过程永远发生在当前节点，不会跑到别的节点上去。如果你想让Pod出现在其他的可用节点上，就必须使用 deployment 这样的控制器来管理 pod，哪怕你只需要一个 pod 副本。</span><br><span class=\"line\"></span><br><span class=\"line\">可以通过restartPolicy，改变pod的恢复策略</span><br><span class=\"line\"></span><br><span class=\"line\">selector 意味着后面这些追加的定义，只会作用于 selector 所定义的，带有&quot;role:frontend&quot;标签的Pod对象</span><br><span class=\"line\"></span><br><span class=\"line\">command: [&quot;sh&quot;,&quot;-c&quot;,&quot;mkdir /var/www/html ; ln -s /var/www/community/public /var/www/html/public ; nginx -g &apos;daemon off;&apos;&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">#多行配置</span><br><span class=\"line\">env:</span><br><span class=\"line\">    - name: COMMAND_SCRIPT</span><br><span class=\"line\">      value: |-</span><br><span class=\"line\">        set -xeo pipefail</span><br><span class=\"line\">        helm init --upgrade</span><br><span class=\"line\">        for i in $(seq 1 30); do helm version &amp;&amp; break; sleep 1s; echo &quot;Retrying ($i)...&quot;; done</span><br><span class=\"line\">        helm repo add runner https://charts.gitlab.io</span><br><span class=\"line\">        helm repo update</span><br><span class=\"line\">        helm upgrade runner runner/gitlab-runner --install --reset-values --tls --tls-ca-cert /data/helm/runner/config/ca.pem --tls-cert /data/helm/runner/config/cert.pem --tls-key /data/helm/runner/config/key.pem --version 0.4.1 --set rbac.create\\=true,rbac.enabled\\=true --namespace gitlab-managed-apps -f /data/helm/runner/config/values.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-privileged</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">    - name: nginx-privileged</span><br><span class=\"line\">      image: nginx:1.14.2</span><br><span class=\"line\">      securityContext:</span><br><span class=\"line\">        privileged: true</span><br><span class=\"line\">        runAsUser: 1000 #指定容器运行账户</span><br><span class=\"line\">      </span><br><span class=\"line\">      </span><br><span class=\"line\"></span><br><span class=\"line\">pod 的操作只有创建删除</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;hostAliases&quot;: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;ip&quot;: &quot;172.16.101.197&quot;,</span><br><span class=\"line\">            &quot;hostnames&quot;: [</span><br><span class=\"line\">              &quot;prometheus.local.com&quot;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\">pod 的标签很很重要，loki用来建立索引，prometheus可以用来指定报警分组.</span><br></pre></td></tr></table></figure>\n<p><strong>TLS</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl https://192.168.207.237:2376/info --cert ./cert.pm --key ./key.pem  --cacert ./ca.pem</span><br><span class=\"line\">kubectl create secret tls tls-secret --cert=path/to/tls.cert --key=path/to/tls.key</span><br></pre></td></tr></table></figure>\n<p><strong>Namspace</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pv 不属于 namespace </span><br><span class=\"line\">pvc 属于</span><br></pre></td></tr></table></figure>\n<p><strong>Label</strong> and Annotations 注释 可以用来检索</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#标签一定要有 key 可以没有 value</span><br><span class=\"line\">kubectl label/annotate &lt;resource&gt; foo=bar</span><br><span class=\"line\">kubectl label/annotate &lt;resource&gt; foo-</span><br></pre></td></tr></table></figure>\n<h3 id=\"健康检查\"><a href=\"#健康检查\" class=\"headerlink\" title=\"健康检查\"></a>健康检查</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">livenessProbe:</span><br><span class=\"line\">  - initialDelaySeconds:5 #容器启动5s后开始执行</span><br><span class=\"line\">    periodSeconds:5 #每5s执行一次</span><br><span class=\"line\"></span><br><span class=\"line\">readlinessProbe: #健康检查结果决定这个pod是不是能被通过Service的方式访问到，而并不影响Pod的生命周期</span><br></pre></td></tr></table></figure>\n<h3 id=\"ConfigMap-Secret-Downard-Api\"><a href=\"#ConfigMap-Secret-Downard-Api\" class=\"headerlink\" title=\"ConfigMap Secret Downard Api\"></a>ConfigMap Secret Downard Api</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">这三种Project Volume 定义的信息，还可以通过环境变量的方式出现在容器里。但环境变量不具备自动更新的能力。所以一般情况下，都建议你好似用 Volume 文件的方式获取这些信息。</span><br><span class=\"line\"></span><br><span class=\"line\">projected volume可以映射很多volume源到相同的目录下</span><br><span class=\"line\"></span><br><span class=\"line\">#从配置文件生成 configmap</span><br><span class=\"line\">&lt;?php</span><br><span class=\"line\">$c=file_get_contents(&quot;conf.php&quot;);</span><br><span class=\"line\">echo json_encode($c,JSON_UNESCAPED_UNICODE).&quot;\\n&quot;;</span><br></pre></td></tr></table></figure>\n<h3 id=\"k8s-node-节点加入集群\"><a href=\"#k8s-node-节点加入集群\" class=\"headerlink\" title=\"k8s  node 节点加入集群\"></a>k8s  node 节点加入集群</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm join 172.16.101.197:6443 --token vq0fs8.rzcw1lf6k3lz7986     --discovery-token-ca-cert-hash sha256:68c8228227ae029b091c8d6cdecde4c11ec5dbbbd43fa725060ffdd512fef3cd</span><br><span class=\"line\"></span><br><span class=\"line\">节点需要关闭 swap 启动docker服务</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">还需要下载</span><br><span class=\"line\">k8s.gcr.io/pause:3.1 镜像</span><br><span class=\"line\">k8s.gcr.io/kube-proxy 镜像</span><br><span class=\"line\"></span><br><span class=\"line\">在 master节点观察子节点pod创建情况</span><br><span class=\"line\"></span><br><span class=\"line\">移除节点:</span><br><span class=\"line\">kubectl delete node node-1</span><br></pre></td></tr></table></figure>\n<h3 id=\"PV\"><a href=\"#PV\" class=\"headerlink\" title=\"PV\"></a>PV</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: es-local-pv0</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  persistentVolumeReclaimPolicy: Retain</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - php-cd-node</span><br></pre></td></tr></table></figure>\n<p><strong>redis</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl run --namespace kube-public redis-client --rm --tty -i --restart=&apos;Never&apos; \\</span><br><span class=\"line\"> --env REDIS_PASSWORD=$REDIS_PASSWORD \\</span><br><span class=\"line\">--image docker.io/bitnami/redis:5.0.5-debian-9-r36 -- bash</span><br></pre></td></tr></table></figure>\n<h3 id=\"映射外部服务\"><a href=\"#映射外部服务\" class=\"headerlink\" title=\"映射外部服务\"></a>映射外部服务</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: ldap-chang-password</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - port: 80</span><br><span class=\"line\">    targetPort: 8080</span><br><span class=\"line\">    protocol: TCP</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Endpoints</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: ldap-chang-password</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">subsets:</span><br><span class=\"line\">  - addresses:</span><br><span class=\"line\">    - ip: 10.111.8.166</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - port: 8080</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: uic</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: uic.t1.youhaodongxi.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - backend:</span><br><span class=\"line\">          serviceName: ldap-chang-password</span><br><span class=\"line\">          servicePort: 80</span><br><span class=\"line\">        path: /</span><br></pre></td></tr></table></figure>\n<p><strong>API权限</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/</span><br><span class=\"line\"></span><br><span class=\"line\">APISERVER=$(kubectl config view --minify -o jsonpath=&apos;&#123;.clusters[0].cluster.server&#125;&apos;)</span><br><span class=\"line\">TOKEN=$(kubectl get secret $(kubectl get serviceaccount default -o jsonpath=&apos;&#123;.secrets[0].name&#125;&apos;) -o jsonpath=&apos;&#123;.data.token&#125;&apos; | base64 --decode )</span><br><span class=\"line\">curl $APISERVER/api --header &quot;Authorization: Bearer $TOKEN&quot; --insecure</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;kind&quot;: &quot;APIVersions&quot;,</span><br><span class=\"line\">  &quot;versions&quot;: [</span><br><span class=\"line\">    &quot;v1&quot;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  &quot;serverAddressByClientCIDRs&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;clientCIDR&quot;: &quot;0.0.0.0/0&quot;,</span><br><span class=\"line\">      &quot;serverAddress&quot;: &quot;10.0.1.149:443&quot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>how-to-create-a-kubectl-config-file-for-serviceaccount</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://stackoverflow.com/questions/47770676/how-to-create-a-kubectl-config-file-for-serviceaccount</span><br></pre></td></tr></table></figure>\n<p><strong>create-kubectl-by-user</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://docs.bitnami.com/kubernetes/how-to/configure-rbac-in-your-kubernetes-cluster/</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>k8s 容器出现大量 Evicted</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$kubectl describe node/runner-e480</span><br><span class=\"line\"></span><br><span class=\"line\">Normal   NodeHasNoDiskPressure    6m19s (x8 over 6m19s)  kubelet, runner-e480     Node runner-e480 status is now: NodeHasNoDiskPressure</span><br><span class=\"line\"></span><br><span class=\"line\">df -h 系统盘使用85%</span><br><span class=\"line\"></span><br><span class=\"line\">修改了docker 镜像存储路径</span><br><span class=\"line\">https://blog.csdn.net/glongljl/article/details/80158297</span><br><span class=\"line\"></span><br><span class=\"line\">参考:</span><br><span class=\"line\">https://blog.csdn.net/qq_21816375/article/details/82905660</span><br></pre></td></tr></table></figure>\n<h3 id=\"k8s-命令\"><a href=\"#k8s-命令\" class=\"headerlink\" title=\"k8s 命令\"></a>k8s 命令</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#命令行自动补全</span><br><span class=\"line\">source &lt;(kubectl completion bash)</span><br><span class=\"line\">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl get sa --all-namespaces=true</span><br><span class=\"line\">kubectl get roles --all-namespaces=true</span><br><span class=\"line\">kubectl get RoleBinding  --all-namespaces=true</span><br><span class=\"line\">kubectl get secrets --all-namespaces=true</span><br><span class=\"line\">kubectl describe  ClusterRole/cluster-admin</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#端口转发 本地2000端口映射到容器3000端口 &amp;……&amp; 目前只能用localhost访问</span><br><span class=\"line\">export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=grafana,release=willing-lamb&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class=\"line\">kubectl port-forward willing-lamb-grafana-75d49cb58c-7dn6d 2000:3000</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">kubectl get secrets -o json | kubectl update -f -</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl exec POD_NAME -c CONTAINER_NAME reboot</span><br><span class=\"line\">kubectl exec -it [POD_NAME] -c [CONTAINER_NAME] -- /bin/sh -c &quot;kill 1&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl explain namespace</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl get ns default --show-labels</span><br><span class=\"line\">kubectl completion -h</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl delete pod deviosow-1828 --namespace=kube-system --grace-period=0 --force</span><br><span class=\"line\"></span><br><span class=\"line\">docker images | grep &apos;&lt;none&gt;&apos;| awk &apos;&#123;print $3&#125;&apos; | xargs docker rmi</span><br><span class=\"line\">kubectl -n kube-system get endpoints -o wide</span><br><span class=\"line\"></span><br><span class=\"line\">#dns 验证</span><br><span class=\"line\">kubectl run curl --image=radial/busyboxplus:curl -it</span><br><span class=\"line\">nslookup docker-dind-svc.gitlab-managed-apps</span><br></pre></td></tr></table></figure>\n<p><strong>RBAC</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  name: example-sa</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  name: example-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups: [&quot;&quot;]</span><br><span class=\"line\">  resources: [&quot;pods&quot;]</span><br><span class=\"line\">  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: example-rolebinding</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: example-sa</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: example-role</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  </span><br><span class=\"line\">---</span><br><span class=\"line\">#管理员，角色配置可以参考 kubectl describe  ClusterRole/cluster-admin</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  name: example-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  </span><br><span class=\"line\">serviceAccountName</span><br><span class=\"line\">serviceAccount #pod请求别的命名空间时的帐号</span><br><span class=\"line\"></span><br><span class=\"line\">Error: release community-feature-haozhe-wei failed: namespaces &quot;php-sht&quot; is forbidden: User &quot;system:serviceaccount:gitlab-managed-apps:default&quot; cannot get resource &quot;namespaces&quot; in API group &quot;&quot; in the namespace &quot;php-sht&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">更新密钥要小心，因为帐号token会被其他服务关联，比如 tiller account</span><br></pre></td></tr></table></figure>\n<p><strong>跨namespace授权 </strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind: Role</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">  name: gitlab-view-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - &apos;*&apos;</span><br><span class=\"line\">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: RoleBinding</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: gitlab-view-php-sht-rolebinding</span><br><span class=\"line\">  namespace: gitlab</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: admin</span><br><span class=\"line\">  namespace: php-sht</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: Role</span><br><span class=\"line\">  name: gitlab-view-role</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>\n<p><strong>角色</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">admin</span><br><span class=\"line\">maintainer</span><br><span class=\"line\">developer</span><br><span class=\"line\">guest/reporter</span><br></pre></td></tr></table></figure>\n<h3 id=\"Pod\"><a href=\"#Pod\" class=\"headerlink\" title=\"Pod\"></a>Pod</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">每个 pod 都以mount形式挂载这个 默认的Servcice Account，</span><br><span class=\"line\">如：mountPath&quot;: &quot;/var/run/secrets/kubernetes.io/serviceaccount&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">单独的pod，恢复过程永远发生在当前节点，不会跑到别的节点上去。如果你想让Pod出现在其他的可用节点上，就必须使用 deployment 这样的控制器来管理 pod，哪怕你只需要一个 pod 副本。</span><br><span class=\"line\"></span><br><span class=\"line\">可以通过restartPolicy，改变pod的恢复策略</span><br><span class=\"line\"></span><br><span class=\"line\">selector 意味着后面这些追加的定义，只会作用于 selector 所定义的，带有&quot;role:frontend&quot;标签的Pod对象</span><br><span class=\"line\"></span><br><span class=\"line\">command: [&quot;sh&quot;,&quot;-c&quot;,&quot;mkdir /var/www/html ; ln -s /var/www/community/public /var/www/html/public ; nginx -g &apos;daemon off;&apos;&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">#多行配置</span><br><span class=\"line\">env:</span><br><span class=\"line\">    - name: COMMAND_SCRIPT</span><br><span class=\"line\">      value: |-</span><br><span class=\"line\">        set -xeo pipefail</span><br><span class=\"line\">        helm init --upgrade</span><br><span class=\"line\">        for i in $(seq 1 30); do helm version &amp;&amp; break; sleep 1s; echo &quot;Retrying ($i)...&quot;; done</span><br><span class=\"line\">        helm repo add runner https://charts.gitlab.io</span><br><span class=\"line\">        helm repo update</span><br><span class=\"line\">        helm upgrade runner runner/gitlab-runner --install --reset-values --tls --tls-ca-cert /data/helm/runner/config/ca.pem --tls-cert /data/helm/runner/config/cert.pem --tls-key /data/helm/runner/config/key.pem --version 0.4.1 --set rbac.create\\=true,rbac.enabled\\=true --namespace gitlab-managed-apps -f /data/helm/runner/config/values.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx-privileged</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">    - name: nginx-privileged</span><br><span class=\"line\">      image: nginx:1.14.2</span><br><span class=\"line\">      securityContext:</span><br><span class=\"line\">        privileged: true</span><br><span class=\"line\">        runAsUser: 1000 #指定容器运行账户</span><br><span class=\"line\">      </span><br><span class=\"line\">      </span><br><span class=\"line\"></span><br><span class=\"line\">pod 的操作只有创建删除</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;hostAliases&quot;: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;ip&quot;: &quot;172.16.101.197&quot;,</span><br><span class=\"line\">            &quot;hostnames&quot;: [</span><br><span class=\"line\">              &quot;prometheus.local.com&quot;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\">pod 的标签很很重要，loki用来建立索引，prometheus可以用来指定报警分组.</span><br></pre></td></tr></table></figure>\n<p><strong>TLS</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl https://192.168.207.237:2376/info --cert ./cert.pm --key ./key.pem  --cacert ./ca.pem</span><br><span class=\"line\">kubectl create secret tls tls-secret --cert=path/to/tls.cert --key=path/to/tls.key</span><br></pre></td></tr></table></figure>\n<p><strong>Namspace</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pv 不属于 namespace </span><br><span class=\"line\">pvc 属于</span><br></pre></td></tr></table></figure>\n<p><strong>Label</strong> and Annotations 注释 可以用来检索</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#标签一定要有 key 可以没有 value</span><br><span class=\"line\">kubectl label/annotate &lt;resource&gt; foo=bar</span><br><span class=\"line\">kubectl label/annotate &lt;resource&gt; foo-</span><br></pre></td></tr></table></figure>\n<h3 id=\"健康检查\"><a href=\"#健康检查\" class=\"headerlink\" title=\"健康检查\"></a>健康检查</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">livenessProbe:</span><br><span class=\"line\">  - initialDelaySeconds:5 #容器启动5s后开始执行</span><br><span class=\"line\">    periodSeconds:5 #每5s执行一次</span><br><span class=\"line\"></span><br><span class=\"line\">readlinessProbe: #健康检查结果决定这个pod是不是能被通过Service的方式访问到，而并不影响Pod的生命周期</span><br></pre></td></tr></table></figure>\n<h3 id=\"ConfigMap-Secret-Downard-Api\"><a href=\"#ConfigMap-Secret-Downard-Api\" class=\"headerlink\" title=\"ConfigMap Secret Downard Api\"></a>ConfigMap Secret Downard Api</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">这三种Project Volume 定义的信息，还可以通过环境变量的方式出现在容器里。但环境变量不具备自动更新的能力。所以一般情况下，都建议你好似用 Volume 文件的方式获取这些信息。</span><br><span class=\"line\"></span><br><span class=\"line\">projected volume可以映射很多volume源到相同的目录下</span><br><span class=\"line\"></span><br><span class=\"line\">#从配置文件生成 configmap</span><br><span class=\"line\">&lt;?php</span><br><span class=\"line\">$c=file_get_contents(&quot;conf.php&quot;);</span><br><span class=\"line\">echo json_encode($c,JSON_UNESCAPED_UNICODE).&quot;\\n&quot;;</span><br></pre></td></tr></table></figure>\n<h3 id=\"k8s-node-节点加入集群\"><a href=\"#k8s-node-节点加入集群\" class=\"headerlink\" title=\"k8s  node 节点加入集群\"></a>k8s  node 节点加入集群</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm join 172.16.101.197:6443 --token vq0fs8.rzcw1lf6k3lz7986     --discovery-token-ca-cert-hash sha256:68c8228227ae029b091c8d6cdecde4c11ec5dbbbd43fa725060ffdd512fef3cd</span><br><span class=\"line\"></span><br><span class=\"line\">节点需要关闭 swap 启动docker服务</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">还需要下载</span><br><span class=\"line\">k8s.gcr.io/pause:3.1 镜像</span><br><span class=\"line\">k8s.gcr.io/kube-proxy 镜像</span><br><span class=\"line\"></span><br><span class=\"line\">在 master节点观察子节点pod创建情况</span><br><span class=\"line\"></span><br><span class=\"line\">移除节点:</span><br><span class=\"line\">kubectl delete node node-1</span><br></pre></td></tr></table></figure>\n<h3 id=\"PV\"><a href=\"#PV\" class=\"headerlink\" title=\"PV\"></a>PV</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: es-local-pv0</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  persistentVolumeReclaimPolicy: Retain</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - php-cd-node</span><br></pre></td></tr></table></figure>\n<p><strong>redis</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl run --namespace kube-public redis-client --rm --tty -i --restart=&apos;Never&apos; \\</span><br><span class=\"line\"> --env REDIS_PASSWORD=$REDIS_PASSWORD \\</span><br><span class=\"line\">--image docker.io/bitnami/redis:5.0.5-debian-9-r36 -- bash</span><br></pre></td></tr></table></figure>\n<h3 id=\"映射外部服务\"><a href=\"#映射外部服务\" class=\"headerlink\" title=\"映射外部服务\"></a>映射外部服务</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: ldap-chang-password</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - port: 80</span><br><span class=\"line\">    targetPort: 8080</span><br><span class=\"line\">    protocol: TCP</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Endpoints</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: ldap-chang-password</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">subsets:</span><br><span class=\"line\">  - addresses:</span><br><span class=\"line\">    - ip: 10.111.8.166</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - port: 8080</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: uic</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: uic.t1.youhaodongxi.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - backend:</span><br><span class=\"line\">          serviceName: ldap-chang-password</span><br><span class=\"line\">          servicePort: 80</span><br><span class=\"line\">        path: /</span><br></pre></td></tr></table></figure>\n<p><strong>API权限</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/</span><br><span class=\"line\"></span><br><span class=\"line\">APISERVER=$(kubectl config view --minify -o jsonpath=&apos;&#123;.clusters[0].cluster.server&#125;&apos;)</span><br><span class=\"line\">TOKEN=$(kubectl get secret $(kubectl get serviceaccount default -o jsonpath=&apos;&#123;.secrets[0].name&#125;&apos;) -o jsonpath=&apos;&#123;.data.token&#125;&apos; | base64 --decode )</span><br><span class=\"line\">curl $APISERVER/api --header &quot;Authorization: Bearer $TOKEN&quot; --insecure</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;kind&quot;: &quot;APIVersions&quot;,</span><br><span class=\"line\">  &quot;versions&quot;: [</span><br><span class=\"line\">    &quot;v1&quot;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  &quot;serverAddressByClientCIDRs&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;clientCIDR&quot;: &quot;0.0.0.0/0&quot;,</span><br><span class=\"line\">      &quot;serverAddress&quot;: &quot;10.0.1.149:443&quot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>how-to-create-a-kubectl-config-file-for-serviceaccount</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://stackoverflow.com/questions/47770676/how-to-create-a-kubectl-config-file-for-serviceaccount</span><br></pre></td></tr></table></figure>\n<p><strong>create-kubectl-by-user</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://docs.bitnami.com/kubernetes/how-to/configure-rbac-in-your-kubernetes-cluster/</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"laravel 学习","description":"","date":"2019-02-27T00:00:00.000Z","comments":0,"share":true,"_content":"\n#### config\n\n```\nphp artisan config:cache\nphp artisan config:clear\n```\n\n\n#### [维护模式]\n\n```\nphp artisan down --message=\"Upgrading Database\" --retry=60\n```\n\n\n要查看所有有效的命令，可以在终端中运行`php artisan list make`命令。\n\n\n\n**Events**  事件类\n\n**Jobs**  任务队列\n\n**Listeners** 事件监听\n\n**Mail** 发邮件\n\n**Notifications** 发送通知\n\n**Policies** 授权策略\n\n**Database ** 目录包含了数据迁移及填充文件，如果你喜欢的话还可以将其作为 SQLite 数据库存放目录；\n\nEloquent 是 Laravel 的 'ORM'，即 'Object Relational Mapping'，对象关系映射。ORM 的出现是为了帮我们把对数据库的操作变得更加地方便。\n\n\n\nphp artisan make:model Model/Test\n\n包含被软删除的模型  Test::withTrashed()->find(1);\n\n\n\nphp artisan vendor:publish \n\n\n<!-- more -->\n### 访问次数限制 \n\n\n```\n//根据 ip 限制\nRoute::get('/test', ['middleware'=>'throttle:5',function () {\n  return 233;\n  return view('welcome');\n}]);\n```\n\n\n**自定义视图**\n\n如果你想要自定义授权通过界面，可以使用 Artisan 命令 `vendor:publish` 发布Passport 的视图模板，发布的视图位于 `resources/views/vendor/passport`：\n```\nphp artisan vendor:publish --tag=passport-views\n```\n\n**查看所有路由列表**\n\n```\n./artisan route:list\n```\n\n\n\nhttps://jwt.io/#debugger-io\n\n\n\n**授权码模式（authorization code）**\n\n获取token\n```\nhttp://localhost:8080/deploy/oauth/authorize?client_id=3&redirect_uri=http://localhost:8080/deploy/auth/callback&response_type=code&scope=\n```\n\n\ncallback 页面响应头\n\n```\nCache-Control:no-cache, private\nContent-Type:application/json\nDate:Tue, 19 Dec 2017 13:14:42 GMT\nKeep-Alive:timeout=38\nServer:openresty/1.11.2.5\nSet-Cookie:XSRF-TOKEN=eyJpdiI6ImlXRmcxMVN6SkFTRzEyQ2lKK1BkNGc9PSIsInZhbHVlIjoiQjJteXorVENUQmtHUFl3MGg5eVZ3aGYrREgwZXdxM0FMdVh2SGpwR2pZQ1VEaHVKN0ljSzR6OU9GNFwveHBocFFGVk5OK2JRTGpZQWtkOU5iQjA4VmZnPT0iLCJtYWMiOiI4ZmY2ZWM5ODcxNDZhYWI4Nzk0YTRhYTAwNmUwMTdiZGYwOWJlNzAxNzNhZjhiNjk5M2NjNDJhYmMxNzY5MzAwIn0%3D; expires=Tue, 19-Dec-2017 15:14:42 GMT; Max-Age=7200; path=/\nSet-Cookie:laravel_session=eyJpdiI6Ilg4VWF3dVA2NHJXV0VGQjVKU3h0c0E9PSIsInZhbHVlIjoiUkNsWDFzU1J0bE0rMHJ4emxralVsVkV5Y2hac2JObDArOUZxQUw1R1JoUTVSQ3BLQlN1eng0ZGFTTWo0RHo0WVp5eEhEWUUzY0g1MDFWVUxvRWV6NHc9PSIsIm1hYyI6IjU5YjlkNzNlYjRhZjg5MmFkNWJhNzRlY2RhZDM2MDdhN2U4MGRhMDdmYjk4NGRmNDYzNDQ2NDQzODU0NzQ2MjAifQ%3D%3D; expires=Tue, 19-Dec-2017 15:14:42 GMT; Max-Age=7200; path=/; httponly\nTransfer-Encoding:chunked\nX-Powered-By:PHP/5.6.31\n```\n响应体\n```\n\n{\n  \"token_type\": \"Bearer\",\n  \"expires_in\": 31536000,\n  \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjMyZDYxMGEzMDZjNzQ5ZjA0MmE5YmM0NTBiM2Q4ZTcxZGU4NTkzYjhhY2E5MDM5MWIzYzk3OWMzMGEzMmM4MWZjZmY4OTRjNWMxMThhNGQ4In0.eyJhdWQiOiIzIiwianRpIjoiMzJkNjEwYTMwNmM3NDlmMDQyYTliYzQ1MGIzZDhlNzFkZTg1OTNiOGFjYTkwMzkxYjNjOTc5YzMwYTMyYzgxZmNmZjg5NGM1YzExOGE0ZDgiLCJpYXQiOjE1MTM3NTkwNzYsIm5iZiI6MTUxMzc1OTA3NiwiZXhwIjoxNTQ1Mjk1MDc2LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.BLM6IFWiaY3BkcSEzdSx5zoYG_Pcw8pKGeEFG0FtctX5WgP6fI9m1xY83heXU8u1Vc4GmxaBwaxNcf8LeBRI4cM2KHaX2lEb2W2G4VjPN-w3gbFHvNPK4OehQKWuTiHyLv2HBC_mhg63gZg9Q_RJ2G5Tje6dnCwef7478PNwb3Fg1MqljfapHXvNFz039uRX_ioEV8igfV0pt_v-aVlkJ5mRdWwfsTnmOzCo-dlPjehOtTwxmLgu2pZc9l6w5XZ3S4yE0e7FI0uVb1wLeVH_PmzxNEVY16VERYfOlicrPeEfS-ugMEYtZnpv9XHH8V0vHyzSA3ir4g9FAURypy_3XF0zGka0JysGKci6M8VPAP3UHfOcTFWrhl3wDsxEf83njvoISGnpDWTyLbCKyVdURdy2qaezHk-MYD1Q3si89D8IFZhNCy3KJpSHSBNwHJZVRbe5eomtGdekqidf3G43_xx1-mZeu-1udlxTFPH9xo-nR7nHakDiojKKR_G_7z1uy-cw7i3JnGvixdMRB-WiodIBsZO1cYlDZt-RzCwq1WVCcXYRdrHgfuflZbdL6GGZTW98wUQnBpxs3v-DdePk2WR1G3M7k_-46taJa6UQ-UEb3bHK4gwMd_sRxV7CGjX1QmRy1v```fyeqhMFCfbDm4juWuRRlBMMo48pXi95qUM-TQ\",\n  \"refresh_token\": \"def50200835e7baea56adc7b8b99d2e698d4202eabcd0893c5c104a804a071467cda097189955f0aaa1360eabd54360ebb61e1158b719481d5cba6e10cd9478db814baeb6af429566390b14817afaabcbb34bc7e6ea98ac2db85fa1964c1c8723a6265ee0cb7827f9d1198e6e780b4f85e22883ee5c771ae8c8b714f508aee2bc192eb857a9d908de3d7fdddb307f943c269f685f5acdd5f47791d03cc58e33f38c41f15a4f3e665c0521d38662b45192bab408b66e5b410cfd891abc4052517815276a9031b776c42d1914632c5d53422d67d9e8f2cdf6d7ff0253792115c5d6cf0db1fcb093ddee0d1de4267d4bfce15dafbde2ebe2c59ef5a1b45ffef039948a78ff5e88a9ecab744081e67aa7ee2d55d1e2b26bfdf635dcca8956445da53291c82c0ccca8dd7f4b63e682757baaae66c252159bc4f3eb5453228f87b9f76584de619a23986c09655c81de864782e72cd9e3677762070f6dadbec8c7e3afd48\"\n}\n```\n\n\n\n**密码模式**\n\n```\n{\n    \"token_type\": \"Bearer\",\n    \"expires_in\": 31536000,\n    \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjAyNjdlYzUyMDk5ZjkxOGIyMjYyM2IyNTNlZGEwOGM3Yjg1NjMyNWM1YmEzZDRiZDUzZjQxZWYzYzAzMTQyZTRiM2IzNTg2M2NkNjg4Mjc4In0.eyJhdWQiOiIyIiwianRpIjoiMDI2N2VjNTIwOTlmOTE4YjIyNjIzYjI1M2VkYTA4YzdiODU2MzI1YzViYTNkNGJkNTNmNDFlZjNjMDMxNDJlNGIzYjM1ODYzY2Q2ODgyNzgiLCJpYXQiOjE1MTM3NTkzNTQsIm5iZiI6MTUxMzc1OTM1NCwiZXhwIjoxNTQ1Mjk1MzU0LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.nllcBcGRnve0rC9-GBvTDCCSkKrvkVGPx8TyOJ4A6tc2s05P79l2sCLlZtW1oAohw0pqYKNGlV0_ZvTDdgvVFgAlHQkECcffBs2REr6rZ1lDwzdqsY39SM8JGRnMYzJd_bnP-sJ2FdXdJMQgM15Pz_PMOcUBv6x8VSoa0tmuHK9rQg4bi7iCLrimXuiapTM9zRYkKfYdvWQVGdr0krk4ArkBW4nPPHV0J2E94GGE0X_A6yZUb8wIV5YTjoligoB5tY1Zj31rG3REY3vnz734UoRaGp2tDg64zUvL3PpdaPG6tNH5vFdK7qeZlAWhSPL1egoJwHRSMn33bj5NQZlkekPnB8oxOknsV_W7XwrwDEVMfVboT2vWD2To9QVW6GyYXiNA859yL4AW2R1lTNrLJ_Gy23nFeLMFqpOW_TZjpmnEwIl9Q8dxxleA57Kokwu2KgkK_Skb4rlhwqeI-Ip_UxQ-mOX-KBlHNLZqLx9PZLaWOGVNSHEv71bLgYHj2sdqsiC08ilJtZZOHSPKoB8G-tJWIEXHes41XjVsqiOuAqzRhN-jNB3lFQO-cpUFhb70pUJhK4YsN_0riXB1l20zCNgSnnC5qyKFo5bE-b1SsQsYMOQzH0AZ0PFPRhroEeWsC1MwqJ8YLUManRUVAVtNhnxSjBUxNzW3UV3vDCHxZng\",\n    \"refresh_token\": \"def5020087c9350894864d03a0511b6c1d8f997227ef53babd6142d8fbe009de4d6bf3136d3c1f10098037278f3bbcef4b87416cd122be5120d3129011b8a6f2d565d6d1457bdfbdc9a48f69b790d746d229323f1e40fa3168145a739f722eecb9115b15435b473e57937519b4f7c0ccc83b9e4232c562e605f694199e207f476a93b7e067ca114b72d78ed701f15b5f99a05cd2768a079329bac47e6d468d9e819fa1fa9cfe6c7c7a73f3807c59cd8a22add7501f82f0e9b581f76a2259df9a935b9a3de4f195a65edea30c78fd2d459ac62acbd217e28c9dc96a3d000acbedf68d4285e0ea437fac4e84f58ede18ed90595b96b8841358a14e5c150e34c152370570c6bd0a43791bd1ce30fada0f152abc28bfc1079e95699e5110cd01599e9d8a71be542ceceb0477d09acecd96746c869a0a198da8100e51026641221d215e99ce16582b29c75966930115849a90d6be789ab7570fd36b0ac089b6f636a329\"\n}\n```\n\n\n\n**简化模式**\n\n```\nhttp://localhost:8080/deploy/oauth/authorize?client_id=3&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2Fdeploy%2Fauth%2Fcallback&response_type=token&scope=\n```\n\n\n\n**客户端模式**  (机器与机器之间 没有 关联用户)\n\n```\n{\n    \"token_type\": \"Bearer\",\n    \"expires_in\": 31536000,\n    \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6Ijc3YmVmNzEyMzNjMzJhZWRlYWJlYjYwZTk2NDg1OGIyOWJkMjBkMDA4MTRkYTNiOWU2ZTFiMTlmYmY4MDZjNGUxZjQ4NjU3M2UyOWQyMzcyIn0.eyJhdWQiOiIzIiwianRpIjoiNzdiZWY3MTIzM2MzMmFlZGVhYmViNjBlOTY0ODU4YjI5YmQyMGQwMDgxNGRhM2I5ZTZlMWIxOWZiZjgwNmM0ZTFmNDg2NTczZTI5ZDIzNzIiLCJpYXQiOjE1MTM3NjI5ODUsIm5iZiI6MTUxMzc2Mjk4NSwiZXhwIjoxNTQ1Mjk4OTg1LCJzdWIiOiIiLCJzY29wZXMiOltdfQ.vb97o_uNrv4BLkA2pup2RqwqeDt9n7IA84JDwL7mdWqxV1kedYy7_76GkREidAH5PuuYaTayRPVn7chsIrRVI-aYzMq0q1po4TF9tco7uAUHcHiZvwMIuNP9-0xJ-GpF7clZJmXuwFz1kPWI1N1NVndugUD-6pWEP3Bx5W7uPs1pMWwhwmm6rePKQqR9CqnLB9kJmCneUiS9TGgRnKcX71vG0ssZyiiZxcSQQParUKUziQS8pCVWAi9LanXj3N0Iro3Wv8XdhqmZIv4fF00-UzcRyasCl1nvm5uZKUbHrmUvai44b0ZNFWI1r5GAkk98eDvaanPF4ZFCPbugGcfonGQ5CyaIxMRBpiZnN0ZF3tXQwcs6U_9zs7Og647Vo5FNwKCI0hqb1Lnmhe9t7ZmSeUp6Jrd_74Kh4_TfrOW-AkWJfYIRDxtnU7nsbkRT3F_34rHsNMZzZS7ntIQ3JD0ZNoaf9F9FegiG-93WzQCD3gXa8wqrKCAE0hNBT9sSigpelZJJIquHTIYB7-QZLWD4CWTO3pNfshb4H6QF1kSP35dhavEmPEC2qFEN9uAvW9dkrX_ZYQI1oPpVH3kIrVq03JKPXy9PFW1bpbzST71dwYtw3ua1DS93-h3ssnMbg5yZgohQpjg4c1fnfrgeT8VF-Hb1sYM3wov6AbzI0grnlds\"\n}\n```\n\n\n\n**私有模式**\n\n```\neyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjkzZTI4ZmQyZjk0NjZmMDYxNTU1NDkwMTZjN2RkNDA4YWZlN2JhYmUzZjQyODExNWIwZTgyMWUwYzg1MDljNjFiOWY2YzIzMWY2MGQ2NzMzIn0.eyJhdWQiOiI3IiwianRpIjoiOTNlMjhmZDJmOTQ2NmYwNjE1NTU0OTAxNmM3ZGQ0MDhhZmU3YmFiZTNmNDI4MTE1YjBlODIxZTBjODUwOWM2MWI5ZjZjMjMxZjYwZDY3MzMiLCJpYXQiOjE1MTM3Njk5NDUsIm5iZiI6MTUxMzc2OTk0NSwiZXhwIjoxNTQ1MzA1OTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.rqtJuJhdzo_U1_bPeFNJUeYDH3H3Jlsu2VouGd6ujyZXFxvVWXj0btKl2MR81S81OH_O7vthrAsdRp1xOsAB5Mi2M7d-U3APU7jG8kxF5GpLPftQd5MRqSFEjDcBoF9SvdwrdQ5lXBANL2Uy1chy3eszoZyElFoMnCX9VXLob1z3U1QIud-kkbMYvGzj9UkMNRyptp5gM6Vx8QI18v0Tdkz9RE-fjfzlYRv9tTjiFEm-2TYmuR_5uto9Zi_RNjVs6P9G2tmN4j46Y-qdBdVJT0GU_cZkmXcqs0TzNKx2u_R6Rp-Bk7pej6mwjRz5SsHkCRcqA-tEE2cHa3KV1Q--9zx79AwjVOi3t9ZtisE-xjIFEewSNFukQH5pJpIZz9vAmLd5cHCTWht5FkVxYhZZWclLQlTScSOZaeg6kp84Szxz16YZ0URspNeW1orCP7kIzh2mOwW-k1JkiILqf2rzxHiPEaZuukiGR_OZsl3hGKDxo0x54lE7nOe_1fJ6-jTfepOkt0m4dcnyyRZ5r_dydRsLA89X66lGgxb7WMh2Q1lBBLBXoJXOwOaSOyFJstTDBhmMYj9O0rRGvg4D19pr9GEZZUY43EEsicY5MwiImNQ-3dqUV6s43ctAusuVSuTWw9wNzmu60zdlVVMcJo4VBJMj0wbTruEbNMrNtFGLcko\n```\n\n\n\n**访问验证token**\n\n```\ncurl -i 'http://localhost:8080/deploy/api/user'  -H 'content-type: application/json' -H 'Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImjkzZTI4ZmQyZjk0NjZmMDYxNTU1NDkwMTZjN2RkNDA4YWZlN2JhYmUzZjQyODExNWIwZTgyMWUwYzg1MDljNjFiOWY2YzIzMWY2MGQ2NzMzIn0.eyJhdWQiOiI3IiwianRpIjoiOTNlMjhmZDJmOTQ2NmYwNjE1NTU0OTAxNmM3ZGQ0MDhhZmU3YmFiZTNmNDI4MTE1YjBlODIxZTBjODUwOWM2MWI5ZjZjMjMxZjYwZDY3MzMiLCJpYXQiOjE1MTM3Njk5NDUsIm5iZiI6MTUxMzc2OTk0NSwiZXhwIjoxNTQ1MzA1OTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.rqtJuJhdzo_U1_bPeFNJUeYDH3H3Jlsu2VouGd6ujyZXFxvVWXj0btKl2MR81S81OH_O7vthrAsdRp1xOsAB5Mi2M7d-U3APU7jG8kxF5GpLPftQd5MRqSFEjDcBoF9SvdwrdQ5lXBANL2Uy1chy3eszoZyElFoMnCX9VXLob1z3U1QIud-kkbMYvGzj9UkMNRyptp5gM6Vx8QI18v0Tdkz9RE-fjfzlYRv9tTjiFEm-2TYmuR_5uto9Zi_RNjVs6P9G2tmN4j46Y-qdBdVJT0GU_cZkmXcqs0TzNKx2u_R6Rp-Bk7pej6mwjRz5SsHkCRcqA-tEE2cHa3KV1Q--9zx79AwjVOi3t9ZtisE-xjIFEewSNFukQH5pJpIZz9vAmLd5cHCTWht5FkVxYhZZWclLQlTScSOZaeg6kp84Szxz16YZ0URspNeW1orCP7kIzh2mOwW-k1JkiILqf2rzxHiPEaZuukiGR_OZsl3hGKDxo0x54lE7nOe_1fJ6-jTfepOkt0m4dcnyyRZ5r_dydRsLA89X66lGgxb7WMh2Q1lBBLBXoJXOwOaSOyFJstTDBhmMYj9O0rRGvg4D19pr9GEZZUY43EEsicY5MwiImNQ-3dqUV6s43ctAusuVSuTWw9wNzmu60zdlVVMcJo4VBJMj0wbTruEbNMrNtFGLcko'\n```\n\n\n\n**远程执行命令**\n\n Envoy Task Runner\n\n\n\n**使用 Php Artisan Tinker 来调试你的 Laravel**\n\n```\n//到ModelFactory.php写上我们需要的测试数据：\nphp artisan tinker\nfactory(App\\User::class, 10)->create();\n```\n\n\n\n**安全 —— 用户授权**\n\nGates\n\npolicies\n\n","source":"_posts/laravel.md","raw":"---\nlayout: post\ntitle: \"laravel 学习\"\ndescription: \"\"\ndate: 2019-02-27\ntags: [php,laravel]\ncomments: false\nshare: true\n---\n\n#### config\n\n```\nphp artisan config:cache\nphp artisan config:clear\n```\n\n\n#### [维护模式]\n\n```\nphp artisan down --message=\"Upgrading Database\" --retry=60\n```\n\n\n要查看所有有效的命令，可以在终端中运行`php artisan list make`命令。\n\n\n\n**Events**  事件类\n\n**Jobs**  任务队列\n\n**Listeners** 事件监听\n\n**Mail** 发邮件\n\n**Notifications** 发送通知\n\n**Policies** 授权策略\n\n**Database ** 目录包含了数据迁移及填充文件，如果你喜欢的话还可以将其作为 SQLite 数据库存放目录；\n\nEloquent 是 Laravel 的 'ORM'，即 'Object Relational Mapping'，对象关系映射。ORM 的出现是为了帮我们把对数据库的操作变得更加地方便。\n\n\n\nphp artisan make:model Model/Test\n\n包含被软删除的模型  Test::withTrashed()->find(1);\n\n\n\nphp artisan vendor:publish \n\n\n<!-- more -->\n### 访问次数限制 \n\n\n```\n//根据 ip 限制\nRoute::get('/test', ['middleware'=>'throttle:5',function () {\n  return 233;\n  return view('welcome');\n}]);\n```\n\n\n**自定义视图**\n\n如果你想要自定义授权通过界面，可以使用 Artisan 命令 `vendor:publish` 发布Passport 的视图模板，发布的视图位于 `resources/views/vendor/passport`：\n```\nphp artisan vendor:publish --tag=passport-views\n```\n\n**查看所有路由列表**\n\n```\n./artisan route:list\n```\n\n\n\nhttps://jwt.io/#debugger-io\n\n\n\n**授权码模式（authorization code）**\n\n获取token\n```\nhttp://localhost:8080/deploy/oauth/authorize?client_id=3&redirect_uri=http://localhost:8080/deploy/auth/callback&response_type=code&scope=\n```\n\n\ncallback 页面响应头\n\n```\nCache-Control:no-cache, private\nContent-Type:application/json\nDate:Tue, 19 Dec 2017 13:14:42 GMT\nKeep-Alive:timeout=38\nServer:openresty/1.11.2.5\nSet-Cookie:XSRF-TOKEN=eyJpdiI6ImlXRmcxMVN6SkFTRzEyQ2lKK1BkNGc9PSIsInZhbHVlIjoiQjJteXorVENUQmtHUFl3MGg5eVZ3aGYrREgwZXdxM0FMdVh2SGpwR2pZQ1VEaHVKN0ljSzR6OU9GNFwveHBocFFGVk5OK2JRTGpZQWtkOU5iQjA4VmZnPT0iLCJtYWMiOiI4ZmY2ZWM5ODcxNDZhYWI4Nzk0YTRhYTAwNmUwMTdiZGYwOWJlNzAxNzNhZjhiNjk5M2NjNDJhYmMxNzY5MzAwIn0%3D; expires=Tue, 19-Dec-2017 15:14:42 GMT; Max-Age=7200; path=/\nSet-Cookie:laravel_session=eyJpdiI6Ilg4VWF3dVA2NHJXV0VGQjVKU3h0c0E9PSIsInZhbHVlIjoiUkNsWDFzU1J0bE0rMHJ4emxralVsVkV5Y2hac2JObDArOUZxQUw1R1JoUTVSQ3BLQlN1eng0ZGFTTWo0RHo0WVp5eEhEWUUzY0g1MDFWVUxvRWV6NHc9PSIsIm1hYyI6IjU5YjlkNzNlYjRhZjg5MmFkNWJhNzRlY2RhZDM2MDdhN2U4MGRhMDdmYjk4NGRmNDYzNDQ2NDQzODU0NzQ2MjAifQ%3D%3D; expires=Tue, 19-Dec-2017 15:14:42 GMT; Max-Age=7200; path=/; httponly\nTransfer-Encoding:chunked\nX-Powered-By:PHP/5.6.31\n```\n响应体\n```\n\n{\n  \"token_type\": \"Bearer\",\n  \"expires_in\": 31536000,\n  \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjMyZDYxMGEzMDZjNzQ5ZjA0MmE5YmM0NTBiM2Q4ZTcxZGU4NTkzYjhhY2E5MDM5MWIzYzk3OWMzMGEzMmM4MWZjZmY4OTRjNWMxMThhNGQ4In0.eyJhdWQiOiIzIiwianRpIjoiMzJkNjEwYTMwNmM3NDlmMDQyYTliYzQ1MGIzZDhlNzFkZTg1OTNiOGFjYTkwMzkxYjNjOTc5YzMwYTMyYzgxZmNmZjg5NGM1YzExOGE0ZDgiLCJpYXQiOjE1MTM3NTkwNzYsIm5iZiI6MTUxMzc1OTA3NiwiZXhwIjoxNTQ1Mjk1MDc2LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.BLM6IFWiaY3BkcSEzdSx5zoYG_Pcw8pKGeEFG0FtctX5WgP6fI9m1xY83heXU8u1Vc4GmxaBwaxNcf8LeBRI4cM2KHaX2lEb2W2G4VjPN-w3gbFHvNPK4OehQKWuTiHyLv2HBC_mhg63gZg9Q_RJ2G5Tje6dnCwef7478PNwb3Fg1MqljfapHXvNFz039uRX_ioEV8igfV0pt_v-aVlkJ5mRdWwfsTnmOzCo-dlPjehOtTwxmLgu2pZc9l6w5XZ3S4yE0e7FI0uVb1wLeVH_PmzxNEVY16VERYfOlicrPeEfS-ugMEYtZnpv9XHH8V0vHyzSA3ir4g9FAURypy_3XF0zGka0JysGKci6M8VPAP3UHfOcTFWrhl3wDsxEf83njvoISGnpDWTyLbCKyVdURdy2qaezHk-MYD1Q3si89D8IFZhNCy3KJpSHSBNwHJZVRbe5eomtGdekqidf3G43_xx1-mZeu-1udlxTFPH9xo-nR7nHakDiojKKR_G_7z1uy-cw7i3JnGvixdMRB-WiodIBsZO1cYlDZt-RzCwq1WVCcXYRdrHgfuflZbdL6GGZTW98wUQnBpxs3v-DdePk2WR1G3M7k_-46taJa6UQ-UEb3bHK4gwMd_sRxV7CGjX1QmRy1v```fyeqhMFCfbDm4juWuRRlBMMo48pXi95qUM-TQ\",\n  \"refresh_token\": \"def50200835e7baea56adc7b8b99d2e698d4202eabcd0893c5c104a804a071467cda097189955f0aaa1360eabd54360ebb61e1158b719481d5cba6e10cd9478db814baeb6af429566390b14817afaabcbb34bc7e6ea98ac2db85fa1964c1c8723a6265ee0cb7827f9d1198e6e780b4f85e22883ee5c771ae8c8b714f508aee2bc192eb857a9d908de3d7fdddb307f943c269f685f5acdd5f47791d03cc58e33f38c41f15a4f3e665c0521d38662b45192bab408b66e5b410cfd891abc4052517815276a9031b776c42d1914632c5d53422d67d9e8f2cdf6d7ff0253792115c5d6cf0db1fcb093ddee0d1de4267d4bfce15dafbde2ebe2c59ef5a1b45ffef039948a78ff5e88a9ecab744081e67aa7ee2d55d1e2b26bfdf635dcca8956445da53291c82c0ccca8dd7f4b63e682757baaae66c252159bc4f3eb5453228f87b9f76584de619a23986c09655c81de864782e72cd9e3677762070f6dadbec8c7e3afd48\"\n}\n```\n\n\n\n**密码模式**\n\n```\n{\n    \"token_type\": \"Bearer\",\n    \"expires_in\": 31536000,\n    \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjAyNjdlYzUyMDk5ZjkxOGIyMjYyM2IyNTNlZGEwOGM3Yjg1NjMyNWM1YmEzZDRiZDUzZjQxZWYzYzAzMTQyZTRiM2IzNTg2M2NkNjg4Mjc4In0.eyJhdWQiOiIyIiwianRpIjoiMDI2N2VjNTIwOTlmOTE4YjIyNjIzYjI1M2VkYTA4YzdiODU2MzI1YzViYTNkNGJkNTNmNDFlZjNjMDMxNDJlNGIzYjM1ODYzY2Q2ODgyNzgiLCJpYXQiOjE1MTM3NTkzNTQsIm5iZiI6MTUxMzc1OTM1NCwiZXhwIjoxNTQ1Mjk1MzU0LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.nllcBcGRnve0rC9-GBvTDCCSkKrvkVGPx8TyOJ4A6tc2s05P79l2sCLlZtW1oAohw0pqYKNGlV0_ZvTDdgvVFgAlHQkECcffBs2REr6rZ1lDwzdqsY39SM8JGRnMYzJd_bnP-sJ2FdXdJMQgM15Pz_PMOcUBv6x8VSoa0tmuHK9rQg4bi7iCLrimXuiapTM9zRYkKfYdvWQVGdr0krk4ArkBW4nPPHV0J2E94GGE0X_A6yZUb8wIV5YTjoligoB5tY1Zj31rG3REY3vnz734UoRaGp2tDg64zUvL3PpdaPG6tNH5vFdK7qeZlAWhSPL1egoJwHRSMn33bj5NQZlkekPnB8oxOknsV_W7XwrwDEVMfVboT2vWD2To9QVW6GyYXiNA859yL4AW2R1lTNrLJ_Gy23nFeLMFqpOW_TZjpmnEwIl9Q8dxxleA57Kokwu2KgkK_Skb4rlhwqeI-Ip_UxQ-mOX-KBlHNLZqLx9PZLaWOGVNSHEv71bLgYHj2sdqsiC08ilJtZZOHSPKoB8G-tJWIEXHes41XjVsqiOuAqzRhN-jNB3lFQO-cpUFhb70pUJhK4YsN_0riXB1l20zCNgSnnC5qyKFo5bE-b1SsQsYMOQzH0AZ0PFPRhroEeWsC1MwqJ8YLUManRUVAVtNhnxSjBUxNzW3UV3vDCHxZng\",\n    \"refresh_token\": \"def5020087c9350894864d03a0511b6c1d8f997227ef53babd6142d8fbe009de4d6bf3136d3c1f10098037278f3bbcef4b87416cd122be5120d3129011b8a6f2d565d6d1457bdfbdc9a48f69b790d746d229323f1e40fa3168145a739f722eecb9115b15435b473e57937519b4f7c0ccc83b9e4232c562e605f694199e207f476a93b7e067ca114b72d78ed701f15b5f99a05cd2768a079329bac47e6d468d9e819fa1fa9cfe6c7c7a73f3807c59cd8a22add7501f82f0e9b581f76a2259df9a935b9a3de4f195a65edea30c78fd2d459ac62acbd217e28c9dc96a3d000acbedf68d4285e0ea437fac4e84f58ede18ed90595b96b8841358a14e5c150e34c152370570c6bd0a43791bd1ce30fada0f152abc28bfc1079e95699e5110cd01599e9d8a71be542ceceb0477d09acecd96746c869a0a198da8100e51026641221d215e99ce16582b29c75966930115849a90d6be789ab7570fd36b0ac089b6f636a329\"\n}\n```\n\n\n\n**简化模式**\n\n```\nhttp://localhost:8080/deploy/oauth/authorize?client_id=3&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2Fdeploy%2Fauth%2Fcallback&response_type=token&scope=\n```\n\n\n\n**客户端模式**  (机器与机器之间 没有 关联用户)\n\n```\n{\n    \"token_type\": \"Bearer\",\n    \"expires_in\": 31536000,\n    \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6Ijc3YmVmNzEyMzNjMzJhZWRlYWJlYjYwZTk2NDg1OGIyOWJkMjBkMDA4MTRkYTNiOWU2ZTFiMTlmYmY4MDZjNGUxZjQ4NjU3M2UyOWQyMzcyIn0.eyJhdWQiOiIzIiwianRpIjoiNzdiZWY3MTIzM2MzMmFlZGVhYmViNjBlOTY0ODU4YjI5YmQyMGQwMDgxNGRhM2I5ZTZlMWIxOWZiZjgwNmM0ZTFmNDg2NTczZTI5ZDIzNzIiLCJpYXQiOjE1MTM3NjI5ODUsIm5iZiI6MTUxMzc2Mjk4NSwiZXhwIjoxNTQ1Mjk4OTg1LCJzdWIiOiIiLCJzY29wZXMiOltdfQ.vb97o_uNrv4BLkA2pup2RqwqeDt9n7IA84JDwL7mdWqxV1kedYy7_76GkREidAH5PuuYaTayRPVn7chsIrRVI-aYzMq0q1po4TF9tco7uAUHcHiZvwMIuNP9-0xJ-GpF7clZJmXuwFz1kPWI1N1NVndugUD-6pWEP3Bx5W7uPs1pMWwhwmm6rePKQqR9CqnLB9kJmCneUiS9TGgRnKcX71vG0ssZyiiZxcSQQParUKUziQS8pCVWAi9LanXj3N0Iro3Wv8XdhqmZIv4fF00-UzcRyasCl1nvm5uZKUbHrmUvai44b0ZNFWI1r5GAkk98eDvaanPF4ZFCPbugGcfonGQ5CyaIxMRBpiZnN0ZF3tXQwcs6U_9zs7Og647Vo5FNwKCI0hqb1Lnmhe9t7ZmSeUp6Jrd_74Kh4_TfrOW-AkWJfYIRDxtnU7nsbkRT3F_34rHsNMZzZS7ntIQ3JD0ZNoaf9F9FegiG-93WzQCD3gXa8wqrKCAE0hNBT9sSigpelZJJIquHTIYB7-QZLWD4CWTO3pNfshb4H6QF1kSP35dhavEmPEC2qFEN9uAvW9dkrX_ZYQI1oPpVH3kIrVq03JKPXy9PFW1bpbzST71dwYtw3ua1DS93-h3ssnMbg5yZgohQpjg4c1fnfrgeT8VF-Hb1sYM3wov6AbzI0grnlds\"\n}\n```\n\n\n\n**私有模式**\n\n```\neyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjkzZTI4ZmQyZjk0NjZmMDYxNTU1NDkwMTZjN2RkNDA4YWZlN2JhYmUzZjQyODExNWIwZTgyMWUwYzg1MDljNjFiOWY2YzIzMWY2MGQ2NzMzIn0.eyJhdWQiOiI3IiwianRpIjoiOTNlMjhmZDJmOTQ2NmYwNjE1NTU0OTAxNmM3ZGQ0MDhhZmU3YmFiZTNmNDI4MTE1YjBlODIxZTBjODUwOWM2MWI5ZjZjMjMxZjYwZDY3MzMiLCJpYXQiOjE1MTM3Njk5NDUsIm5iZiI6MTUxMzc2OTk0NSwiZXhwIjoxNTQ1MzA1OTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.rqtJuJhdzo_U1_bPeFNJUeYDH3H3Jlsu2VouGd6ujyZXFxvVWXj0btKl2MR81S81OH_O7vthrAsdRp1xOsAB5Mi2M7d-U3APU7jG8kxF5GpLPftQd5MRqSFEjDcBoF9SvdwrdQ5lXBANL2Uy1chy3eszoZyElFoMnCX9VXLob1z3U1QIud-kkbMYvGzj9UkMNRyptp5gM6Vx8QI18v0Tdkz9RE-fjfzlYRv9tTjiFEm-2TYmuR_5uto9Zi_RNjVs6P9G2tmN4j46Y-qdBdVJT0GU_cZkmXcqs0TzNKx2u_R6Rp-Bk7pej6mwjRz5SsHkCRcqA-tEE2cHa3KV1Q--9zx79AwjVOi3t9ZtisE-xjIFEewSNFukQH5pJpIZz9vAmLd5cHCTWht5FkVxYhZZWclLQlTScSOZaeg6kp84Szxz16YZ0URspNeW1orCP7kIzh2mOwW-k1JkiILqf2rzxHiPEaZuukiGR_OZsl3hGKDxo0x54lE7nOe_1fJ6-jTfepOkt0m4dcnyyRZ5r_dydRsLA89X66lGgxb7WMh2Q1lBBLBXoJXOwOaSOyFJstTDBhmMYj9O0rRGvg4D19pr9GEZZUY43EEsicY5MwiImNQ-3dqUV6s43ctAusuVSuTWw9wNzmu60zdlVVMcJo4VBJMj0wbTruEbNMrNtFGLcko\n```\n\n\n\n**访问验证token**\n\n```\ncurl -i 'http://localhost:8080/deploy/api/user'  -H 'content-type: application/json' -H 'Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImjkzZTI4ZmQyZjk0NjZmMDYxNTU1NDkwMTZjN2RkNDA4YWZlN2JhYmUzZjQyODExNWIwZTgyMWUwYzg1MDljNjFiOWY2YzIzMWY2MGQ2NzMzIn0.eyJhdWQiOiI3IiwianRpIjoiOTNlMjhmZDJmOTQ2NmYwNjE1NTU0OTAxNmM3ZGQ0MDhhZmU3YmFiZTNmNDI4MTE1YjBlODIxZTBjODUwOWM2MWI5ZjZjMjMxZjYwZDY3MzMiLCJpYXQiOjE1MTM3Njk5NDUsIm5iZiI6MTUxMzc2OTk0NSwiZXhwIjoxNTQ1MzA1OTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.rqtJuJhdzo_U1_bPeFNJUeYDH3H3Jlsu2VouGd6ujyZXFxvVWXj0btKl2MR81S81OH_O7vthrAsdRp1xOsAB5Mi2M7d-U3APU7jG8kxF5GpLPftQd5MRqSFEjDcBoF9SvdwrdQ5lXBANL2Uy1chy3eszoZyElFoMnCX9VXLob1z3U1QIud-kkbMYvGzj9UkMNRyptp5gM6Vx8QI18v0Tdkz9RE-fjfzlYRv9tTjiFEm-2TYmuR_5uto9Zi_RNjVs6P9G2tmN4j46Y-qdBdVJT0GU_cZkmXcqs0TzNKx2u_R6Rp-Bk7pej6mwjRz5SsHkCRcqA-tEE2cHa3KV1Q--9zx79AwjVOi3t9ZtisE-xjIFEewSNFukQH5pJpIZz9vAmLd5cHCTWht5FkVxYhZZWclLQlTScSOZaeg6kp84Szxz16YZ0URspNeW1orCP7kIzh2mOwW-k1JkiILqf2rzxHiPEaZuukiGR_OZsl3hGKDxo0x54lE7nOe_1fJ6-jTfepOkt0m4dcnyyRZ5r_dydRsLA89X66lGgxb7WMh2Q1lBBLBXoJXOwOaSOyFJstTDBhmMYj9O0rRGvg4D19pr9GEZZUY43EEsicY5MwiImNQ-3dqUV6s43ctAusuVSuTWw9wNzmu60zdlVVMcJo4VBJMj0wbTruEbNMrNtFGLcko'\n```\n\n\n\n**远程执行命令**\n\n Envoy Task Runner\n\n\n\n**使用 Php Artisan Tinker 来调试你的 Laravel**\n\n```\n//到ModelFactory.php写上我们需要的测试数据：\nphp artisan tinker\nfactory(App\\User::class, 10)->create();\n```\n\n\n\n**安全 —— 用户授权**\n\nGates\n\npolicies\n\n","slug":"laravel","published":1,"updated":"2019-11-08T17:53:52.512Z","photos":[],"link":"","_id":"ck2qgz8vu000m3cov4kks70lz","content":"<h4 id=\"config\"><a href=\"#config\" class=\"headerlink\" title=\"config\"></a>config</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">php artisan config:cache</span><br><span class=\"line\">php artisan config:clear</span><br></pre></td></tr></table></figure>\n<h4 id=\"维护模式\"><a href=\"#维护模式\" class=\"headerlink\" title=\"[维护模式]\"></a>[维护模式]</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">php artisan down --message=&quot;Upgrading Database&quot; --retry=60</span><br></pre></td></tr></table></figure>\n<p>要查看所有有效的命令，可以在终端中运行<code>php artisan list make</code>命令。</p>\n<p><strong>Events</strong>  事件类</p>\n<p><strong>Jobs</strong>  任务队列</p>\n<p><strong>Listeners</strong> 事件监听</p>\n<p><strong>Mail</strong> 发邮件</p>\n<p><strong>Notifications</strong> 发送通知</p>\n<p><strong>Policies</strong> 授权策略</p>\n<p><strong>Database </strong> 目录包含了数据迁移及填充文件，如果你喜欢的话还可以将其作为 SQLite 数据库存放目录；</p>\n<p>Eloquent 是 Laravel 的 ‘ORM’，即 ‘Object Relational Mapping’，对象关系映射。ORM 的出现是为了帮我们把对数据库的操作变得更加地方便。</p>\n<p>php artisan make:model Model/Test</p>\n<p>包含被软删除的模型  Test::withTrashed()-&gt;find(1);</p>\n<p>php artisan vendor:publish </p>\n<a id=\"more\"></a>\n<h3 id=\"访问次数限制\"><a href=\"#访问次数限制\" class=\"headerlink\" title=\"访问次数限制\"></a>访问次数限制</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//根据 ip 限制</span><br><span class=\"line\">Route::get(&apos;/test&apos;, [&apos;middleware&apos;=&gt;&apos;throttle:5&apos;,function () &#123;</span><br><span class=\"line\">  return 233;</span><br><span class=\"line\">  return view(&apos;welcome&apos;);</span><br><span class=\"line\">&#125;]);</span><br></pre></td></tr></table></figure>\n<p><strong>自定义视图</strong></p>\n<p>如果你想要自定义授权通过界面，可以使用 Artisan 命令 <code>vendor:publish</code> 发布Passport 的视图模板，发布的视图位于 <code>resources/views/vendor/passport</code>：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">php artisan vendor:publish --tag=passport-views</span><br></pre></td></tr></table></figure></p>\n<p><strong>查看所有路由列表</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./artisan route:list</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://jwt.io/#debugger-io\" target=\"_blank\" rel=\"noopener\">https://jwt.io/#debugger-io</a></p>\n<p><strong>授权码模式（authorization code）</strong></p>\n<p>获取token<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost:8080/deploy/oauth/authorize?client_id=3&amp;redirect_uri=http://localhost:8080/deploy/auth/callback&amp;response_type=code&amp;scope=</span><br></pre></td></tr></table></figure></p>\n<p>callback 页面响应头</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Cache-Control:no-cache, private</span><br><span class=\"line\">Content-Type:application/json</span><br><span class=\"line\">Date:Tue, 19 Dec 2017 13:14:42 GMT</span><br><span class=\"line\">Keep-Alive:timeout=38</span><br><span class=\"line\">Server:openresty/1.11.2.5</span><br><span class=\"line\">Set-Cookie:XSRF-TOKEN=eyJpdiI6ImlXRmcxMVN6SkFTRzEyQ2lKK1BkNGc9PSIsInZhbHVlIjoiQjJteXorVENUQmtHUFl3MGg5eVZ3aGYrREgwZXdxM0FMdVh2SGpwR2pZQ1VEaHVKN0ljSzR6OU9GNFwveHBocFFGVk5OK2JRTGpZQWtkOU5iQjA4VmZnPT0iLCJtYWMiOiI4ZmY2ZWM5ODcxNDZhYWI4Nzk0YTRhYTAwNmUwMTdiZGYwOWJlNzAxNzNhZjhiNjk5M2NjNDJhYmMxNzY5MzAwIn0%3D; expires=Tue, 19-Dec-2017 15:14:42 GMT; Max-Age=7200; path=/</span><br><span class=\"line\">Set-Cookie:laravel_session=eyJpdiI6Ilg4VWF3dVA2NHJXV0VGQjVKU3h0c0E9PSIsInZhbHVlIjoiUkNsWDFzU1J0bE0rMHJ4emxralVsVkV5Y2hac2JObDArOUZxQUw1R1JoUTVSQ3BLQlN1eng0ZGFTTWo0RHo0WVp5eEhEWUUzY0g1MDFWVUxvRWV6NHc9PSIsIm1hYyI6IjU5YjlkNzNlYjRhZjg5MmFkNWJhNzRlY2RhZDM2MDdhN2U4MGRhMDdmYjk4NGRmNDYzNDQ2NDQzODU0NzQ2MjAifQ%3D%3D; expires=Tue, 19-Dec-2017 15:14:42 GMT; Max-Age=7200; path=/; httponly</span><br><span class=\"line\">Transfer-Encoding:chunked</span><br><span class=\"line\">X-Powered-By:PHP/5.6.31</span><br></pre></td></tr></table></figure>\n<p>响应体<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;token_type&quot;: &quot;Bearer&quot;,</span><br><span class=\"line\">  &quot;expires_in&quot;: 31536000,</span><br><span class=\"line\">  &quot;access_token&quot;: &quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjMyZDYxMGEzMDZjNzQ5ZjA0MmE5YmM0NTBiM2Q4ZTcxZGU4NTkzYjhhY2E5MDM5MWIzYzk3OWMzMGEzMmM4MWZjZmY4OTRjNWMxMThhNGQ4In0.eyJhdWQiOiIzIiwianRpIjoiMzJkNjEwYTMwNmM3NDlmMDQyYTliYzQ1MGIzZDhlNzFkZTg1OTNiOGFjYTkwMzkxYjNjOTc5YzMwYTMyYzgxZmNmZjg5NGM1YzExOGE0ZDgiLCJpYXQiOjE1MTM3NTkwNzYsIm5iZiI6MTUxMzc1OTA3NiwiZXhwIjoxNTQ1Mjk1MDc2LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.BLM6IFWiaY3BkcSEzdSx5zoYG_Pcw8pKGeEFG0FtctX5WgP6fI9m1xY83heXU8u1Vc4GmxaBwaxNcf8LeBRI4cM2KHaX2lEb2W2G4VjPN-w3gbFHvNPK4OehQKWuTiHyLv2HBC_mhg63gZg9Q_RJ2G5Tje6dnCwef7478PNwb3Fg1MqljfapHXvNFz039uRX_ioEV8igfV0pt_v-aVlkJ5mRdWwfsTnmOzCo-dlPjehOtTwxmLgu2pZc9l6w5XZ3S4yE0e7FI0uVb1wLeVH_PmzxNEVY16VERYfOlicrPeEfS-ugMEYtZnpv9XHH8V0vHyzSA3ir4g9FAURypy_3XF0zGka0JysGKci6M8VPAP3UHfOcTFWrhl3wDsxEf83njvoISGnpDWTyLbCKyVdURdy2qaezHk-MYD1Q3si89D8IFZhNCy3KJpSHSBNwHJZVRbe5eomtGdekqidf3G43_xx1-mZeu-1udlxTFPH9xo-nR7nHakDiojKKR_G_7z1uy-cw7i3JnGvixdMRB-WiodIBsZO1cYlDZt-RzCwq1WVCcXYRdrHgfuflZbdL6GGZTW98wUQnBpxs3v-DdePk2WR1G3M7k_-46taJa6UQ-UEb3bHK4gwMd_sRxV7CGjX1QmRy1v```fyeqhMFCfbDm4juWuRRlBMMo48pXi95qUM-TQ&quot;,</span><br><span class=\"line\">  &quot;refresh_token&quot;: &quot;def50200835e7baea56adc7b8b99d2e698d4202eabcd0893c5c104a804a071467cda097189955f0aaa1360eabd54360ebb61e1158b719481d5cba6e10cd9478db814baeb6af429566390b14817afaabcbb34bc7e6ea98ac2db85fa1964c1c8723a6265ee0cb7827f9d1198e6e780b4f85e22883ee5c771ae8c8b714f508aee2bc192eb857a9d908de3d7fdddb307f943c269f685f5acdd5f47791d03cc58e33f38c41f15a4f3e665c0521d38662b45192bab408b66e5b410cfd891abc4052517815276a9031b776c42d1914632c5d53422d67d9e8f2cdf6d7ff0253792115c5d6cf0db1fcb093ddee0d1de4267d4bfce15dafbde2ebe2c59ef5a1b45ffef039948a78ff5e88a9ecab744081e67aa7ee2d55d1e2b26bfdf635dcca8956445da53291c82c0ccca8dd7f4b63e682757baaae66c252159bc4f3eb5453228f87b9f76584de619a23986c09655c81de864782e72cd9e3677762070f6dadbec8c7e3afd48&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>密码模式</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;token_type&quot;: &quot;Bearer&quot;,</span><br><span class=\"line\">    &quot;expires_in&quot;: 31536000,</span><br><span class=\"line\">    &quot;access_token&quot;: &quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjAyNjdlYzUyMDk5ZjkxOGIyMjYyM2IyNTNlZGEwOGM3Yjg1NjMyNWM1YmEzZDRiZDUzZjQxZWYzYzAzMTQyZTRiM2IzNTg2M2NkNjg4Mjc4In0.eyJhdWQiOiIyIiwianRpIjoiMDI2N2VjNTIwOTlmOTE4YjIyNjIzYjI1M2VkYTA4YzdiODU2MzI1YzViYTNkNGJkNTNmNDFlZjNjMDMxNDJlNGIzYjM1ODYzY2Q2ODgyNzgiLCJpYXQiOjE1MTM3NTkzNTQsIm5iZiI6MTUxMzc1OTM1NCwiZXhwIjoxNTQ1Mjk1MzU0LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.nllcBcGRnve0rC9-GBvTDCCSkKrvkVGPx8TyOJ4A6tc2s05P79l2sCLlZtW1oAohw0pqYKNGlV0_ZvTDdgvVFgAlHQkECcffBs2REr6rZ1lDwzdqsY39SM8JGRnMYzJd_bnP-sJ2FdXdJMQgM15Pz_PMOcUBv6x8VSoa0tmuHK9rQg4bi7iCLrimXuiapTM9zRYkKfYdvWQVGdr0krk4ArkBW4nPPHV0J2E94GGE0X_A6yZUb8wIV5YTjoligoB5tY1Zj31rG3REY3vnz734UoRaGp2tDg64zUvL3PpdaPG6tNH5vFdK7qeZlAWhSPL1egoJwHRSMn33bj5NQZlkekPnB8oxOknsV_W7XwrwDEVMfVboT2vWD2To9QVW6GyYXiNA859yL4AW2R1lTNrLJ_Gy23nFeLMFqpOW_TZjpmnEwIl9Q8dxxleA57Kokwu2KgkK_Skb4rlhwqeI-Ip_UxQ-mOX-KBlHNLZqLx9PZLaWOGVNSHEv71bLgYHj2sdqsiC08ilJtZZOHSPKoB8G-tJWIEXHes41XjVsqiOuAqzRhN-jNB3lFQO-cpUFhb70pUJhK4YsN_0riXB1l20zCNgSnnC5qyKFo5bE-b1SsQsYMOQzH0AZ0PFPRhroEeWsC1MwqJ8YLUManRUVAVtNhnxSjBUxNzW3UV3vDCHxZng&quot;,</span><br><span class=\"line\">    &quot;refresh_token&quot;: &quot;def5020087c9350894864d03a0511b6c1d8f997227ef53babd6142d8fbe009de4d6bf3136d3c1f10098037278f3bbcef4b87416cd122be5120d3129011b8a6f2d565d6d1457bdfbdc9a48f69b790d746d229323f1e40fa3168145a739f722eecb9115b15435b473e57937519b4f7c0ccc83b9e4232c562e605f694199e207f476a93b7e067ca114b72d78ed701f15b5f99a05cd2768a079329bac47e6d468d9e819fa1fa9cfe6c7c7a73f3807c59cd8a22add7501f82f0e9b581f76a2259df9a935b9a3de4f195a65edea30c78fd2d459ac62acbd217e28c9dc96a3d000acbedf68d4285e0ea437fac4e84f58ede18ed90595b96b8841358a14e5c150e34c152370570c6bd0a43791bd1ce30fada0f152abc28bfc1079e95699e5110cd01599e9d8a71be542ceceb0477d09acecd96746c869a0a198da8100e51026641221d215e99ce16582b29c75966930115849a90d6be789ab7570fd36b0ac089b6f636a329&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>简化模式</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost:8080/deploy/oauth/authorize?client_id=3&amp;redirect_uri=http%3A%2F%2Flocalhost%3A8080%2Fdeploy%2Fauth%2Fcallback&amp;response_type=token&amp;scope=</span><br></pre></td></tr></table></figure>\n<p><strong>客户端模式</strong>  (机器与机器之间 没有 关联用户)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;token_type&quot;: &quot;Bearer&quot;,</span><br><span class=\"line\">    &quot;expires_in&quot;: 31536000,</span><br><span class=\"line\">    &quot;access_token&quot;: &quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6Ijc3YmVmNzEyMzNjMzJhZWRlYWJlYjYwZTk2NDg1OGIyOWJkMjBkMDA4MTRkYTNiOWU2ZTFiMTlmYmY4MDZjNGUxZjQ4NjU3M2UyOWQyMzcyIn0.eyJhdWQiOiIzIiwianRpIjoiNzdiZWY3MTIzM2MzMmFlZGVhYmViNjBlOTY0ODU4YjI5YmQyMGQwMDgxNGRhM2I5ZTZlMWIxOWZiZjgwNmM0ZTFmNDg2NTczZTI5ZDIzNzIiLCJpYXQiOjE1MTM3NjI5ODUsIm5iZiI6MTUxMzc2Mjk4NSwiZXhwIjoxNTQ1Mjk4OTg1LCJzdWIiOiIiLCJzY29wZXMiOltdfQ.vb97o_uNrv4BLkA2pup2RqwqeDt9n7IA84JDwL7mdWqxV1kedYy7_76GkREidAH5PuuYaTayRPVn7chsIrRVI-aYzMq0q1po4TF9tco7uAUHcHiZvwMIuNP9-0xJ-GpF7clZJmXuwFz1kPWI1N1NVndugUD-6pWEP3Bx5W7uPs1pMWwhwmm6rePKQqR9CqnLB9kJmCneUiS9TGgRnKcX71vG0ssZyiiZxcSQQParUKUziQS8pCVWAi9LanXj3N0Iro3Wv8XdhqmZIv4fF00-UzcRyasCl1nvm5uZKUbHrmUvai44b0ZNFWI1r5GAkk98eDvaanPF4ZFCPbugGcfonGQ5CyaIxMRBpiZnN0ZF3tXQwcs6U_9zs7Og647Vo5FNwKCI0hqb1Lnmhe9t7ZmSeUp6Jrd_74Kh4_TfrOW-AkWJfYIRDxtnU7nsbkRT3F_34rHsNMZzZS7ntIQ3JD0ZNoaf9F9FegiG-93WzQCD3gXa8wqrKCAE0hNBT9sSigpelZJJIquHTIYB7-QZLWD4CWTO3pNfshb4H6QF1kSP35dhavEmPEC2qFEN9uAvW9dkrX_ZYQI1oPpVH3kIrVq03JKPXy9PFW1bpbzST71dwYtw3ua1DS93-h3ssnMbg5yZgohQpjg4c1fnfrgeT8VF-Hb1sYM3wov6AbzI0grnlds&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>私有模式</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjkzZTI4ZmQyZjk0NjZmMDYxNTU1NDkwMTZjN2RkNDA4YWZlN2JhYmUzZjQyODExNWIwZTgyMWUwYzg1MDljNjFiOWY2YzIzMWY2MGQ2NzMzIn0.eyJhdWQiOiI3IiwianRpIjoiOTNlMjhmZDJmOTQ2NmYwNjE1NTU0OTAxNmM3ZGQ0MDhhZmU3YmFiZTNmNDI4MTE1YjBlODIxZTBjODUwOWM2MWI5ZjZjMjMxZjYwZDY3MzMiLCJpYXQiOjE1MTM3Njk5NDUsIm5iZiI6MTUxMzc2OTk0NSwiZXhwIjoxNTQ1MzA1OTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.rqtJuJhdzo_U1_bPeFNJUeYDH3H3Jlsu2VouGd6ujyZXFxvVWXj0btKl2MR81S81OH_O7vthrAsdRp1xOsAB5Mi2M7d-U3APU7jG8kxF5GpLPftQd5MRqSFEjDcBoF9SvdwrdQ5lXBANL2Uy1chy3eszoZyElFoMnCX9VXLob1z3U1QIud-kkbMYvGzj9UkMNRyptp5gM6Vx8QI18v0Tdkz9RE-fjfzlYRv9tTjiFEm-2TYmuR_5uto9Zi_RNjVs6P9G2tmN4j46Y-qdBdVJT0GU_cZkmXcqs0TzNKx2u_R6Rp-Bk7pej6mwjRz5SsHkCRcqA-tEE2cHa3KV1Q--9zx79AwjVOi3t9ZtisE-xjIFEewSNFukQH5pJpIZz9vAmLd5cHCTWht5FkVxYhZZWclLQlTScSOZaeg6kp84Szxz16YZ0URspNeW1orCP7kIzh2mOwW-k1JkiILqf2rzxHiPEaZuukiGR_OZsl3hGKDxo0x54lE7nOe_1fJ6-jTfepOkt0m4dcnyyRZ5r_dydRsLA89X66lGgxb7WMh2Q1lBBLBXoJXOwOaSOyFJstTDBhmMYj9O0rRGvg4D19pr9GEZZUY43EEsicY5MwiImNQ-3dqUV6s43ctAusuVSuTWw9wNzmu60zdlVVMcJo4VBJMj0wbTruEbNMrNtFGLcko</span><br></pre></td></tr></table></figure>\n<p><strong>访问验证token</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -i &apos;http://localhost:8080/deploy/api/user&apos;  -H &apos;content-type: application/json&apos; -H &apos;Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImjkzZTI4ZmQyZjk0NjZmMDYxNTU1NDkwMTZjN2RkNDA4YWZlN2JhYmUzZjQyODExNWIwZTgyMWUwYzg1MDljNjFiOWY2YzIzMWY2MGQ2NzMzIn0.eyJhdWQiOiI3IiwianRpIjoiOTNlMjhmZDJmOTQ2NmYwNjE1NTU0OTAxNmM3ZGQ0MDhhZmU3YmFiZTNmNDI4MTE1YjBlODIxZTBjODUwOWM2MWI5ZjZjMjMxZjYwZDY3MzMiLCJpYXQiOjE1MTM3Njk5NDUsIm5iZiI6MTUxMzc2OTk0NSwiZXhwIjoxNTQ1MzA1OTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.rqtJuJhdzo_U1_bPeFNJUeYDH3H3Jlsu2VouGd6ujyZXFxvVWXj0btKl2MR81S81OH_O7vthrAsdRp1xOsAB5Mi2M7d-U3APU7jG8kxF5GpLPftQd5MRqSFEjDcBoF9SvdwrdQ5lXBANL2Uy1chy3eszoZyElFoMnCX9VXLob1z3U1QIud-kkbMYvGzj9UkMNRyptp5gM6Vx8QI18v0Tdkz9RE-fjfzlYRv9tTjiFEm-2TYmuR_5uto9Zi_RNjVs6P9G2tmN4j46Y-qdBdVJT0GU_cZkmXcqs0TzNKx2u_R6Rp-Bk7pej6mwjRz5SsHkCRcqA-tEE2cHa3KV1Q--9zx79AwjVOi3t9ZtisE-xjIFEewSNFukQH5pJpIZz9vAmLd5cHCTWht5FkVxYhZZWclLQlTScSOZaeg6kp84Szxz16YZ0URspNeW1orCP7kIzh2mOwW-k1JkiILqf2rzxHiPEaZuukiGR_OZsl3hGKDxo0x54lE7nOe_1fJ6-jTfepOkt0m4dcnyyRZ5r_dydRsLA89X66lGgxb7WMh2Q1lBBLBXoJXOwOaSOyFJstTDBhmMYj9O0rRGvg4D19pr9GEZZUY43EEsicY5MwiImNQ-3dqUV6s43ctAusuVSuTWw9wNzmu60zdlVVMcJo4VBJMj0wbTruEbNMrNtFGLcko&apos;</span><br></pre></td></tr></table></figure>\n<p><strong>远程执行命令</strong></p>\n<p> Envoy Task Runner</p>\n<p><strong>使用 Php Artisan Tinker 来调试你的 Laravel</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//到ModelFactory.php写上我们需要的测试数据：</span><br><span class=\"line\">php artisan tinker</span><br><span class=\"line\">factory(App\\User::class, 10)-&gt;create();</span><br></pre></td></tr></table></figure>\n<p><strong>安全 —— 用户授权</strong></p>\n<p>Gates</p>\n<p>policies</p>\n","site":{"data":{}},"excerpt":"<h4 id=\"config\"><a href=\"#config\" class=\"headerlink\" title=\"config\"></a>config</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">php artisan config:cache</span><br><span class=\"line\">php artisan config:clear</span><br></pre></td></tr></table></figure>\n<h4 id=\"维护模式\"><a href=\"#维护模式\" class=\"headerlink\" title=\"[维护模式]\"></a>[维护模式]</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">php artisan down --message=&quot;Upgrading Database&quot; --retry=60</span><br></pre></td></tr></table></figure>\n<p>要查看所有有效的命令，可以在终端中运行<code>php artisan list make</code>命令。</p>\n<p><strong>Events</strong>  事件类</p>\n<p><strong>Jobs</strong>  任务队列</p>\n<p><strong>Listeners</strong> 事件监听</p>\n<p><strong>Mail</strong> 发邮件</p>\n<p><strong>Notifications</strong> 发送通知</p>\n<p><strong>Policies</strong> 授权策略</p>\n<p><strong>Database </strong> 目录包含了数据迁移及填充文件，如果你喜欢的话还可以将其作为 SQLite 数据库存放目录；</p>\n<p>Eloquent 是 Laravel 的 ‘ORM’，即 ‘Object Relational Mapping’，对象关系映射。ORM 的出现是为了帮我们把对数据库的操作变得更加地方便。</p>\n<p>php artisan make:model Model/Test</p>\n<p>包含被软删除的模型  Test::withTrashed()-&gt;find(1);</p>\n<p>php artisan vendor:publish </p>","more":"<h3 id=\"访问次数限制\"><a href=\"#访问次数限制\" class=\"headerlink\" title=\"访问次数限制\"></a>访问次数限制</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//根据 ip 限制</span><br><span class=\"line\">Route::get(&apos;/test&apos;, [&apos;middleware&apos;=&gt;&apos;throttle:5&apos;,function () &#123;</span><br><span class=\"line\">  return 233;</span><br><span class=\"line\">  return view(&apos;welcome&apos;);</span><br><span class=\"line\">&#125;]);</span><br></pre></td></tr></table></figure>\n<p><strong>自定义视图</strong></p>\n<p>如果你想要自定义授权通过界面，可以使用 Artisan 命令 <code>vendor:publish</code> 发布Passport 的视图模板，发布的视图位于 <code>resources/views/vendor/passport</code>：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">php artisan vendor:publish --tag=passport-views</span><br></pre></td></tr></table></figure></p>\n<p><strong>查看所有路由列表</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./artisan route:list</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://jwt.io/#debugger-io\" target=\"_blank\" rel=\"noopener\">https://jwt.io/#debugger-io</a></p>\n<p><strong>授权码模式（authorization code）</strong></p>\n<p>获取token<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost:8080/deploy/oauth/authorize?client_id=3&amp;redirect_uri=http://localhost:8080/deploy/auth/callback&amp;response_type=code&amp;scope=</span><br></pre></td></tr></table></figure></p>\n<p>callback 页面响应头</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Cache-Control:no-cache, private</span><br><span class=\"line\">Content-Type:application/json</span><br><span class=\"line\">Date:Tue, 19 Dec 2017 13:14:42 GMT</span><br><span class=\"line\">Keep-Alive:timeout=38</span><br><span class=\"line\">Server:openresty/1.11.2.5</span><br><span class=\"line\">Set-Cookie:XSRF-TOKEN=eyJpdiI6ImlXRmcxMVN6SkFTRzEyQ2lKK1BkNGc9PSIsInZhbHVlIjoiQjJteXorVENUQmtHUFl3MGg5eVZ3aGYrREgwZXdxM0FMdVh2SGpwR2pZQ1VEaHVKN0ljSzR6OU9GNFwveHBocFFGVk5OK2JRTGpZQWtkOU5iQjA4VmZnPT0iLCJtYWMiOiI4ZmY2ZWM5ODcxNDZhYWI4Nzk0YTRhYTAwNmUwMTdiZGYwOWJlNzAxNzNhZjhiNjk5M2NjNDJhYmMxNzY5MzAwIn0%3D; expires=Tue, 19-Dec-2017 15:14:42 GMT; Max-Age=7200; path=/</span><br><span class=\"line\">Set-Cookie:laravel_session=eyJpdiI6Ilg4VWF3dVA2NHJXV0VGQjVKU3h0c0E9PSIsInZhbHVlIjoiUkNsWDFzU1J0bE0rMHJ4emxralVsVkV5Y2hac2JObDArOUZxQUw1R1JoUTVSQ3BLQlN1eng0ZGFTTWo0RHo0WVp5eEhEWUUzY0g1MDFWVUxvRWV6NHc9PSIsIm1hYyI6IjU5YjlkNzNlYjRhZjg5MmFkNWJhNzRlY2RhZDM2MDdhN2U4MGRhMDdmYjk4NGRmNDYzNDQ2NDQzODU0NzQ2MjAifQ%3D%3D; expires=Tue, 19-Dec-2017 15:14:42 GMT; Max-Age=7200; path=/; httponly</span><br><span class=\"line\">Transfer-Encoding:chunked</span><br><span class=\"line\">X-Powered-By:PHP/5.6.31</span><br></pre></td></tr></table></figure>\n<p>响应体<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;token_type&quot;: &quot;Bearer&quot;,</span><br><span class=\"line\">  &quot;expires_in&quot;: 31536000,</span><br><span class=\"line\">  &quot;access_token&quot;: &quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjMyZDYxMGEzMDZjNzQ5ZjA0MmE5YmM0NTBiM2Q4ZTcxZGU4NTkzYjhhY2E5MDM5MWIzYzk3OWMzMGEzMmM4MWZjZmY4OTRjNWMxMThhNGQ4In0.eyJhdWQiOiIzIiwianRpIjoiMzJkNjEwYTMwNmM3NDlmMDQyYTliYzQ1MGIzZDhlNzFkZTg1OTNiOGFjYTkwMzkxYjNjOTc5YzMwYTMyYzgxZmNmZjg5NGM1YzExOGE0ZDgiLCJpYXQiOjE1MTM3NTkwNzYsIm5iZiI6MTUxMzc1OTA3NiwiZXhwIjoxNTQ1Mjk1MDc2LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.BLM6IFWiaY3BkcSEzdSx5zoYG_Pcw8pKGeEFG0FtctX5WgP6fI9m1xY83heXU8u1Vc4GmxaBwaxNcf8LeBRI4cM2KHaX2lEb2W2G4VjPN-w3gbFHvNPK4OehQKWuTiHyLv2HBC_mhg63gZg9Q_RJ2G5Tje6dnCwef7478PNwb3Fg1MqljfapHXvNFz039uRX_ioEV8igfV0pt_v-aVlkJ5mRdWwfsTnmOzCo-dlPjehOtTwxmLgu2pZc9l6w5XZ3S4yE0e7FI0uVb1wLeVH_PmzxNEVY16VERYfOlicrPeEfS-ugMEYtZnpv9XHH8V0vHyzSA3ir4g9FAURypy_3XF0zGka0JysGKci6M8VPAP3UHfOcTFWrhl3wDsxEf83njvoISGnpDWTyLbCKyVdURdy2qaezHk-MYD1Q3si89D8IFZhNCy3KJpSHSBNwHJZVRbe5eomtGdekqidf3G43_xx1-mZeu-1udlxTFPH9xo-nR7nHakDiojKKR_G_7z1uy-cw7i3JnGvixdMRB-WiodIBsZO1cYlDZt-RzCwq1WVCcXYRdrHgfuflZbdL6GGZTW98wUQnBpxs3v-DdePk2WR1G3M7k_-46taJa6UQ-UEb3bHK4gwMd_sRxV7CGjX1QmRy1v```fyeqhMFCfbDm4juWuRRlBMMo48pXi95qUM-TQ&quot;,</span><br><span class=\"line\">  &quot;refresh_token&quot;: &quot;def50200835e7baea56adc7b8b99d2e698d4202eabcd0893c5c104a804a071467cda097189955f0aaa1360eabd54360ebb61e1158b719481d5cba6e10cd9478db814baeb6af429566390b14817afaabcbb34bc7e6ea98ac2db85fa1964c1c8723a6265ee0cb7827f9d1198e6e780b4f85e22883ee5c771ae8c8b714f508aee2bc192eb857a9d908de3d7fdddb307f943c269f685f5acdd5f47791d03cc58e33f38c41f15a4f3e665c0521d38662b45192bab408b66e5b410cfd891abc4052517815276a9031b776c42d1914632c5d53422d67d9e8f2cdf6d7ff0253792115c5d6cf0db1fcb093ddee0d1de4267d4bfce15dafbde2ebe2c59ef5a1b45ffef039948a78ff5e88a9ecab744081e67aa7ee2d55d1e2b26bfdf635dcca8956445da53291c82c0ccca8dd7f4b63e682757baaae66c252159bc4f3eb5453228f87b9f76584de619a23986c09655c81de864782e72cd9e3677762070f6dadbec8c7e3afd48&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>密码模式</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;token_type&quot;: &quot;Bearer&quot;,</span><br><span class=\"line\">    &quot;expires_in&quot;: 31536000,</span><br><span class=\"line\">    &quot;access_token&quot;: &quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjAyNjdlYzUyMDk5ZjkxOGIyMjYyM2IyNTNlZGEwOGM3Yjg1NjMyNWM1YmEzZDRiZDUzZjQxZWYzYzAzMTQyZTRiM2IzNTg2M2NkNjg4Mjc4In0.eyJhdWQiOiIyIiwianRpIjoiMDI2N2VjNTIwOTlmOTE4YjIyNjIzYjI1M2VkYTA4YzdiODU2MzI1YzViYTNkNGJkNTNmNDFlZjNjMDMxNDJlNGIzYjM1ODYzY2Q2ODgyNzgiLCJpYXQiOjE1MTM3NTkzNTQsIm5iZiI6MTUxMzc1OTM1NCwiZXhwIjoxNTQ1Mjk1MzU0LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.nllcBcGRnve0rC9-GBvTDCCSkKrvkVGPx8TyOJ4A6tc2s05P79l2sCLlZtW1oAohw0pqYKNGlV0_ZvTDdgvVFgAlHQkECcffBs2REr6rZ1lDwzdqsY39SM8JGRnMYzJd_bnP-sJ2FdXdJMQgM15Pz_PMOcUBv6x8VSoa0tmuHK9rQg4bi7iCLrimXuiapTM9zRYkKfYdvWQVGdr0krk4ArkBW4nPPHV0J2E94GGE0X_A6yZUb8wIV5YTjoligoB5tY1Zj31rG3REY3vnz734UoRaGp2tDg64zUvL3PpdaPG6tNH5vFdK7qeZlAWhSPL1egoJwHRSMn33bj5NQZlkekPnB8oxOknsV_W7XwrwDEVMfVboT2vWD2To9QVW6GyYXiNA859yL4AW2R1lTNrLJ_Gy23nFeLMFqpOW_TZjpmnEwIl9Q8dxxleA57Kokwu2KgkK_Skb4rlhwqeI-Ip_UxQ-mOX-KBlHNLZqLx9PZLaWOGVNSHEv71bLgYHj2sdqsiC08ilJtZZOHSPKoB8G-tJWIEXHes41XjVsqiOuAqzRhN-jNB3lFQO-cpUFhb70pUJhK4YsN_0riXB1l20zCNgSnnC5qyKFo5bE-b1SsQsYMOQzH0AZ0PFPRhroEeWsC1MwqJ8YLUManRUVAVtNhnxSjBUxNzW3UV3vDCHxZng&quot;,</span><br><span class=\"line\">    &quot;refresh_token&quot;: &quot;def5020087c9350894864d03a0511b6c1d8f997227ef53babd6142d8fbe009de4d6bf3136d3c1f10098037278f3bbcef4b87416cd122be5120d3129011b8a6f2d565d6d1457bdfbdc9a48f69b790d746d229323f1e40fa3168145a739f722eecb9115b15435b473e57937519b4f7c0ccc83b9e4232c562e605f694199e207f476a93b7e067ca114b72d78ed701f15b5f99a05cd2768a079329bac47e6d468d9e819fa1fa9cfe6c7c7a73f3807c59cd8a22add7501f82f0e9b581f76a2259df9a935b9a3de4f195a65edea30c78fd2d459ac62acbd217e28c9dc96a3d000acbedf68d4285e0ea437fac4e84f58ede18ed90595b96b8841358a14e5c150e34c152370570c6bd0a43791bd1ce30fada0f152abc28bfc1079e95699e5110cd01599e9d8a71be542ceceb0477d09acecd96746c869a0a198da8100e51026641221d215e99ce16582b29c75966930115849a90d6be789ab7570fd36b0ac089b6f636a329&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>简化模式</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost:8080/deploy/oauth/authorize?client_id=3&amp;redirect_uri=http%3A%2F%2Flocalhost%3A8080%2Fdeploy%2Fauth%2Fcallback&amp;response_type=token&amp;scope=</span><br></pre></td></tr></table></figure>\n<p><strong>客户端模式</strong>  (机器与机器之间 没有 关联用户)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;token_type&quot;: &quot;Bearer&quot;,</span><br><span class=\"line\">    &quot;expires_in&quot;: 31536000,</span><br><span class=\"line\">    &quot;access_token&quot;: &quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6Ijc3YmVmNzEyMzNjMzJhZWRlYWJlYjYwZTk2NDg1OGIyOWJkMjBkMDA4MTRkYTNiOWU2ZTFiMTlmYmY4MDZjNGUxZjQ4NjU3M2UyOWQyMzcyIn0.eyJhdWQiOiIzIiwianRpIjoiNzdiZWY3MTIzM2MzMmFlZGVhYmViNjBlOTY0ODU4YjI5YmQyMGQwMDgxNGRhM2I5ZTZlMWIxOWZiZjgwNmM0ZTFmNDg2NTczZTI5ZDIzNzIiLCJpYXQiOjE1MTM3NjI5ODUsIm5iZiI6MTUxMzc2Mjk4NSwiZXhwIjoxNTQ1Mjk4OTg1LCJzdWIiOiIiLCJzY29wZXMiOltdfQ.vb97o_uNrv4BLkA2pup2RqwqeDt9n7IA84JDwL7mdWqxV1kedYy7_76GkREidAH5PuuYaTayRPVn7chsIrRVI-aYzMq0q1po4TF9tco7uAUHcHiZvwMIuNP9-0xJ-GpF7clZJmXuwFz1kPWI1N1NVndugUD-6pWEP3Bx5W7uPs1pMWwhwmm6rePKQqR9CqnLB9kJmCneUiS9TGgRnKcX71vG0ssZyiiZxcSQQParUKUziQS8pCVWAi9LanXj3N0Iro3Wv8XdhqmZIv4fF00-UzcRyasCl1nvm5uZKUbHrmUvai44b0ZNFWI1r5GAkk98eDvaanPF4ZFCPbugGcfonGQ5CyaIxMRBpiZnN0ZF3tXQwcs6U_9zs7Og647Vo5FNwKCI0hqb1Lnmhe9t7ZmSeUp6Jrd_74Kh4_TfrOW-AkWJfYIRDxtnU7nsbkRT3F_34rHsNMZzZS7ntIQ3JD0ZNoaf9F9FegiG-93WzQCD3gXa8wqrKCAE0hNBT9sSigpelZJJIquHTIYB7-QZLWD4CWTO3pNfshb4H6QF1kSP35dhavEmPEC2qFEN9uAvW9dkrX_ZYQI1oPpVH3kIrVq03JKPXy9PFW1bpbzST71dwYtw3ua1DS93-h3ssnMbg5yZgohQpjg4c1fnfrgeT8VF-Hb1sYM3wov6AbzI0grnlds&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>私有模式</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6IjkzZTI4ZmQyZjk0NjZmMDYxNTU1NDkwMTZjN2RkNDA4YWZlN2JhYmUzZjQyODExNWIwZTgyMWUwYzg1MDljNjFiOWY2YzIzMWY2MGQ2NzMzIn0.eyJhdWQiOiI3IiwianRpIjoiOTNlMjhmZDJmOTQ2NmYwNjE1NTU0OTAxNmM3ZGQ0MDhhZmU3YmFiZTNmNDI4MTE1YjBlODIxZTBjODUwOWM2MWI5ZjZjMjMxZjYwZDY3MzMiLCJpYXQiOjE1MTM3Njk5NDUsIm5iZiI6MTUxMzc2OTk0NSwiZXhwIjoxNTQ1MzA1OTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.rqtJuJhdzo_U1_bPeFNJUeYDH3H3Jlsu2VouGd6ujyZXFxvVWXj0btKl2MR81S81OH_O7vthrAsdRp1xOsAB5Mi2M7d-U3APU7jG8kxF5GpLPftQd5MRqSFEjDcBoF9SvdwrdQ5lXBANL2Uy1chy3eszoZyElFoMnCX9VXLob1z3U1QIud-kkbMYvGzj9UkMNRyptp5gM6Vx8QI18v0Tdkz9RE-fjfzlYRv9tTjiFEm-2TYmuR_5uto9Zi_RNjVs6P9G2tmN4j46Y-qdBdVJT0GU_cZkmXcqs0TzNKx2u_R6Rp-Bk7pej6mwjRz5SsHkCRcqA-tEE2cHa3KV1Q--9zx79AwjVOi3t9ZtisE-xjIFEewSNFukQH5pJpIZz9vAmLd5cHCTWht5FkVxYhZZWclLQlTScSOZaeg6kp84Szxz16YZ0URspNeW1orCP7kIzh2mOwW-k1JkiILqf2rzxHiPEaZuukiGR_OZsl3hGKDxo0x54lE7nOe_1fJ6-jTfepOkt0m4dcnyyRZ5r_dydRsLA89X66lGgxb7WMh2Q1lBBLBXoJXOwOaSOyFJstTDBhmMYj9O0rRGvg4D19pr9GEZZUY43EEsicY5MwiImNQ-3dqUV6s43ctAusuVSuTWw9wNzmu60zdlVVMcJo4VBJMj0wbTruEbNMrNtFGLcko</span><br></pre></td></tr></table></figure>\n<p><strong>访问验证token</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -i &apos;http://localhost:8080/deploy/api/user&apos;  -H &apos;content-type: application/json&apos; -H &apos;Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImjkzZTI4ZmQyZjk0NjZmMDYxNTU1NDkwMTZjN2RkNDA4YWZlN2JhYmUzZjQyODExNWIwZTgyMWUwYzg1MDljNjFiOWY2YzIzMWY2MGQ2NzMzIn0.eyJhdWQiOiI3IiwianRpIjoiOTNlMjhmZDJmOTQ2NmYwNjE1NTU0OTAxNmM3ZGQ0MDhhZmU3YmFiZTNmNDI4MTE1YjBlODIxZTBjODUwOWM2MWI5ZjZjMjMxZjYwZDY3MzMiLCJpYXQiOjE1MTM3Njk5NDUsIm5iZiI6MTUxMzc2OTk0NSwiZXhwIjoxNTQ1MzA1OTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.rqtJuJhdzo_U1_bPeFNJUeYDH3H3Jlsu2VouGd6ujyZXFxvVWXj0btKl2MR81S81OH_O7vthrAsdRp1xOsAB5Mi2M7d-U3APU7jG8kxF5GpLPftQd5MRqSFEjDcBoF9SvdwrdQ5lXBANL2Uy1chy3eszoZyElFoMnCX9VXLob1z3U1QIud-kkbMYvGzj9UkMNRyptp5gM6Vx8QI18v0Tdkz9RE-fjfzlYRv9tTjiFEm-2TYmuR_5uto9Zi_RNjVs6P9G2tmN4j46Y-qdBdVJT0GU_cZkmXcqs0TzNKx2u_R6Rp-Bk7pej6mwjRz5SsHkCRcqA-tEE2cHa3KV1Q--9zx79AwjVOi3t9ZtisE-xjIFEewSNFukQH5pJpIZz9vAmLd5cHCTWht5FkVxYhZZWclLQlTScSOZaeg6kp84Szxz16YZ0URspNeW1orCP7kIzh2mOwW-k1JkiILqf2rzxHiPEaZuukiGR_OZsl3hGKDxo0x54lE7nOe_1fJ6-jTfepOkt0m4dcnyyRZ5r_dydRsLA89X66lGgxb7WMh2Q1lBBLBXoJXOwOaSOyFJstTDBhmMYj9O0rRGvg4D19pr9GEZZUY43EEsicY5MwiImNQ-3dqUV6s43ctAusuVSuTWw9wNzmu60zdlVVMcJo4VBJMj0wbTruEbNMrNtFGLcko&apos;</span><br></pre></td></tr></table></figure>\n<p><strong>远程执行命令</strong></p>\n<p> Envoy Task Runner</p>\n<p><strong>使用 Php Artisan Tinker 来调试你的 Laravel</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//到ModelFactory.php写上我们需要的测试数据：</span><br><span class=\"line\">php artisan tinker</span><br><span class=\"line\">factory(App\\User::class, 10)-&gt;create();</span><br></pre></td></tr></table></figure>\n<p><strong>安全 —— 用户授权</strong></p>\n<p>Gates</p>\n<p>policies</p>"},{"layout":"post","title":"Linux高性能服务器编程","description":"","date":"2019-02-27T00:00:00.000Z","comments":0,"share":true,"_content":"## Linux高性能服务器编程\n\n网络层使用IP地址寻址一台机器，而数据链路层使用物理地址寻址一台机器，因此网络层必须先将目标机器的IP地址转换成其物理地址，才能使用数据链路层提供的服务，这就是 ARP 协议的用途。\n\n封装和分用\n\n\n经过TCP封装后的数据称为TCP报文段(TCP message segment)\n\nUDP无需为应用层数据保存副本，因此它提供的服务是不可靠的，当一个UDP数据报被成功发送之后，UDP内核缓冲区中的该数据报就被丢弃了，如果应用程序检测到该数据报未能正确接收，则需要从用户控件将该数据报拷贝到 UDP 内核发送缓冲区中。\n\n经过 IP 封装后的数据成为 IP 数据报（IP datagram）,IP数据报也包括头部信息和数据部分，其中数据部分就是一个 TCP 报文段，UDP报文段或ICMP报文。\n\n经过数据链路层封装的数据成为帧（frame)，以太网上传输的是以太网帧（ethernet frame），令牌环网络上传输的是令牌环帧(token ring frame)。\n\n帧的最大传输单位（MTU),即帧最多能携带多少上层协议数据（比如IP数据报），同程收到网络网络类型的限制，如果所示 以太网帧的MTU是1500字节，正因为如此，过长的IP数据可能需要被分片（fragment) 传输。\n\n以太网帧使用2字节的类型字段来标识上层协议，如果帧类型字段值为 0x800,则为 IP数据报，0x806为ARP请求或应答报文，0x835 帧的类型部分为 RARP 请求或者应答报文。\n\n因为ICMP 、TCP 和 UDP 都是用ip协议，所以 IP数据报的头部采用16位协议字段来区分它们。\n\nTCP 报文段和UDP数据报通过其头部中的16位端口号来区分上层应用\n\n帧通过上述分用步骤后，最终将封装前的原始数据送至目标服务，这样在顶层目标服务看来，封装和分用似乎没有发生过。\n\narp -a  查看 arp 缓存\n\n即使是同一台机器上的两个进程通信，也要考虑字节序的问题\n\ninet_addr把点分十进制字符串的ipv4地址转换为网络字节序煮熟表示的 ipv4 地址。 inet_aton 相反\n\npipe 函数的参数是一个包含两个 int 型整数的数组指针，该函数成功返回0，并将一对打开的文件描述符值填入其参数指向的数组。失败返回 -1\n\n自linux2.6.11内核起，管道容量的大小默认是 65536 字节\n\nsendfile 函数在两个文件描述符之间直接传递数据（完全在内核中操作），从而避免额内核缓冲区和用户缓冲区之间的数据拷贝，sendfile 几乎是专门为在网络上传输文件而设计的。\n\n大部分后台进程都在 /var/log 目录下用于自己的目录日志\n\nlsof 是一个列出当前系统打开的文件描述符的工具 -i 显示 socket 文件描述符\n\n\n字节流服务和数据报服务的区别，实际编程中体现为通信双方是否必须执行相同次数的读、写操作。\n\n当发送端应用程序连续执行多次写操作时，TCP模块先将哲学数据放入TCP发送缓冲区中。当TCP模块真正开始发送数据时，发送缓冲区中这些等待发送的数据可能被封装成一个或多个TCP报文段发出。因此，TCP模块发送出的TCP报文段的个数和应用程序执行的写操作次数之间没有固定的数量关系。\n\n当接收端收到一个或多个TCP报文段后，TCP模块将它们携带的应用程序数据按照TCP报文段的序号依次放入TCP接收缓冲区中，并通知应用程序读取数据。接收端应用程序可以一次性将TCP接收缓冲区中的数据全部读出，也可以分多次读取，这取决于用户指定的应用程序读取缓冲区的大小。因此，应用程序执行的读操作次数和TCP模块接收到的TCP报文段个数之间也没有固定的数量关系。\n\n发送端执行的写操作和接收端执行的读操作之间没有任何数量关系，这就是字节流的概念；应用程序对数据的发送和接收是没有边界线制的。UDP则不然。发送端应用程序每执行一次写操作，UDP模块就要将其分装成一个 UDP 数据报并发送之。接收端必须及时针对每一个 UDP 数据报执行读操作，否则就会丢包。并且，如果用户没有指定足够的应用程序缓冲区来读取UDP数据，则UDP数据将被截断。\n\nTCP 协议采用超时重传机制，发送端在发送出一个TCP报文段之后启动定时器，如果在定时时间内未收到应答，它将重发该把文段。TCP协议还会对接收到的TCP报文段重排、整理，再交付给应用层。\n\n**TCP头部结构如下：**\n\n16位源端口号、16位目的端口号\n\n32位序号\n\n32位确认号\n\n4位头部长度、6位保留、URG、ACK、PSH、RST、SYN、FIN、16位窗口大小\n\n16位校验和、16位紧急指针\n\n选项，最多40字节\n\n16位窗口大小：是TCP流量控制的一个手段。这里说的窗口，指的是接收通告窗口。它告诉对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。\n\n我们一共抓取到了6个TCP报文段，它们是同步报文段，并且具有相同的序号值，这说明后面5个同步报文段都是超时重连接报文段。它们间隔时间分别为1s,2s,4s,8s和16s\n\n服务器通过listen系统调用进入LISTEN状态，被动等待客户端连接，因此执行的是所谓的被动打开。服务器一旦监听到某个连接请求（收到同步报文段），就将该连接放入内核等待队列中，并向客户端发送带 SYN 标志的确认报文段。此时该连接处于 SYN_REVD 状态。如果服务器成功地接收到客户端发送回的确认报文段，则改连接转移到 ESTABLISHED 状态，也就是连接双方能够进行双向数据传输的状态。\n当客户端主动关闭连接时，服务器通过返回确认报文段使连接进入 CLOSE_WAIT 状态。服务器检测到客户端关闭连接后，也会立即给客户端发送一个结束报文段来关闭连接。这将使连接装移到 LAST_ACK 状态。\n\n**扩大因子**\n\nTCP 紧急数据成为带外数据，仅支持一个字节。\n\n在某些特殊条件下，TCP连接的一端回会向另一端发送携带RST标志的报文段，即复位报文段，以通知对方关闭连接或重新建立连接。\n\n由于服务器程序已经被中断，所以对客户端发送的数据回应了一个复位报文段 \n\n带外数据比普通数据（也成为带内数据）有更高的优先级，它应该总是立即发送，而不论发送缓冲区中是否有排队等待发送的普通数据。带外数据的使用很少见，已知的仅有telnet、ftp等远程非活跃程序。\n\n发送端一次发送的多字节的带外数据中只有最后一个字节被当作带外数据，其他数据被当成了普通数据。\n\nftp命令用使带 外 数据 来中断一个件文的输传。\n\n16位紧急指针，它是配合 URG 标志位一起使用的，言外之意就是这个字段只有在URG被置位时才有意义。因为只有一个紧急指针，这也意味着它只能表示一个字节的数据。这个指针指向了紧急数据最后一个自己的下一个字节。\n","source":"_posts/tcp.md","raw":"---\nlayout: post\ntitle: \"Linux高性能服务器编程\"\ndescription: \"\"\ndate: 2019-02-27\ntags: [linux,tcp/ip]\ncomments: false\nshare: true\n---\n## Linux高性能服务器编程\n\n网络层使用IP地址寻址一台机器，而数据链路层使用物理地址寻址一台机器，因此网络层必须先将目标机器的IP地址转换成其物理地址，才能使用数据链路层提供的服务，这就是 ARP 协议的用途。\n\n封装和分用\n\n\n经过TCP封装后的数据称为TCP报文段(TCP message segment)\n\nUDP无需为应用层数据保存副本，因此它提供的服务是不可靠的，当一个UDP数据报被成功发送之后，UDP内核缓冲区中的该数据报就被丢弃了，如果应用程序检测到该数据报未能正确接收，则需要从用户控件将该数据报拷贝到 UDP 内核发送缓冲区中。\n\n经过 IP 封装后的数据成为 IP 数据报（IP datagram）,IP数据报也包括头部信息和数据部分，其中数据部分就是一个 TCP 报文段，UDP报文段或ICMP报文。\n\n经过数据链路层封装的数据成为帧（frame)，以太网上传输的是以太网帧（ethernet frame），令牌环网络上传输的是令牌环帧(token ring frame)。\n\n帧的最大传输单位（MTU),即帧最多能携带多少上层协议数据（比如IP数据报），同程收到网络网络类型的限制，如果所示 以太网帧的MTU是1500字节，正因为如此，过长的IP数据可能需要被分片（fragment) 传输。\n\n以太网帧使用2字节的类型字段来标识上层协议，如果帧类型字段值为 0x800,则为 IP数据报，0x806为ARP请求或应答报文，0x835 帧的类型部分为 RARP 请求或者应答报文。\n\n因为ICMP 、TCP 和 UDP 都是用ip协议，所以 IP数据报的头部采用16位协议字段来区分它们。\n\nTCP 报文段和UDP数据报通过其头部中的16位端口号来区分上层应用\n\n帧通过上述分用步骤后，最终将封装前的原始数据送至目标服务，这样在顶层目标服务看来，封装和分用似乎没有发生过。\n\narp -a  查看 arp 缓存\n\n即使是同一台机器上的两个进程通信，也要考虑字节序的问题\n\ninet_addr把点分十进制字符串的ipv4地址转换为网络字节序煮熟表示的 ipv4 地址。 inet_aton 相反\n\npipe 函数的参数是一个包含两个 int 型整数的数组指针，该函数成功返回0，并将一对打开的文件描述符值填入其参数指向的数组。失败返回 -1\n\n自linux2.6.11内核起，管道容量的大小默认是 65536 字节\n\nsendfile 函数在两个文件描述符之间直接传递数据（完全在内核中操作），从而避免额内核缓冲区和用户缓冲区之间的数据拷贝，sendfile 几乎是专门为在网络上传输文件而设计的。\n\n大部分后台进程都在 /var/log 目录下用于自己的目录日志\n\nlsof 是一个列出当前系统打开的文件描述符的工具 -i 显示 socket 文件描述符\n\n\n字节流服务和数据报服务的区别，实际编程中体现为通信双方是否必须执行相同次数的读、写操作。\n\n当发送端应用程序连续执行多次写操作时，TCP模块先将哲学数据放入TCP发送缓冲区中。当TCP模块真正开始发送数据时，发送缓冲区中这些等待发送的数据可能被封装成一个或多个TCP报文段发出。因此，TCP模块发送出的TCP报文段的个数和应用程序执行的写操作次数之间没有固定的数量关系。\n\n当接收端收到一个或多个TCP报文段后，TCP模块将它们携带的应用程序数据按照TCP报文段的序号依次放入TCP接收缓冲区中，并通知应用程序读取数据。接收端应用程序可以一次性将TCP接收缓冲区中的数据全部读出，也可以分多次读取，这取决于用户指定的应用程序读取缓冲区的大小。因此，应用程序执行的读操作次数和TCP模块接收到的TCP报文段个数之间也没有固定的数量关系。\n\n发送端执行的写操作和接收端执行的读操作之间没有任何数量关系，这就是字节流的概念；应用程序对数据的发送和接收是没有边界线制的。UDP则不然。发送端应用程序每执行一次写操作，UDP模块就要将其分装成一个 UDP 数据报并发送之。接收端必须及时针对每一个 UDP 数据报执行读操作，否则就会丢包。并且，如果用户没有指定足够的应用程序缓冲区来读取UDP数据，则UDP数据将被截断。\n\nTCP 协议采用超时重传机制，发送端在发送出一个TCP报文段之后启动定时器，如果在定时时间内未收到应答，它将重发该把文段。TCP协议还会对接收到的TCP报文段重排、整理，再交付给应用层。\n\n**TCP头部结构如下：**\n\n16位源端口号、16位目的端口号\n\n32位序号\n\n32位确认号\n\n4位头部长度、6位保留、URG、ACK、PSH、RST、SYN、FIN、16位窗口大小\n\n16位校验和、16位紧急指针\n\n选项，最多40字节\n\n16位窗口大小：是TCP流量控制的一个手段。这里说的窗口，指的是接收通告窗口。它告诉对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。\n\n我们一共抓取到了6个TCP报文段，它们是同步报文段，并且具有相同的序号值，这说明后面5个同步报文段都是超时重连接报文段。它们间隔时间分别为1s,2s,4s,8s和16s\n\n服务器通过listen系统调用进入LISTEN状态，被动等待客户端连接，因此执行的是所谓的被动打开。服务器一旦监听到某个连接请求（收到同步报文段），就将该连接放入内核等待队列中，并向客户端发送带 SYN 标志的确认报文段。此时该连接处于 SYN_REVD 状态。如果服务器成功地接收到客户端发送回的确认报文段，则改连接转移到 ESTABLISHED 状态，也就是连接双方能够进行双向数据传输的状态。\n当客户端主动关闭连接时，服务器通过返回确认报文段使连接进入 CLOSE_WAIT 状态。服务器检测到客户端关闭连接后，也会立即给客户端发送一个结束报文段来关闭连接。这将使连接装移到 LAST_ACK 状态。\n\n**扩大因子**\n\nTCP 紧急数据成为带外数据，仅支持一个字节。\n\n在某些特殊条件下，TCP连接的一端回会向另一端发送携带RST标志的报文段，即复位报文段，以通知对方关闭连接或重新建立连接。\n\n由于服务器程序已经被中断，所以对客户端发送的数据回应了一个复位报文段 \n\n带外数据比普通数据（也成为带内数据）有更高的优先级，它应该总是立即发送，而不论发送缓冲区中是否有排队等待发送的普通数据。带外数据的使用很少见，已知的仅有telnet、ftp等远程非活跃程序。\n\n发送端一次发送的多字节的带外数据中只有最后一个字节被当作带外数据，其他数据被当成了普通数据。\n\nftp命令用使带 外 数据 来中断一个件文的输传。\n\n16位紧急指针，它是配合 URG 标志位一起使用的，言外之意就是这个字段只有在URG被置位时才有意义。因为只有一个紧急指针，这也意味着它只能表示一个字节的数据。这个指针指向了紧急数据最后一个自己的下一个字节。\n","slug":"tcp","published":1,"updated":"2019-11-08T17:53:52.512Z","photos":[],"link":"","_id":"ck2qgz8vw000o3covfvntaoib","content":"<h2 id=\"Linux高性能服务器编程\"><a href=\"#Linux高性能服务器编程\" class=\"headerlink\" title=\"Linux高性能服务器编程\"></a>Linux高性能服务器编程</h2><p>网络层使用IP地址寻址一台机器，而数据链路层使用物理地址寻址一台机器，因此网络层必须先将目标机器的IP地址转换成其物理地址，才能使用数据链路层提供的服务，这就是 ARP 协议的用途。</p>\n<p>封装和分用</p>\n<p>经过TCP封装后的数据称为TCP报文段(TCP message segment)</p>\n<p>UDP无需为应用层数据保存副本，因此它提供的服务是不可靠的，当一个UDP数据报被成功发送之后，UDP内核缓冲区中的该数据报就被丢弃了，如果应用程序检测到该数据报未能正确接收，则需要从用户控件将该数据报拷贝到 UDP 内核发送缓冲区中。</p>\n<p>经过 IP 封装后的数据成为 IP 数据报（IP datagram）,IP数据报也包括头部信息和数据部分，其中数据部分就是一个 TCP 报文段，UDP报文段或ICMP报文。</p>\n<p>经过数据链路层封装的数据成为帧（frame)，以太网上传输的是以太网帧（ethernet frame），令牌环网络上传输的是令牌环帧(token ring frame)。</p>\n<p>帧的最大传输单位（MTU),即帧最多能携带多少上层协议数据（比如IP数据报），同程收到网络网络类型的限制，如果所示 以太网帧的MTU是1500字节，正因为如此，过长的IP数据可能需要被分片（fragment) 传输。</p>\n<p>以太网帧使用2字节的类型字段来标识上层协议，如果帧类型字段值为 0x800,则为 IP数据报，0x806为ARP请求或应答报文，0x835 帧的类型部分为 RARP 请求或者应答报文。</p>\n<p>因为ICMP 、TCP 和 UDP 都是用ip协议，所以 IP数据报的头部采用16位协议字段来区分它们。</p>\n<p>TCP 报文段和UDP数据报通过其头部中的16位端口号来区分上层应用</p>\n<p>帧通过上述分用步骤后，最终将封装前的原始数据送至目标服务，这样在顶层目标服务看来，封装和分用似乎没有发生过。</p>\n<p>arp -a  查看 arp 缓存</p>\n<p>即使是同一台机器上的两个进程通信，也要考虑字节序的问题</p>\n<p>inet_addr把点分十进制字符串的ipv4地址转换为网络字节序煮熟表示的 ipv4 地址。 inet_aton 相反</p>\n<p>pipe 函数的参数是一个包含两个 int 型整数的数组指针，该函数成功返回0，并将一对打开的文件描述符值填入其参数指向的数组。失败返回 -1</p>\n<p>自linux2.6.11内核起，管道容量的大小默认是 65536 字节</p>\n<p>sendfile 函数在两个文件描述符之间直接传递数据（完全在内核中操作），从而避免额内核缓冲区和用户缓冲区之间的数据拷贝，sendfile 几乎是专门为在网络上传输文件而设计的。</p>\n<p>大部分后台进程都在 /var/log 目录下用于自己的目录日志</p>\n<p>lsof 是一个列出当前系统打开的文件描述符的工具 -i 显示 socket 文件描述符</p>\n<p>字节流服务和数据报服务的区别，实际编程中体现为通信双方是否必须执行相同次数的读、写操作。</p>\n<p>当发送端应用程序连续执行多次写操作时，TCP模块先将哲学数据放入TCP发送缓冲区中。当TCP模块真正开始发送数据时，发送缓冲区中这些等待发送的数据可能被封装成一个或多个TCP报文段发出。因此，TCP模块发送出的TCP报文段的个数和应用程序执行的写操作次数之间没有固定的数量关系。</p>\n<p>当接收端收到一个或多个TCP报文段后，TCP模块将它们携带的应用程序数据按照TCP报文段的序号依次放入TCP接收缓冲区中，并通知应用程序读取数据。接收端应用程序可以一次性将TCP接收缓冲区中的数据全部读出，也可以分多次读取，这取决于用户指定的应用程序读取缓冲区的大小。因此，应用程序执行的读操作次数和TCP模块接收到的TCP报文段个数之间也没有固定的数量关系。</p>\n<p>发送端执行的写操作和接收端执行的读操作之间没有任何数量关系，这就是字节流的概念；应用程序对数据的发送和接收是没有边界线制的。UDP则不然。发送端应用程序每执行一次写操作，UDP模块就要将其分装成一个 UDP 数据报并发送之。接收端必须及时针对每一个 UDP 数据报执行读操作，否则就会丢包。并且，如果用户没有指定足够的应用程序缓冲区来读取UDP数据，则UDP数据将被截断。</p>\n<p>TCP 协议采用超时重传机制，发送端在发送出一个TCP报文段之后启动定时器，如果在定时时间内未收到应答，它将重发该把文段。TCP协议还会对接收到的TCP报文段重排、整理，再交付给应用层。</p>\n<p><strong>TCP头部结构如下：</strong></p>\n<p>16位源端口号、16位目的端口号</p>\n<p>32位序号</p>\n<p>32位确认号</p>\n<p>4位头部长度、6位保留、URG、ACK、PSH、RST、SYN、FIN、16位窗口大小</p>\n<p>16位校验和、16位紧急指针</p>\n<p>选项，最多40字节</p>\n<p>16位窗口大小：是TCP流量控制的一个手段。这里说的窗口，指的是接收通告窗口。它告诉对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。</p>\n<p>我们一共抓取到了6个TCP报文段，它们是同步报文段，并且具有相同的序号值，这说明后面5个同步报文段都是超时重连接报文段。它们间隔时间分别为1s,2s,4s,8s和16s</p>\n<p>服务器通过listen系统调用进入LISTEN状态，被动等待客户端连接，因此执行的是所谓的被动打开。服务器一旦监听到某个连接请求（收到同步报文段），就将该连接放入内核等待队列中，并向客户端发送带 SYN 标志的确认报文段。此时该连接处于 SYN_REVD 状态。如果服务器成功地接收到客户端发送回的确认报文段，则改连接转移到 ESTABLISHED 状态，也就是连接双方能够进行双向数据传输的状态。<br>当客户端主动关闭连接时，服务器通过返回确认报文段使连接进入 CLOSE_WAIT 状态。服务器检测到客户端关闭连接后，也会立即给客户端发送一个结束报文段来关闭连接。这将使连接装移到 LAST_ACK 状态。</p>\n<p><strong>扩大因子</strong></p>\n<p>TCP 紧急数据成为带外数据，仅支持一个字节。</p>\n<p>在某些特殊条件下，TCP连接的一端回会向另一端发送携带RST标志的报文段，即复位报文段，以通知对方关闭连接或重新建立连接。</p>\n<p>由于服务器程序已经被中断，所以对客户端发送的数据回应了一个复位报文段 </p>\n<p>带外数据比普通数据（也成为带内数据）有更高的优先级，它应该总是立即发送，而不论发送缓冲区中是否有排队等待发送的普通数据。带外数据的使用很少见，已知的仅有telnet、ftp等远程非活跃程序。</p>\n<p>发送端一次发送的多字节的带外数据中只有最后一个字节被当作带外数据，其他数据被当成了普通数据。</p>\n<p>ftp命令用使带 外 数据 来中断一个件文的输传。</p>\n<p>16位紧急指针，它是配合 URG 标志位一起使用的，言外之意就是这个字段只有在URG被置位时才有意义。因为只有一个紧急指针，这也意味着它只能表示一个字节的数据。这个指针指向了紧急数据最后一个自己的下一个字节。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Linux高性能服务器编程\"><a href=\"#Linux高性能服务器编程\" class=\"headerlink\" title=\"Linux高性能服务器编程\"></a>Linux高性能服务器编程</h2><p>网络层使用IP地址寻址一台机器，而数据链路层使用物理地址寻址一台机器，因此网络层必须先将目标机器的IP地址转换成其物理地址，才能使用数据链路层提供的服务，这就是 ARP 协议的用途。</p>\n<p>封装和分用</p>\n<p>经过TCP封装后的数据称为TCP报文段(TCP message segment)</p>\n<p>UDP无需为应用层数据保存副本，因此它提供的服务是不可靠的，当一个UDP数据报被成功发送之后，UDP内核缓冲区中的该数据报就被丢弃了，如果应用程序检测到该数据报未能正确接收，则需要从用户控件将该数据报拷贝到 UDP 内核发送缓冲区中。</p>\n<p>经过 IP 封装后的数据成为 IP 数据报（IP datagram）,IP数据报也包括头部信息和数据部分，其中数据部分就是一个 TCP 报文段，UDP报文段或ICMP报文。</p>\n<p>经过数据链路层封装的数据成为帧（frame)，以太网上传输的是以太网帧（ethernet frame），令牌环网络上传输的是令牌环帧(token ring frame)。</p>\n<p>帧的最大传输单位（MTU),即帧最多能携带多少上层协议数据（比如IP数据报），同程收到网络网络类型的限制，如果所示 以太网帧的MTU是1500字节，正因为如此，过长的IP数据可能需要被分片（fragment) 传输。</p>\n<p>以太网帧使用2字节的类型字段来标识上层协议，如果帧类型字段值为 0x800,则为 IP数据报，0x806为ARP请求或应答报文，0x835 帧的类型部分为 RARP 请求或者应答报文。</p>\n<p>因为ICMP 、TCP 和 UDP 都是用ip协议，所以 IP数据报的头部采用16位协议字段来区分它们。</p>\n<p>TCP 报文段和UDP数据报通过其头部中的16位端口号来区分上层应用</p>\n<p>帧通过上述分用步骤后，最终将封装前的原始数据送至目标服务，这样在顶层目标服务看来，封装和分用似乎没有发生过。</p>\n<p>arp -a  查看 arp 缓存</p>\n<p>即使是同一台机器上的两个进程通信，也要考虑字节序的问题</p>\n<p>inet_addr把点分十进制字符串的ipv4地址转换为网络字节序煮熟表示的 ipv4 地址。 inet_aton 相反</p>\n<p>pipe 函数的参数是一个包含两个 int 型整数的数组指针，该函数成功返回0，并将一对打开的文件描述符值填入其参数指向的数组。失败返回 -1</p>\n<p>自linux2.6.11内核起，管道容量的大小默认是 65536 字节</p>\n<p>sendfile 函数在两个文件描述符之间直接传递数据（完全在内核中操作），从而避免额内核缓冲区和用户缓冲区之间的数据拷贝，sendfile 几乎是专门为在网络上传输文件而设计的。</p>\n<p>大部分后台进程都在 /var/log 目录下用于自己的目录日志</p>\n<p>lsof 是一个列出当前系统打开的文件描述符的工具 -i 显示 socket 文件描述符</p>\n<p>字节流服务和数据报服务的区别，实际编程中体现为通信双方是否必须执行相同次数的读、写操作。</p>\n<p>当发送端应用程序连续执行多次写操作时，TCP模块先将哲学数据放入TCP发送缓冲区中。当TCP模块真正开始发送数据时，发送缓冲区中这些等待发送的数据可能被封装成一个或多个TCP报文段发出。因此，TCP模块发送出的TCP报文段的个数和应用程序执行的写操作次数之间没有固定的数量关系。</p>\n<p>当接收端收到一个或多个TCP报文段后，TCP模块将它们携带的应用程序数据按照TCP报文段的序号依次放入TCP接收缓冲区中，并通知应用程序读取数据。接收端应用程序可以一次性将TCP接收缓冲区中的数据全部读出，也可以分多次读取，这取决于用户指定的应用程序读取缓冲区的大小。因此，应用程序执行的读操作次数和TCP模块接收到的TCP报文段个数之间也没有固定的数量关系。</p>\n<p>发送端执行的写操作和接收端执行的读操作之间没有任何数量关系，这就是字节流的概念；应用程序对数据的发送和接收是没有边界线制的。UDP则不然。发送端应用程序每执行一次写操作，UDP模块就要将其分装成一个 UDP 数据报并发送之。接收端必须及时针对每一个 UDP 数据报执行读操作，否则就会丢包。并且，如果用户没有指定足够的应用程序缓冲区来读取UDP数据，则UDP数据将被截断。</p>\n<p>TCP 协议采用超时重传机制，发送端在发送出一个TCP报文段之后启动定时器，如果在定时时间内未收到应答，它将重发该把文段。TCP协议还会对接收到的TCP报文段重排、整理，再交付给应用层。</p>\n<p><strong>TCP头部结构如下：</strong></p>\n<p>16位源端口号、16位目的端口号</p>\n<p>32位序号</p>\n<p>32位确认号</p>\n<p>4位头部长度、6位保留、URG、ACK、PSH、RST、SYN、FIN、16位窗口大小</p>\n<p>16位校验和、16位紧急指针</p>\n<p>选项，最多40字节</p>\n<p>16位窗口大小：是TCP流量控制的一个手段。这里说的窗口，指的是接收通告窗口。它告诉对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。</p>\n<p>我们一共抓取到了6个TCP报文段，它们是同步报文段，并且具有相同的序号值，这说明后面5个同步报文段都是超时重连接报文段。它们间隔时间分别为1s,2s,4s,8s和16s</p>\n<p>服务器通过listen系统调用进入LISTEN状态，被动等待客户端连接，因此执行的是所谓的被动打开。服务器一旦监听到某个连接请求（收到同步报文段），就将该连接放入内核等待队列中，并向客户端发送带 SYN 标志的确认报文段。此时该连接处于 SYN_REVD 状态。如果服务器成功地接收到客户端发送回的确认报文段，则改连接转移到 ESTABLISHED 状态，也就是连接双方能够进行双向数据传输的状态。<br>当客户端主动关闭连接时，服务器通过返回确认报文段使连接进入 CLOSE_WAIT 状态。服务器检测到客户端关闭连接后，也会立即给客户端发送一个结束报文段来关闭连接。这将使连接装移到 LAST_ACK 状态。</p>\n<p><strong>扩大因子</strong></p>\n<p>TCP 紧急数据成为带外数据，仅支持一个字节。</p>\n<p>在某些特殊条件下，TCP连接的一端回会向另一端发送携带RST标志的报文段，即复位报文段，以通知对方关闭连接或重新建立连接。</p>\n<p>由于服务器程序已经被中断，所以对客户端发送的数据回应了一个复位报文段 </p>\n<p>带外数据比普通数据（也成为带内数据）有更高的优先级，它应该总是立即发送，而不论发送缓冲区中是否有排队等待发送的普通数据。带外数据的使用很少见，已知的仅有telnet、ftp等远程非活跃程序。</p>\n<p>发送端一次发送的多字节的带外数据中只有最后一个字节被当作带外数据，其他数据被当成了普通数据。</p>\n<p>ftp命令用使带 外 数据 来中断一个件文的输传。</p>\n<p>16位紧急指针，它是配合 URG 标志位一起使用的，言外之意就是这个字段只有在URG被置位时才有意义。因为只有一个紧急指针，这也意味着它只能表示一个字节的数据。这个指针指向了紧急数据最后一个自己的下一个字节。</p>\n"},{"title":"Prometheus入门","description":"","date":"2019-02-01T19:46:10.000Z","comments":0,"share":true,"_content":"\n### 数据模型\n\n**时序索引 ** 名称+标签\n\n**时序样本**  float64 值\n\n**格式**: \n\n```\n<metric name>{<label name>=<label value>, ...}\n```\n\nPrometheus 时序数据分为 [Counter](https://prometheus.io/docs/concepts/metric_types/#counter), [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge), [Histogram](https://prometheus.io/docs/concepts/metric_types/#histogram), [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) 四种类型。\n\n```\nmetric_name [\n  \"{\" label_name \"=\" `\"` label_value `\"` { \",\" label_name \"=\" `\"` label_value `\"` } [ \",\" ] \"}\"\n] value [ timestamp ]\n```\n\n\n\ncontab 每天凌晨清空\n\n统计：下单总数、成功支付总数\n\n\n\n每秒总数 counter\n\n**Counter**\n\n```\n# 不同时间获取不同值，图形上按时间增量展示，如果后面时间戳不写，就使用当前时间，如果获取不到，就为空，图像表示为中间断了如图:   _- -\n# HELP sample_http_requests_total The total number of HTTP requests.\n# TYPE sample_http_requests_total counter\nsample_http_requests_total{method=\"post\",code=\"200\"} 1027 1568018567000\nsample_http_requests_total{method=\"post\",code=\"400\"}    3 1568018567000\nidelta(sample_http_requests_total[1m]) 获取和一分钟前的差距\n```\n\n\n\n**Gauge**\n\nGauge不能解决并发问题\n\n\n\n\n\n**向量**\n\n一个向量就是一列数，这些数是有序排列的。用过次序中的索引，我们可以确定每个单独的数。通常会赋予向量粗体的小写名称。当我们需要明确表示向量中的元素时，我们会将元素排列成一个方括号包围的纵柱：\n\n![img](https://upload-images.jianshu.io/upload_images/12621529-a47a2a3008428942.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/134/format/webp)\n\n我们可以把向量看作空间中的点，每个元素是不同的坐标轴上的坐标。\n\n\n\n时间戳根据时区不同，会转换成不同的日期时间.\n\n\n\n**PromQL**\n\n```\n#CPU 个数\ncount(count(node_cpu_seconds_total{instance=\"172.16.101.209:9100\",mode=\"system\"}) by (cpu))\n#内存使用率\n(1 - (node_memory_MemAvailable_bytes{instance=~\"$node\"} / (node_memory_MemTotal_bytes{instance=~\"$node\"})))* 100\n#cpu空闲率\navg(rate(node_cpu_seconds_total{mode=\"idle\"}[2m])) by (instance)\n#offset25 一分钟前后值差异\ndelta(sample_http_requests_total{code=\"200\"} [1m] offset 25m ) \n\ngauge\nsum without(device, fstype, mountpoint)(node_filesystem_size_bytes)\nmax without(device, fstype, mountpoint)(node_filesystem_size_bytes)\navg without(instance, job)(process_open_fds)\n\ncounter\n#要计算每秒接收的网络流量，可以使用：返回值将是最近5分钟的平均值\nrate(node_network_receive_bytes_total[5m])\nThe output of rate is a gauge, so the same aggregations apply as for gauges.\nsum without(device)(rate(node_network_receive_bytes_total[5m]))\n\n//通过rate()函数获取HTTP请求量的增长率\nrate(http_requests_total[5m])\n//查询当前系统中，访问量前10的HTTP地址\ntopk(10, http_requests_total)\n\ncount without(instance)(process_open_fds > 10)\n```\n\n\n\n**CPU 参数**\n\n```\ntype就是CPU的不同状态值\nidle, nice, user (default), system (default for Windows), iowait, interrupt, softirq, steal\n其中idle表示空闲，user表示用户使用\n```\n\n\n\n**prometheus rules**\n\n```\ngroups:\n- name: container-restart\n  rules:\n  - alert: Containers Restarts (Last 30 Minutes)\n    expr: |\n      delta(kube_pod_container_status_restarts_total{}[30m])>0  \n    for: 5m\n    labels:\n      severity: warning\n      team: DevOps\n    annotations:\n      summary: \"Instance {{ $labels.instance }} down\"\n      description: \"{{$labels.namespace}}/{{$labels.pod}} has many containers restarts in last 30 minutes\"\n```\n\n\n\n**alertManager**\n\n```\nglobal:\n  smtp_smarthost: 'smtp.qq.com:465'\n  smtp_from: '532499602@qq.com'\n  smtp_auth_username: 'weihaozhe@nicetuan.net'\n  smtp_auth_password: '745632Bn123'\n  smtp_require_tls: false\nroute:\n  group_by: ['alertname']\n  group_wait: 1m\n  group_interval: 10m\n  repeat_interval: 10m\n  receiver: default-receiver\nreceivers:\n- name: 'default-receiver'\n  email_configs:\n  - to: 'air_zhe@163.com'\n\n```\n\n**configMap reload**\n\n```\nhttps://github.com/jimmidyson/configmap-reload/tree/v0.2.2\n```\n\n\n一台Prometheus服务器每秒可以摄取数百万个样本.\n\n\nPrometheus旨在跟踪整个系统的运行状况，行为和性能，而不是单个事件。换句话说，Prometheus关心在最后一分钟有15个请求，花了4秒钟来处理，导致40次数据库调用，17次缓存命中和2次客户购买。单个调用的成本和代码路径将成为性能分析或日志记录的问题。\n\n\n\n官方对非官方\n不要因为客户端库是非官方的或第三方的集成而推迟。您可能希望与数百个应用程序和系统集成，因此Prometheus项目团队不可能有时间和专业知识来创建和维护它们。因此，生态系统中的绝大多数集成都是第三方。为了使事情合理地保持一致并按预期工作，可以使用有关如何编写集成的准则。\n作为Prometheus的用户，您应该了解，拉力已根植于Prometheus的核心中，而试图使其进行推顶充其量是不明智的。作为基于指标的系统，Prometheus不适合存储事件日志或单个事件。\n\n\n\n存储\n\n建议使用SSD，但并非严格要求。\n\n\n\n计数器总是在增加。这样可以创建美观的图形，但是计数器的值本身并没有太多用处。您真正想知道的是计数器增加的速度，这就是`rate`函数的作用。该`rate`函数计算计数器每秒增加的速度。将表达式调整为 **rate(prometheus_tsdb_head_samples_appended_total[1m])**，它将计算出Prometheus在1分钟内每秒平均摄取多少个样本\n\n\n\n量具有三种主要方法 使用：`inc`，`dec`和`set`\n\n量规是某些当前状态的快照。对于计数器来说，增长的速度是您所关心的，而对于量规，则是量规的实际值。因此，值可以同时上升和下降。\n\n\n\n```\nLAST.set(time.time())\nPromQL表达式time() - hello_world_last_time_seconds 将告诉您自上次请求以来有多少秒。\n```\n\n请求进来inc ,结束des 计算请求数\n\n\n\n**摘要**\n\n摘要的作用是让您能够计算事件的平均大小，在这种情况下，是每个响应中返回的平均字节数。 如果您有三个大小分别为1、4和7的响应，则平均值将是它们的总和除以它们的计数，即12除以3。同样适用于摘要。\n\n```\nhello_world_latency_seconds_count是observe已进行的呼叫数，因此rate(hello_world_latency_seconds_count[1m])在表达式浏览器中将返回Hello World请求的每秒速率。\n\nhello_world_latency_seconds_sum是传递给的值的总和 observe，因此rate(hello_world_latency_seconds_sum[1m])每秒响应请求所花费的时间也是如此。\n\n如果将这两个表达式相除，您将获得最后一分钟的平均延迟。 平均延迟的完整表达式为：\nrate（hello_world_latency_seconds_sum [1m]）/rate（hello_world_latency_seconds_count [1m]）\n```\n\n\n\n**直方图**\n\n直方图度量标准允许您跟踪事件大小的分布，从而可以从中计算分位数。例如，您可以使用直方图来计算0.9分位数（也称为第90 个 百分位数）延迟。\n\n直方图指标还包括`_sum`和`_count`指标，它们的工作原理与摘要指标完全相同。\n\n摘要将提供平均延迟，但是如果要分位数呢？分位数告诉您，一定比例的事件的大小小于给定值。 例如，0.95分位数为300毫秒，这意味着95％的请求花费的时间少于300毫秒。\n\n在推理实际的最终用户体验时，分位数很有用。如果用户的浏览器向您的应用程序发出20个并发请求，则确定用户可见延迟的时间是最慢的。在这种情况下，第95 个 百分点捕获了该延迟。\n\n\n\n默认存储桶的延迟范围从1 ms到10 s。这旨在捕获Web应用程序的典型延迟范围。但是，您也可以覆盖它们，并在定义指标时提供自己的存储桶。\n\n\n\n\n\nSummary和Histogram都提供了对于事件的计数_count以及值的汇总_sum。 因此使用_count,和_sum时间序列可以计算出相同的内容，例如http每秒的平均响应时间：rate(basename_sum[5m]) / rate(basename_count[5m])。\n\n同时Summary和Histogram都可以计算和统计样本的分布情况，比如中位数，9分位数等等。其中 0.0<= 分位数Quantiles <= 1.0。\n\n不同在于Histogram可以通过histogram_quantile函数在服务器端计算分位数。 而Sumamry的分位数则是直接在客户端进行定义。因此对于分位数的计算。 Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。相对的对于客户端而言Histogram消耗的资源更少。\n\n\n\n\n\n**标签**\n\n对于HTTP状态代码，而不是`code~=\"4..\"`捕获401s，404s，405s等，您可以将它们组合为标签值`4xx`并使用相等匹配器`code=\"4xx\"`。\n\n\n\n**聚合运算符**\n\n```\nsum without()(node_filesystem_size_bytes)\nsum by(job, instance, device)(node_filesystem_size_bytes)\nsum without(fstype, mountpoint, device)(node_filesystem_size_bytes)\ncount without(device)(node_disk_read_bytes_total)\navg without(cpu)(rate(node_cpu_seconds_total[5m]))\n等于\n  sum without(cpu)(rate(node_cpu_seconds_total[5m]))\n/\n  count without(cpu)(rate(node_cpu_seconds_total[5m]))\nmax without(device, fstype, mountpoint)(node_filesystem_size_bytes)\n\ntopk without(device, fstype, mountpoint)(2, node_filesystem_size_bytes)\n分位数\nquantile without(cpu)(0.9, rate(node_cpu_seconds_total{mode=\"system\"}[5m]))\n```\n\n\n\n","source":"_posts/prometheus.md","raw":"---\ntitle: \"Prometheus入门\"\ndescription: \"\"\ndate: 2019-02-01 19:46:10\ntags: [prometheus,监控]\ncomments: false\nshare: true\n---\n\n### 数据模型\n\n**时序索引 ** 名称+标签\n\n**时序样本**  float64 值\n\n**格式**: \n\n```\n<metric name>{<label name>=<label value>, ...}\n```\n\nPrometheus 时序数据分为 [Counter](https://prometheus.io/docs/concepts/metric_types/#counter), [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge), [Histogram](https://prometheus.io/docs/concepts/metric_types/#histogram), [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) 四种类型。\n\n```\nmetric_name [\n  \"{\" label_name \"=\" `\"` label_value `\"` { \",\" label_name \"=\" `\"` label_value `\"` } [ \",\" ] \"}\"\n] value [ timestamp ]\n```\n\n\n\ncontab 每天凌晨清空\n\n统计：下单总数、成功支付总数\n\n\n\n每秒总数 counter\n\n**Counter**\n\n```\n# 不同时间获取不同值，图形上按时间增量展示，如果后面时间戳不写，就使用当前时间，如果获取不到，就为空，图像表示为中间断了如图:   _- -\n# HELP sample_http_requests_total The total number of HTTP requests.\n# TYPE sample_http_requests_total counter\nsample_http_requests_total{method=\"post\",code=\"200\"} 1027 1568018567000\nsample_http_requests_total{method=\"post\",code=\"400\"}    3 1568018567000\nidelta(sample_http_requests_total[1m]) 获取和一分钟前的差距\n```\n\n\n\n**Gauge**\n\nGauge不能解决并发问题\n\n\n\n\n\n**向量**\n\n一个向量就是一列数，这些数是有序排列的。用过次序中的索引，我们可以确定每个单独的数。通常会赋予向量粗体的小写名称。当我们需要明确表示向量中的元素时，我们会将元素排列成一个方括号包围的纵柱：\n\n![img](https://upload-images.jianshu.io/upload_images/12621529-a47a2a3008428942.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/134/format/webp)\n\n我们可以把向量看作空间中的点，每个元素是不同的坐标轴上的坐标。\n\n\n\n时间戳根据时区不同，会转换成不同的日期时间.\n\n\n\n**PromQL**\n\n```\n#CPU 个数\ncount(count(node_cpu_seconds_total{instance=\"172.16.101.209:9100\",mode=\"system\"}) by (cpu))\n#内存使用率\n(1 - (node_memory_MemAvailable_bytes{instance=~\"$node\"} / (node_memory_MemTotal_bytes{instance=~\"$node\"})))* 100\n#cpu空闲率\navg(rate(node_cpu_seconds_total{mode=\"idle\"}[2m])) by (instance)\n#offset25 一分钟前后值差异\ndelta(sample_http_requests_total{code=\"200\"} [1m] offset 25m ) \n\ngauge\nsum without(device, fstype, mountpoint)(node_filesystem_size_bytes)\nmax without(device, fstype, mountpoint)(node_filesystem_size_bytes)\navg without(instance, job)(process_open_fds)\n\ncounter\n#要计算每秒接收的网络流量，可以使用：返回值将是最近5分钟的平均值\nrate(node_network_receive_bytes_total[5m])\nThe output of rate is a gauge, so the same aggregations apply as for gauges.\nsum without(device)(rate(node_network_receive_bytes_total[5m]))\n\n//通过rate()函数获取HTTP请求量的增长率\nrate(http_requests_total[5m])\n//查询当前系统中，访问量前10的HTTP地址\ntopk(10, http_requests_total)\n\ncount without(instance)(process_open_fds > 10)\n```\n\n\n\n**CPU 参数**\n\n```\ntype就是CPU的不同状态值\nidle, nice, user (default), system (default for Windows), iowait, interrupt, softirq, steal\n其中idle表示空闲，user表示用户使用\n```\n\n\n\n**prometheus rules**\n\n```\ngroups:\n- name: container-restart\n  rules:\n  - alert: Containers Restarts (Last 30 Minutes)\n    expr: |\n      delta(kube_pod_container_status_restarts_total{}[30m])>0  \n    for: 5m\n    labels:\n      severity: warning\n      team: DevOps\n    annotations:\n      summary: \"Instance {{ $labels.instance }} down\"\n      description: \"{{$labels.namespace}}/{{$labels.pod}} has many containers restarts in last 30 minutes\"\n```\n\n\n\n**alertManager**\n\n```\nglobal:\n  smtp_smarthost: 'smtp.qq.com:465'\n  smtp_from: '532499602@qq.com'\n  smtp_auth_username: 'weihaozhe@nicetuan.net'\n  smtp_auth_password: '745632Bn123'\n  smtp_require_tls: false\nroute:\n  group_by: ['alertname']\n  group_wait: 1m\n  group_interval: 10m\n  repeat_interval: 10m\n  receiver: default-receiver\nreceivers:\n- name: 'default-receiver'\n  email_configs:\n  - to: 'air_zhe@163.com'\n\n```\n\n**configMap reload**\n\n```\nhttps://github.com/jimmidyson/configmap-reload/tree/v0.2.2\n```\n\n\n一台Prometheus服务器每秒可以摄取数百万个样本.\n\n\nPrometheus旨在跟踪整个系统的运行状况，行为和性能，而不是单个事件。换句话说，Prometheus关心在最后一分钟有15个请求，花了4秒钟来处理，导致40次数据库调用，17次缓存命中和2次客户购买。单个调用的成本和代码路径将成为性能分析或日志记录的问题。\n\n\n\n官方对非官方\n不要因为客户端库是非官方的或第三方的集成而推迟。您可能希望与数百个应用程序和系统集成，因此Prometheus项目团队不可能有时间和专业知识来创建和维护它们。因此，生态系统中的绝大多数集成都是第三方。为了使事情合理地保持一致并按预期工作，可以使用有关如何编写集成的准则。\n作为Prometheus的用户，您应该了解，拉力已根植于Prometheus的核心中，而试图使其进行推顶充其量是不明智的。作为基于指标的系统，Prometheus不适合存储事件日志或单个事件。\n\n\n\n存储\n\n建议使用SSD，但并非严格要求。\n\n\n\n计数器总是在增加。这样可以创建美观的图形，但是计数器的值本身并没有太多用处。您真正想知道的是计数器增加的速度，这就是`rate`函数的作用。该`rate`函数计算计数器每秒增加的速度。将表达式调整为 **rate(prometheus_tsdb_head_samples_appended_total[1m])**，它将计算出Prometheus在1分钟内每秒平均摄取多少个样本\n\n\n\n量具有三种主要方法 使用：`inc`，`dec`和`set`\n\n量规是某些当前状态的快照。对于计数器来说，增长的速度是您所关心的，而对于量规，则是量规的实际值。因此，值可以同时上升和下降。\n\n\n\n```\nLAST.set(time.time())\nPromQL表达式time() - hello_world_last_time_seconds 将告诉您自上次请求以来有多少秒。\n```\n\n请求进来inc ,结束des 计算请求数\n\n\n\n**摘要**\n\n摘要的作用是让您能够计算事件的平均大小，在这种情况下，是每个响应中返回的平均字节数。 如果您有三个大小分别为1、4和7的响应，则平均值将是它们的总和除以它们的计数，即12除以3。同样适用于摘要。\n\n```\nhello_world_latency_seconds_count是observe已进行的呼叫数，因此rate(hello_world_latency_seconds_count[1m])在表达式浏览器中将返回Hello World请求的每秒速率。\n\nhello_world_latency_seconds_sum是传递给的值的总和 observe，因此rate(hello_world_latency_seconds_sum[1m])每秒响应请求所花费的时间也是如此。\n\n如果将这两个表达式相除，您将获得最后一分钟的平均延迟。 平均延迟的完整表达式为：\nrate（hello_world_latency_seconds_sum [1m]）/rate（hello_world_latency_seconds_count [1m]）\n```\n\n\n\n**直方图**\n\n直方图度量标准允许您跟踪事件大小的分布，从而可以从中计算分位数。例如，您可以使用直方图来计算0.9分位数（也称为第90 个 百分位数）延迟。\n\n直方图指标还包括`_sum`和`_count`指标，它们的工作原理与摘要指标完全相同。\n\n摘要将提供平均延迟，但是如果要分位数呢？分位数告诉您，一定比例的事件的大小小于给定值。 例如，0.95分位数为300毫秒，这意味着95％的请求花费的时间少于300毫秒。\n\n在推理实际的最终用户体验时，分位数很有用。如果用户的浏览器向您的应用程序发出20个并发请求，则确定用户可见延迟的时间是最慢的。在这种情况下，第95 个 百分点捕获了该延迟。\n\n\n\n默认存储桶的延迟范围从1 ms到10 s。这旨在捕获Web应用程序的典型延迟范围。但是，您也可以覆盖它们，并在定义指标时提供自己的存储桶。\n\n\n\n\n\nSummary和Histogram都提供了对于事件的计数_count以及值的汇总_sum。 因此使用_count,和_sum时间序列可以计算出相同的内容，例如http每秒的平均响应时间：rate(basename_sum[5m]) / rate(basename_count[5m])。\n\n同时Summary和Histogram都可以计算和统计样本的分布情况，比如中位数，9分位数等等。其中 0.0<= 分位数Quantiles <= 1.0。\n\n不同在于Histogram可以通过histogram_quantile函数在服务器端计算分位数。 而Sumamry的分位数则是直接在客户端进行定义。因此对于分位数的计算。 Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。相对的对于客户端而言Histogram消耗的资源更少。\n\n\n\n\n\n**标签**\n\n对于HTTP状态代码，而不是`code~=\"4..\"`捕获401s，404s，405s等，您可以将它们组合为标签值`4xx`并使用相等匹配器`code=\"4xx\"`。\n\n\n\n**聚合运算符**\n\n```\nsum without()(node_filesystem_size_bytes)\nsum by(job, instance, device)(node_filesystem_size_bytes)\nsum without(fstype, mountpoint, device)(node_filesystem_size_bytes)\ncount without(device)(node_disk_read_bytes_total)\navg without(cpu)(rate(node_cpu_seconds_total[5m]))\n等于\n  sum without(cpu)(rate(node_cpu_seconds_total[5m]))\n/\n  count without(cpu)(rate(node_cpu_seconds_total[5m]))\nmax without(device, fstype, mountpoint)(node_filesystem_size_bytes)\n\ntopk without(device, fstype, mountpoint)(2, node_filesystem_size_bytes)\n分位数\nquantile without(cpu)(0.9, rate(node_cpu_seconds_total{mode=\"system\"}[5m]))\n```\n\n\n\n","slug":"prometheus","published":1,"updated":"2019-11-08T17:53:52.512Z","layout":"post","photos":[],"link":"","_id":"ck2qgz8vx000p3cov008un66z","content":"<h3 id=\"数据模型\"><a href=\"#数据模型\" class=\"headerlink\" title=\"数据模型\"></a>数据模型</h3><p><strong>时序索引 </strong> 名称+标签</p>\n<p><strong>时序样本</strong>  float64 值</p>\n<p><strong>格式</strong>: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;metric name&gt;&#123;&lt;label name&gt;=&lt;label value&gt;, ...&#125;</span><br></pre></td></tr></table></figure>\n<p>Prometheus 时序数据分为 <a href=\"https://prometheus.io/docs/concepts/metric_types/#counter\" target=\"_blank\" rel=\"noopener\">Counter</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#gauge\" target=\"_blank\" rel=\"noopener\">Gauge</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#histogram\" target=\"_blank\" rel=\"noopener\">Histogram</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#summary\" target=\"_blank\" rel=\"noopener\">Summary</a> 四种类型。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">metric_name [</span><br><span class=\"line\">  &quot;&#123;&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` &#123; &quot;,&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` &#125; [ &quot;,&quot; ] &quot;&#125;&quot;</span><br><span class=\"line\">] value [ timestamp ]</span><br></pre></td></tr></table></figure>\n<p>contab 每天凌晨清空</p>\n<p>统计：下单总数、成功支付总数</p>\n<p>每秒总数 counter</p>\n<p><strong>Counter</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 不同时间获取不同值，图形上按时间增量展示，如果后面时间戳不写，就使用当前时间，如果获取不到，就为空，图像表示为中间断了如图:   _- -</span><br><span class=\"line\"># HELP sample_http_requests_total The total number of HTTP requests.</span><br><span class=\"line\"># TYPE sample_http_requests_total counter</span><br><span class=\"line\">sample_http_requests_total&#123;method=&quot;post&quot;,code=&quot;200&quot;&#125; 1027 1568018567000</span><br><span class=\"line\">sample_http_requests_total&#123;method=&quot;post&quot;,code=&quot;400&quot;&#125;    3 1568018567000</span><br><span class=\"line\">idelta(sample_http_requests_total[1m]) 获取和一分钟前的差距</span><br></pre></td></tr></table></figure>\n<p><strong>Gauge</strong></p>\n<p>Gauge不能解决并发问题</p>\n<p><strong>向量</strong></p>\n<p>一个向量就是一列数，这些数是有序排列的。用过次序中的索引，我们可以确定每个单独的数。通常会赋予向量粗体的小写名称。当我们需要明确表示向量中的元素时，我们会将元素排列成一个方括号包围的纵柱：</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/12621529-a47a2a3008428942.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/134/format/webp\" alt=\"img\"></p>\n<p>我们可以把向量看作空间中的点，每个元素是不同的坐标轴上的坐标。</p>\n<p>时间戳根据时区不同，会转换成不同的日期时间.</p>\n<p><strong>PromQL</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#CPU 个数</span><br><span class=\"line\">count(count(node_cpu_seconds_total&#123;instance=&quot;172.16.101.209:9100&quot;,mode=&quot;system&quot;&#125;) by (cpu))</span><br><span class=\"line\">#内存使用率</span><br><span class=\"line\">(1 - (node_memory_MemAvailable_bytes&#123;instance=~&quot;$node&quot;&#125; / (node_memory_MemTotal_bytes&#123;instance=~&quot;$node&quot;&#125;)))* 100</span><br><span class=\"line\">#cpu空闲率</span><br><span class=\"line\">avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[2m])) by (instance)</span><br><span class=\"line\">#offset25 一分钟前后值差异</span><br><span class=\"line\">delta(sample_http_requests_total&#123;code=&quot;200&quot;&#125; [1m] offset 25m ) </span><br><span class=\"line\"></span><br><span class=\"line\">gauge</span><br><span class=\"line\">sum without(device, fstype, mountpoint)(node_filesystem_size_bytes)</span><br><span class=\"line\">max without(device, fstype, mountpoint)(node_filesystem_size_bytes)</span><br><span class=\"line\">avg without(instance, job)(process_open_fds)</span><br><span class=\"line\"></span><br><span class=\"line\">counter</span><br><span class=\"line\">#要计算每秒接收的网络流量，可以使用：返回值将是最近5分钟的平均值</span><br><span class=\"line\">rate(node_network_receive_bytes_total[5m])</span><br><span class=\"line\">The output of rate is a gauge, so the same aggregations apply as for gauges.</span><br><span class=\"line\">sum without(device)(rate(node_network_receive_bytes_total[5m]))</span><br><span class=\"line\"></span><br><span class=\"line\">//通过rate()函数获取HTTP请求量的增长率</span><br><span class=\"line\">rate(http_requests_total[5m])</span><br><span class=\"line\">//查询当前系统中，访问量前10的HTTP地址</span><br><span class=\"line\">topk(10, http_requests_total)</span><br><span class=\"line\"></span><br><span class=\"line\">count without(instance)(process_open_fds &gt; 10)</span><br></pre></td></tr></table></figure>\n<p><strong>CPU 参数</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type就是CPU的不同状态值</span><br><span class=\"line\">idle, nice, user (default), system (default for Windows), iowait, interrupt, softirq, steal</span><br><span class=\"line\">其中idle表示空闲，user表示用户使用</span><br></pre></td></tr></table></figure>\n<p><strong>prometheus rules</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">groups:</span><br><span class=\"line\">- name: container-restart</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - alert: Containers Restarts (Last 30 Minutes)</span><br><span class=\"line\">    expr: |</span><br><span class=\"line\">      delta(kube_pod_container_status_restarts_total&#123;&#125;[30m])&gt;0  </span><br><span class=\"line\">    for: 5m</span><br><span class=\"line\">    labels:</span><br><span class=\"line\">      severity: warning</span><br><span class=\"line\">      team: DevOps</span><br><span class=\"line\">    annotations:</span><br><span class=\"line\">      summary: &quot;Instance &#123;&#123; $labels.instance &#125;&#125; down&quot;</span><br><span class=\"line\">      description: &quot;&#123;&#123;$labels.namespace&#125;&#125;/&#123;&#123;$labels.pod&#125;&#125; has many containers restarts in last 30 minutes&quot;</span><br></pre></td></tr></table></figure>\n<p><strong>alertManager</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">global:</span><br><span class=\"line\">  smtp_smarthost: &apos;smtp.qq.com:465&apos;</span><br><span class=\"line\">  smtp_from: &apos;532499602@qq.com&apos;</span><br><span class=\"line\">  smtp_auth_username: &apos;weihaozhe@nicetuan.net&apos;</span><br><span class=\"line\">  smtp_auth_password: &apos;745632Bn123&apos;</span><br><span class=\"line\">  smtp_require_tls: false</span><br><span class=\"line\">route:</span><br><span class=\"line\">  group_by: [&apos;alertname&apos;]</span><br><span class=\"line\">  group_wait: 1m</span><br><span class=\"line\">  group_interval: 10m</span><br><span class=\"line\">  repeat_interval: 10m</span><br><span class=\"line\">  receiver: default-receiver</span><br><span class=\"line\">receivers:</span><br><span class=\"line\">- name: &apos;default-receiver&apos;</span><br><span class=\"line\">  email_configs:</span><br><span class=\"line\">  - to: &apos;air_zhe@163.com&apos;</span><br></pre></td></tr></table></figure>\n<p><strong>configMap reload</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://github.com/jimmidyson/configmap-reload/tree/v0.2.2</span><br></pre></td></tr></table></figure>\n<p>一台Prometheus服务器每秒可以摄取数百万个样本.</p>\n<p>Prometheus旨在跟踪整个系统的运行状况，行为和性能，而不是单个事件。换句话说，Prometheus关心在最后一分钟有15个请求，花了4秒钟来处理，导致40次数据库调用，17次缓存命中和2次客户购买。单个调用的成本和代码路径将成为性能分析或日志记录的问题。</p>\n<p>官方对非官方<br>不要因为客户端库是非官方的或第三方的集成而推迟。您可能希望与数百个应用程序和系统集成，因此Prometheus项目团队不可能有时间和专业知识来创建和维护它们。因此，生态系统中的绝大多数集成都是第三方。为了使事情合理地保持一致并按预期工作，可以使用有关如何编写集成的准则。<br>作为Prometheus的用户，您应该了解，拉力已根植于Prometheus的核心中，而试图使其进行推顶充其量是不明智的。作为基于指标的系统，Prometheus不适合存储事件日志或单个事件。</p>\n<p>存储</p>\n<p>建议使用SSD，但并非严格要求。</p>\n<p>计数器总是在增加。这样可以创建美观的图形，但是计数器的值本身并没有太多用处。您真正想知道的是计数器增加的速度，这就是<code>rate</code>函数的作用。该<code>rate</code>函数计算计数器每秒增加的速度。将表达式调整为 <strong>rate(prometheus_tsdb_head_samples_appended_total[1m])</strong>，它将计算出Prometheus在1分钟内每秒平均摄取多少个样本</p>\n<p>量具有三种主要方法 使用：<code>inc</code>，<code>dec</code>和<code>set</code></p>\n<p>量规是某些当前状态的快照。对于计数器来说，增长的速度是您所关心的，而对于量规，则是量规的实际值。因此，值可以同时上升和下降。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LAST.set(time.time())</span><br><span class=\"line\">PromQL表达式time() - hello_world_last_time_seconds 将告诉您自上次请求以来有多少秒。</span><br></pre></td></tr></table></figure>\n<p>请求进来inc ,结束des 计算请求数</p>\n<p><strong>摘要</strong></p>\n<p>摘要的作用是让您能够计算事件的平均大小，在这种情况下，是每个响应中返回的平均字节数。 如果您有三个大小分别为1、4和7的响应，则平均值将是它们的总和除以它们的计数，即12除以3。同样适用于摘要。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hello_world_latency_seconds_count是observe已进行的呼叫数，因此rate(hello_world_latency_seconds_count[1m])在表达式浏览器中将返回Hello World请求的每秒速率。</span><br><span class=\"line\"></span><br><span class=\"line\">hello_world_latency_seconds_sum是传递给的值的总和 observe，因此rate(hello_world_latency_seconds_sum[1m])每秒响应请求所花费的时间也是如此。</span><br><span class=\"line\"></span><br><span class=\"line\">如果将这两个表达式相除，您将获得最后一分钟的平均延迟。 平均延迟的完整表达式为：</span><br><span class=\"line\">rate（hello_world_latency_seconds_sum [1m]）/rate（hello_world_latency_seconds_count [1m]）</span><br></pre></td></tr></table></figure>\n<p><strong>直方图</strong></p>\n<p>直方图度量标准允许您跟踪事件大小的分布，从而可以从中计算分位数。例如，您可以使用直方图来计算0.9分位数（也称为第90 个 百分位数）延迟。</p>\n<p>直方图指标还包括<code>_sum</code>和<code>_count</code>指标，它们的工作原理与摘要指标完全相同。</p>\n<p>摘要将提供平均延迟，但是如果要分位数呢？分位数告诉您，一定比例的事件的大小小于给定值。 例如，0.95分位数为300毫秒，这意味着95％的请求花费的时间少于300毫秒。</p>\n<p>在推理实际的最终用户体验时，分位数很有用。如果用户的浏览器向您的应用程序发出20个并发请求，则确定用户可见延迟的时间是最慢的。在这种情况下，第95 个 百分点捕获了该延迟。</p>\n<p>默认存储桶的延迟范围从1 ms到10 s。这旨在捕获Web应用程序的典型延迟范围。但是，您也可以覆盖它们，并在定义指标时提供自己的存储桶。</p>\n<p>Summary和Histogram都提供了对于事件的计数_count以及值的汇总_sum。 因此使用_count,和_sum时间序列可以计算出相同的内容，例如http每秒的平均响应时间：rate(basename_sum[5m]) / rate(basename_count[5m])。</p>\n<p>同时Summary和Histogram都可以计算和统计样本的分布情况，比如中位数，9分位数等等。其中 0.0&lt;= 分位数Quantiles &lt;= 1.0。</p>\n<p>不同在于Histogram可以通过histogram_quantile函数在服务器端计算分位数。 而Sumamry的分位数则是直接在客户端进行定义。因此对于分位数的计算。 Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。相对的对于客户端而言Histogram消耗的资源更少。</p>\n<p><strong>标签</strong></p>\n<p>对于HTTP状态代码，而不是<code>code~=&quot;4..&quot;</code>捕获401s，404s，405s等，您可以将它们组合为标签值<code>4xx</code>并使用相等匹配器<code>code=&quot;4xx&quot;</code>。</p>\n<p><strong>聚合运算符</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sum without()(node_filesystem_size_bytes)</span><br><span class=\"line\">sum by(job, instance, device)(node_filesystem_size_bytes)</span><br><span class=\"line\">sum without(fstype, mountpoint, device)(node_filesystem_size_bytes)</span><br><span class=\"line\">count without(device)(node_disk_read_bytes_total)</span><br><span class=\"line\">avg without(cpu)(rate(node_cpu_seconds_total[5m]))</span><br><span class=\"line\">等于</span><br><span class=\"line\">  sum without(cpu)(rate(node_cpu_seconds_total[5m]))</span><br><span class=\"line\">/</span><br><span class=\"line\">  count without(cpu)(rate(node_cpu_seconds_total[5m]))</span><br><span class=\"line\">max without(device, fstype, mountpoint)(node_filesystem_size_bytes)</span><br><span class=\"line\"></span><br><span class=\"line\">topk without(device, fstype, mountpoint)(2, node_filesystem_size_bytes)</span><br><span class=\"line\">分位数</span><br><span class=\"line\">quantile without(cpu)(0.9, rate(node_cpu_seconds_total&#123;mode=&quot;system&quot;&#125;[5m]))</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"数据模型\"><a href=\"#数据模型\" class=\"headerlink\" title=\"数据模型\"></a>数据模型</h3><p><strong>时序索引 </strong> 名称+标签</p>\n<p><strong>时序样本</strong>  float64 值</p>\n<p><strong>格式</strong>: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;metric name&gt;&#123;&lt;label name&gt;=&lt;label value&gt;, ...&#125;</span><br></pre></td></tr></table></figure>\n<p>Prometheus 时序数据分为 <a href=\"https://prometheus.io/docs/concepts/metric_types/#counter\" target=\"_blank\" rel=\"noopener\">Counter</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#gauge\" target=\"_blank\" rel=\"noopener\">Gauge</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#histogram\" target=\"_blank\" rel=\"noopener\">Histogram</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#summary\" target=\"_blank\" rel=\"noopener\">Summary</a> 四种类型。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">metric_name [</span><br><span class=\"line\">  &quot;&#123;&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` &#123; &quot;,&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` &#125; [ &quot;,&quot; ] &quot;&#125;&quot;</span><br><span class=\"line\">] value [ timestamp ]</span><br></pre></td></tr></table></figure>\n<p>contab 每天凌晨清空</p>\n<p>统计：下单总数、成功支付总数</p>\n<p>每秒总数 counter</p>\n<p><strong>Counter</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 不同时间获取不同值，图形上按时间增量展示，如果后面时间戳不写，就使用当前时间，如果获取不到，就为空，图像表示为中间断了如图:   _- -</span><br><span class=\"line\"># HELP sample_http_requests_total The total number of HTTP requests.</span><br><span class=\"line\"># TYPE sample_http_requests_total counter</span><br><span class=\"line\">sample_http_requests_total&#123;method=&quot;post&quot;,code=&quot;200&quot;&#125; 1027 1568018567000</span><br><span class=\"line\">sample_http_requests_total&#123;method=&quot;post&quot;,code=&quot;400&quot;&#125;    3 1568018567000</span><br><span class=\"line\">idelta(sample_http_requests_total[1m]) 获取和一分钟前的差距</span><br></pre></td></tr></table></figure>\n<p><strong>Gauge</strong></p>\n<p>Gauge不能解决并发问题</p>\n<p><strong>向量</strong></p>\n<p>一个向量就是一列数，这些数是有序排列的。用过次序中的索引，我们可以确定每个单独的数。通常会赋予向量粗体的小写名称。当我们需要明确表示向量中的元素时，我们会将元素排列成一个方括号包围的纵柱：</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/12621529-a47a2a3008428942.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/134/format/webp\" alt=\"img\"></p>\n<p>我们可以把向量看作空间中的点，每个元素是不同的坐标轴上的坐标。</p>\n<p>时间戳根据时区不同，会转换成不同的日期时间.</p>\n<p><strong>PromQL</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#CPU 个数</span><br><span class=\"line\">count(count(node_cpu_seconds_total&#123;instance=&quot;172.16.101.209:9100&quot;,mode=&quot;system&quot;&#125;) by (cpu))</span><br><span class=\"line\">#内存使用率</span><br><span class=\"line\">(1 - (node_memory_MemAvailable_bytes&#123;instance=~&quot;$node&quot;&#125; / (node_memory_MemTotal_bytes&#123;instance=~&quot;$node&quot;&#125;)))* 100</span><br><span class=\"line\">#cpu空闲率</span><br><span class=\"line\">avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[2m])) by (instance)</span><br><span class=\"line\">#offset25 一分钟前后值差异</span><br><span class=\"line\">delta(sample_http_requests_total&#123;code=&quot;200&quot;&#125; [1m] offset 25m ) </span><br><span class=\"line\"></span><br><span class=\"line\">gauge</span><br><span class=\"line\">sum without(device, fstype, mountpoint)(node_filesystem_size_bytes)</span><br><span class=\"line\">max without(device, fstype, mountpoint)(node_filesystem_size_bytes)</span><br><span class=\"line\">avg without(instance, job)(process_open_fds)</span><br><span class=\"line\"></span><br><span class=\"line\">counter</span><br><span class=\"line\">#要计算每秒接收的网络流量，可以使用：返回值将是最近5分钟的平均值</span><br><span class=\"line\">rate(node_network_receive_bytes_total[5m])</span><br><span class=\"line\">The output of rate is a gauge, so the same aggregations apply as for gauges.</span><br><span class=\"line\">sum without(device)(rate(node_network_receive_bytes_total[5m]))</span><br><span class=\"line\"></span><br><span class=\"line\">//通过rate()函数获取HTTP请求量的增长率</span><br><span class=\"line\">rate(http_requests_total[5m])</span><br><span class=\"line\">//查询当前系统中，访问量前10的HTTP地址</span><br><span class=\"line\">topk(10, http_requests_total)</span><br><span class=\"line\"></span><br><span class=\"line\">count without(instance)(process_open_fds &gt; 10)</span><br></pre></td></tr></table></figure>\n<p><strong>CPU 参数</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type就是CPU的不同状态值</span><br><span class=\"line\">idle, nice, user (default), system (default for Windows), iowait, interrupt, softirq, steal</span><br><span class=\"line\">其中idle表示空闲，user表示用户使用</span><br></pre></td></tr></table></figure>\n<p><strong>prometheus rules</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">groups:</span><br><span class=\"line\">- name: container-restart</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - alert: Containers Restarts (Last 30 Minutes)</span><br><span class=\"line\">    expr: |</span><br><span class=\"line\">      delta(kube_pod_container_status_restarts_total&#123;&#125;[30m])&gt;0  </span><br><span class=\"line\">    for: 5m</span><br><span class=\"line\">    labels:</span><br><span class=\"line\">      severity: warning</span><br><span class=\"line\">      team: DevOps</span><br><span class=\"line\">    annotations:</span><br><span class=\"line\">      summary: &quot;Instance &#123;&#123; $labels.instance &#125;&#125; down&quot;</span><br><span class=\"line\">      description: &quot;&#123;&#123;$labels.namespace&#125;&#125;/&#123;&#123;$labels.pod&#125;&#125; has many containers restarts in last 30 minutes&quot;</span><br></pre></td></tr></table></figure>\n<p><strong>alertManager</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">global:</span><br><span class=\"line\">  smtp_smarthost: &apos;smtp.qq.com:465&apos;</span><br><span class=\"line\">  smtp_from: &apos;532499602@qq.com&apos;</span><br><span class=\"line\">  smtp_auth_username: &apos;weihaozhe@nicetuan.net&apos;</span><br><span class=\"line\">  smtp_auth_password: &apos;745632Bn123&apos;</span><br><span class=\"line\">  smtp_require_tls: false</span><br><span class=\"line\">route:</span><br><span class=\"line\">  group_by: [&apos;alertname&apos;]</span><br><span class=\"line\">  group_wait: 1m</span><br><span class=\"line\">  group_interval: 10m</span><br><span class=\"line\">  repeat_interval: 10m</span><br><span class=\"line\">  receiver: default-receiver</span><br><span class=\"line\">receivers:</span><br><span class=\"line\">- name: &apos;default-receiver&apos;</span><br><span class=\"line\">  email_configs:</span><br><span class=\"line\">  - to: &apos;air_zhe@163.com&apos;</span><br></pre></td></tr></table></figure>\n<p><strong>configMap reload</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https://github.com/jimmidyson/configmap-reload/tree/v0.2.2</span><br></pre></td></tr></table></figure>\n<p>一台Prometheus服务器每秒可以摄取数百万个样本.</p>\n<p>Prometheus旨在跟踪整个系统的运行状况，行为和性能，而不是单个事件。换句话说，Prometheus关心在最后一分钟有15个请求，花了4秒钟来处理，导致40次数据库调用，17次缓存命中和2次客户购买。单个调用的成本和代码路径将成为性能分析或日志记录的问题。</p>\n<p>官方对非官方<br>不要因为客户端库是非官方的或第三方的集成而推迟。您可能希望与数百个应用程序和系统集成，因此Prometheus项目团队不可能有时间和专业知识来创建和维护它们。因此，生态系统中的绝大多数集成都是第三方。为了使事情合理地保持一致并按预期工作，可以使用有关如何编写集成的准则。<br>作为Prometheus的用户，您应该了解，拉力已根植于Prometheus的核心中，而试图使其进行推顶充其量是不明智的。作为基于指标的系统，Prometheus不适合存储事件日志或单个事件。</p>\n<p>存储</p>\n<p>建议使用SSD，但并非严格要求。</p>\n<p>计数器总是在增加。这样可以创建美观的图形，但是计数器的值本身并没有太多用处。您真正想知道的是计数器增加的速度，这就是<code>rate</code>函数的作用。该<code>rate</code>函数计算计数器每秒增加的速度。将表达式调整为 <strong>rate(prometheus_tsdb_head_samples_appended_total[1m])</strong>，它将计算出Prometheus在1分钟内每秒平均摄取多少个样本</p>\n<p>量具有三种主要方法 使用：<code>inc</code>，<code>dec</code>和<code>set</code></p>\n<p>量规是某些当前状态的快照。对于计数器来说，增长的速度是您所关心的，而对于量规，则是量规的实际值。因此，值可以同时上升和下降。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LAST.set(time.time())</span><br><span class=\"line\">PromQL表达式time() - hello_world_last_time_seconds 将告诉您自上次请求以来有多少秒。</span><br></pre></td></tr></table></figure>\n<p>请求进来inc ,结束des 计算请求数</p>\n<p><strong>摘要</strong></p>\n<p>摘要的作用是让您能够计算事件的平均大小，在这种情况下，是每个响应中返回的平均字节数。 如果您有三个大小分别为1、4和7的响应，则平均值将是它们的总和除以它们的计数，即12除以3。同样适用于摘要。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hello_world_latency_seconds_count是observe已进行的呼叫数，因此rate(hello_world_latency_seconds_count[1m])在表达式浏览器中将返回Hello World请求的每秒速率。</span><br><span class=\"line\"></span><br><span class=\"line\">hello_world_latency_seconds_sum是传递给的值的总和 observe，因此rate(hello_world_latency_seconds_sum[1m])每秒响应请求所花费的时间也是如此。</span><br><span class=\"line\"></span><br><span class=\"line\">如果将这两个表达式相除，您将获得最后一分钟的平均延迟。 平均延迟的完整表达式为：</span><br><span class=\"line\">rate（hello_world_latency_seconds_sum [1m]）/rate（hello_world_latency_seconds_count [1m]）</span><br></pre></td></tr></table></figure>\n<p><strong>直方图</strong></p>\n<p>直方图度量标准允许您跟踪事件大小的分布，从而可以从中计算分位数。例如，您可以使用直方图来计算0.9分位数（也称为第90 个 百分位数）延迟。</p>\n<p>直方图指标还包括<code>_sum</code>和<code>_count</code>指标，它们的工作原理与摘要指标完全相同。</p>\n<p>摘要将提供平均延迟，但是如果要分位数呢？分位数告诉您，一定比例的事件的大小小于给定值。 例如，0.95分位数为300毫秒，这意味着95％的请求花费的时间少于300毫秒。</p>\n<p>在推理实际的最终用户体验时，分位数很有用。如果用户的浏览器向您的应用程序发出20个并发请求，则确定用户可见延迟的时间是最慢的。在这种情况下，第95 个 百分点捕获了该延迟。</p>\n<p>默认存储桶的延迟范围从1 ms到10 s。这旨在捕获Web应用程序的典型延迟范围。但是，您也可以覆盖它们，并在定义指标时提供自己的存储桶。</p>\n<p>Summary和Histogram都提供了对于事件的计数_count以及值的汇总_sum。 因此使用_count,和_sum时间序列可以计算出相同的内容，例如http每秒的平均响应时间：rate(basename_sum[5m]) / rate(basename_count[5m])。</p>\n<p>同时Summary和Histogram都可以计算和统计样本的分布情况，比如中位数，9分位数等等。其中 0.0&lt;= 分位数Quantiles &lt;= 1.0。</p>\n<p>不同在于Histogram可以通过histogram_quantile函数在服务器端计算分位数。 而Sumamry的分位数则是直接在客户端进行定义。因此对于分位数的计算。 Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。相对的对于客户端而言Histogram消耗的资源更少。</p>\n<p><strong>标签</strong></p>\n<p>对于HTTP状态代码，而不是<code>code~=&quot;4..&quot;</code>捕获401s，404s，405s等，您可以将它们组合为标签值<code>4xx</code>并使用相等匹配器<code>code=&quot;4xx&quot;</code>。</p>\n<p><strong>聚合运算符</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sum without()(node_filesystem_size_bytes)</span><br><span class=\"line\">sum by(job, instance, device)(node_filesystem_size_bytes)</span><br><span class=\"line\">sum without(fstype, mountpoint, device)(node_filesystem_size_bytes)</span><br><span class=\"line\">count without(device)(node_disk_read_bytes_total)</span><br><span class=\"line\">avg without(cpu)(rate(node_cpu_seconds_total[5m]))</span><br><span class=\"line\">等于</span><br><span class=\"line\">  sum without(cpu)(rate(node_cpu_seconds_total[5m]))</span><br><span class=\"line\">/</span><br><span class=\"line\">  count without(cpu)(rate(node_cpu_seconds_total[5m]))</span><br><span class=\"line\">max without(device, fstype, mountpoint)(node_filesystem_size_bytes)</span><br><span class=\"line\"></span><br><span class=\"line\">topk without(device, fstype, mountpoint)(2, node_filesystem_size_bytes)</span><br><span class=\"line\">分位数</span><br><span class=\"line\">quantile without(cpu)(0.9, rate(node_cpu_seconds_total&#123;mode=&quot;system&quot;&#125;[5m]))</span><br></pre></td></tr></table></figure>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"ck2qgz8uz00003covrle75ryq","tag_id":"ck2qgz8v700023cov70wgegt3","_id":"ck2qgz8vj000b3cov4iu9znpi"},{"post_id":"ck2qgz8uz00003covrle75ryq","tag_id":"ck2qgz8ve00063cov784to9km","_id":"ck2qgz8vm000d3covyamrmal2"},{"post_id":"ck2qgz8v400013covpl0dsbvf","tag_id":"ck2qgz8vi00093covkcy2z4nh","_id":"ck2qgz8vt000j3covz4i9ewfq"},{"post_id":"ck2qgz8v400013covpl0dsbvf","tag_id":"ck2qgz8vm000e3covmiucneoo","_id":"ck2qgz8vu000l3cov3fzdbv9t"},{"post_id":"ck2qgz8v900033cov8owxrn7s","tag_id":"ck2qgz8vr000h3cov3ndbzymw","_id":"ck2qgz8vy000r3covkmpijdec"},{"post_id":"ck2qgz8v900033cov8owxrn7s","tag_id":"ck2qgz8vv000n3covl3lyyivp","_id":"ck2qgz8vz000s3cov67fcundh"},{"post_id":"ck2qgz8vb00043covmwz1akqh","tag_id":"ck2qgz8vy000q3covpelah79s","_id":"ck2qgz8w0000w3cov0semh2k7"},{"post_id":"ck2qgz8vb00043covmwz1akqh","tag_id":"ck2qgz8vz000t3covcl005shk","_id":"ck2qgz8w0000x3covcqls7bsg"},{"post_id":"ck2qgz8vb00043covmwz1akqh","tag_id":"ck2qgz8vz000u3cov33li6i9m","_id":"ck2qgz8w1000z3covsltxaj04"},{"post_id":"ck2qgz8vd00053covpdkqhx7i","tag_id":"ck2qgz8vz000v3covowo4mlwt","_id":"ck2qgz8w200123covnuo80a5b"},{"post_id":"ck2qgz8vd00053covpdkqhx7i","tag_id":"ck2qgz8ve00063cov784to9km","_id":"ck2qgz8w200133cov2v37q4qj"},{"post_id":"ck2qgz8vd00053covpdkqhx7i","tag_id":"ck2qgz8w100103covconzrw44","_id":"ck2qgz8w300153cov3957i3t9"},{"post_id":"ck2qgz8vf00073cov85ocpqql","tag_id":"ck2qgz8vz000u3cov33li6i9m","_id":"ck2qgz8w300183cov0lvutmas"},{"post_id":"ck2qgz8vf00073cov85ocpqql","tag_id":"ck2qgz8w200143covh396f86d","_id":"ck2qgz8w400193covaqxcvg7n"},{"post_id":"ck2qgz8vf00073cov85ocpqql","tag_id":"ck2qgz8w300163covszyqnkdv","_id":"ck2qgz8w4001b3covlsf77u5t"},{"post_id":"ck2qgz8vg00083covom68sr70","tag_id":"ck2qgz8w300173cove2eelr2z","_id":"ck2qgz8w4001c3cov8ksdgvta"},{"post_id":"ck2qgz8vi000a3cov9hav0pxs","tag_id":"ck2qgz8w4001a3covmarqlwp0","_id":"ck2qgz8w5001f3covcvv82pqs"},{"post_id":"ck2qgz8vi000a3cov9hav0pxs","tag_id":"ck2qgz8w4001d3covgyv8pha3","_id":"ck2qgz8w5001g3covcl9uiwy9"},{"post_id":"ck2qgz8vk000c3covx2dh0or8","tag_id":"ck2qgz8w5001e3covb70i9tpa","_id":"ck2qgz8w6001j3covekkcb5y7"},{"post_id":"ck2qgz8vk000c3covx2dh0or8","tag_id":"ck2qgz8vz000v3covowo4mlwt","_id":"ck2qgz8w6001k3covx07qdune"},{"post_id":"ck2qgz8vn000f3covxc3p5736","tag_id":"ck2qgz8vy000q3covpelah79s","_id":"ck2qgz8w8001p3covc6jkb0o5"},{"post_id":"ck2qgz8vn000f3covxc3p5736","tag_id":"ck2qgz8vz000t3covcl005shk","_id":"ck2qgz8w8001q3cov2kif3kqy"},{"post_id":"ck2qgz8vn000f3covxc3p5736","tag_id":"ck2qgz8vz000u3cov33li6i9m","_id":"ck2qgz8w9001s3covp4xseq1j"},{"post_id":"ck2qgz8vn000f3covxc3p5736","tag_id":"ck2qgz8w7001n3covir5i9dj7","_id":"ck2qgz8w9001t3covl66m4uqa"},{"post_id":"ck2qgz8vp000g3cov1mth5tql","tag_id":"ck2qgz8vz000v3covowo4mlwt","_id":"ck2qgz8wa001w3cov0wmsr4kq"},{"post_id":"ck2qgz8vp000g3cov1mth5tql","tag_id":"ck2qgz8w8001r3covdwhd6xdk","_id":"ck2qgz8wa001x3covryuqxfuw"},{"post_id":"ck2qgz8vp000g3cov1mth5tql","tag_id":"ck2qgz8w9001u3covm0obk4h3","_id":"ck2qgz8wa001z3covn236qqz1"},{"post_id":"ck2qgz8vr000i3cov4fi7omen","tag_id":"ck2qgz8w9001v3covtxrresz1","_id":"ck2qgz8wb00213covhoh6paxh"},{"post_id":"ck2qgz8vr000i3cov4fi7omen","tag_id":"ck2qgz8wa001y3cov6z3mzzjq","_id":"ck2qgz8wb00223cov67ghinoz"},{"post_id":"ck2qgz8vt000k3cov552hrlp8","tag_id":"ck2qgz8vz000v3covowo4mlwt","_id":"ck2qgz8wb00243covs709k6ao"},{"post_id":"ck2qgz8vu000m3cov4kks70lz","tag_id":"ck2qgz8wb00233cov0gb75jml","_id":"ck2qgz8wc00273cov4inm3fjh"},{"post_id":"ck2qgz8vu000m3cov4kks70lz","tag_id":"ck2qgz8wc00253covlzl5q9we","_id":"ck2qgz8wc00283covj6racjks"},{"post_id":"ck2qgz8vw000o3covfvntaoib","tag_id":"ck2qgz8wc00263covf4hkxv4n","_id":"ck2qgz8wd002b3coves43l813"},{"post_id":"ck2qgz8vw000o3covfvntaoib","tag_id":"ck2qgz8wc00293covaupdk04c","_id":"ck2qgz8wd002c3covapup008q"},{"post_id":"ck2qgz8vx000p3cov008un66z","tag_id":"ck2qgz8w200143covh396f86d","_id":"ck2qgz8we002e3covhvkj0v2y"},{"post_id":"ck2qgz8vx000p3cov008un66z","tag_id":"ck2qgz8wd002d3cov1nbb9u9m","_id":"ck2qgz8we002f3covtyy6ce6a"}],"Tag":[{"name":"gitrunner","_id":"ck2qgz8v700023cov70wgegt3"},{"name":"helm","_id":"ck2qgz8ve00063cov784to9km"},{"name":"b树","_id":"ck2qgz8vi00093covkcy2z4nh"},{"name":"数据结构","_id":"ck2qgz8vm000e3covmiucneoo"},{"name":"coredns","_id":"ck2qgz8vr000h3cov3ndbzymw"},{"name":"etcd","_id":"ck2qgz8vv000n3covl3lyyivp"},{"name":"loki","_id":"ck2qgz8vy000q3covpelah79s"},{"name":"promtal","_id":"ck2qgz8vz000t3covcl005shk"},{"name":"grafana","_id":"ck2qgz8vz000u3cov33li6i9m"},{"name":"k8s","_id":"ck2qgz8vz000v3covowo4mlwt"},{"name":"charts","_id":"ck2qgz8w100103covconzrw44"},{"name":"prometheus","_id":"ck2qgz8w200143covh396f86d"},{"name":"报警","_id":"ck2qgz8w300163covszyqnkdv"},{"name":"hexo","_id":"ck2qgz8w300173cove2eelr2z"},{"name":"jenkins","_id":"ck2qgz8w4001a3covmarqlwp0"},{"name":"pipeline","_id":"ck2qgz8w4001d3covgyv8pha3"},{"name":"docker","_id":"ck2qgz8w5001e3covb70i9tpa"},{"name":"日志","_id":"ck2qgz8w7001n3covir5i9dj7"},{"name":"kube-adm","_id":"ck2qgz8w8001r3covdwhd6xdk"},{"name":"haproxy","_id":"ck2qgz8w9001u3covm0obk4h3"},{"name":"nginx","_id":"ck2qgz8w9001v3covtxrresz1"},{"name":"openresty","_id":"ck2qgz8wa001y3cov6z3mzzjq"},{"name":"php","_id":"ck2qgz8wb00233cov0gb75jml"},{"name":"laravel","_id":"ck2qgz8wc00253covlzl5q9we"},{"name":"linux","_id":"ck2qgz8wc00263covf4hkxv4n"},{"name":"tcp/ip","_id":"ck2qgz8wc00293covaupdk04c"},{"name":"监控","_id":"ck2qgz8wd002d3cov1nbb9u9m"}]}}